DataBase,Title,Abstract,Keywords,Authors,Year,DocumentType,PublicationTitle,DOI,Affiliations,Publisher,Language,ISSN,ISBN
Inspec,Structural Observability Analysis of Large Scale Systems Using Modelica and Python,"State observability of dynamic systems is a notion which determines how well the states can be inferred from input-output data. For small-scale systems, observability analysis can be done manually, while for large-scale systems an automated systematic approach is advantageous. Here we present an approach based on the concept of structural observability analysis, using graph theory. This approach can be automated and applied to large-scale, complex dynamic systems modeled using Modelica. Modelica models are imported into Python via the JModelica.org-CasADi interface, and the Python packages NetworkX (for graph-theoretic analysis) and PyGraphviz (for graph layout and visualization) are used to analyze the structural observability of the systems. The method is demonstrated with a Modelica model created for the Copper production plant at Glencore Nikkelverk, Kristiansand, Norway. The Copper plant model has 39 states, 11 disturbances and 5 uncertain parameters. The possibility of estimating disturbances and parameters in addition to estimating the states are also discussed from the graph-theory point of view. All the software tools used on the analysis are freely available.",Modelica - Python - dynamic systems - input-output data - small-scale systems - automated systematic approach - structural observability analysis - graph theory - large-scale-complex dynamic systems - JModelica.org-CasADi interface - NetworkX Python package - PyGraphviz - graph layout - graph visualization - copper production plant - Glencore Nikkelverk - Kristiansand - Norway - state parameter estimation - disturbance parameter estimation - uncertain parameter estimation - software tools,"Perera, M.A.S.(1); Lie, B.(1); Pfeiffer, C.F.(1)",2015.0,Journal,"Modeling, Identification and Control",10.4173/mic.2015.1.4,"(1) Telemark Univ. Coll., Porsgrunn, Norway",Norwegian Society of Automatic Control,English,0332-7353,
Inspec,Python's PyQt toolkit,"One of the advantages of using Python is the variety of available GUI libraries. Currently, there are several GUI toolkits in active development, including Tkinter, PyQt/ PyKDE, wxPython, PyGTK/GnomePython, FXPy, PYFLTK, and Pythonwin. Each of these has its strengths and weaknesses. Indeed, as with C or C++, there is nearly always a GUI library perfectly suited to the project in hand. The article examines PyQt, one of the most advanced libraries, and focuses on the innovative signals-and-slots paradigm it offers Python developers.",PyQt toolkit - Python - GUI libraries - GUI toolkits - Tkinter - PyQt - PyKDE - wxPython - PyGTK/GnomePython - FXPy - PYFLTK - Pythonwin - GUI library - signals-and-slots paradigm - Python developers,"Rempt, B.(1)",2001.0,Journal,Dr. Dobb's Journal,,"(1) Tryllian, Netherlands",Miller Freeman,English,1044-789X,
Inspec,Iteration on the Horizon Simulation Framework to Include .NET and Python Scripting,"Modeling and Simulation Is a crucial element of the aerospace engineering design process because it allows designers to thoroughly test their solution before investing In the resources to create it. The Horizon Simulation Framework (HSF) v3.0 is an aerospace modeling and simulation tool that allows the user to verify system level requirements in the early phases of the design process. A low fidelity modal of the system that is created by the user is exhaustively tested within the built-in Day-in-the-Life simulator to provide useful information in the form of failed requirements, system bottle necks and leverage points, and potential schedules of operations. The model can be stood up quickly with Extended Markup Language (XML) input file or can be customly created with Python Scripts that interact with the framework at runtime. The goal of the work presented in this paper is to progress NSF from v2.3 to v3.0 in order to take advantage of current software development technologies and modern software architecting strategies. By updating the codebase from C++ and Lua to C# and Python, previously unreachable constructs became available and a new architecture was achieved. Tho details of the decisions, implementation and benefits of the now framework are discussed within the paper and may be useful to the reader who is designing or re-architecting a simulation framework. The new framework was also compared to the old framework for performance and accuracy and was found to perform similarly if not better in some cases.",Horizon Simulation Framework - iteration - .NET scripting - Python scripting - aerospace engineering design process - HSF v3.0 - aerospace modeling and simulation tool - system level requirement verification - built-in Day-in-the-Life simulator - system bottlenecks - leverage points - operation schedule - Extended Markup Language - XML input file - software development technology - software architecting strategy - codebase update - C++ language - C# language,"Yost, M.(1); Mehiel, E.A.(2)",2017.0,Conference,AIAA Modeling and Simulation Technologies Conference,,"(1) Lockheed Martin Space Systems Co., Littleton, CO, United States; (2) California Polytech. State Univ., San Luis Obispo, CA, United States",AIAA - American Institute of Aeronautics and Astronautics,English,,
Inspec,Programming Language Python for Data Processing,"Geographic information systems belong the group of applications that process spatial data. Some spatial analyses are operated repetitively in the same way for different area or district. Therefore it is useful when the data processing can be run automatically by program extension designed especially for batch data processing. ArcGIS software offers a possibility to design the steps of data processing by data flow diagram in the graphic editor ModelBuilder. In some cases the data flow diagram which is designed in ModelBuilder component is not sufficient for all require tasks. In such cases, it is possible to automatically convert data flow diagram into the Python language and supplement the program code with other program constructions and commands. Some practical examples are presented in this article. All Python scripts were developed as a part of several research projects at Department of Geinformatics at Palacky University in the Czech Republic. This article is a sum of experience with scripting in Python for ArcGIS geoprocessor.",Python programming language - geographic information systems - spatial data - program extension - batch data processing - ArcGIS software - data flow diagram - ModelBuilder graphic editor - program code - Python scripts - ArcGIS geoprocessor,"Dobesova, Z.(1)",2011.0,Conference,2011 International Conference on Electrical and Control Engineering,10.1109/ICECENG.2011.6057428,"(1) Dept. of Geoinf., Palacky Univ. in Olomouc, Olomouc, Czech Republic",IEEE,English,,
Inspec,QuTiP 2: A Python framework for the dynamics of open quantum systems,"We present version 2 of QuTiP, the Quantum Toolbox in Python. Compared to the preceding version [J.R. Johansson, P.D. Nation, F. Nori, Comput. Phys. Commun. 183 (2012) 1760.], we have introduced numerous new features, enhanced performance, and made changes in the Application Programming Interface (API) for improved functionality and consistency within the package, as well as increased compatibility with existing conventions used in other scientific software packages for Python. The most significant new features include efficient solvers for arbitrary time-dependent Hamiltonians and collapse operators, support for the Floquet formalism, and new solvers for Bloch-Redfield and Floquet-Markov master equations. Here we introduce these new features, demonstrate their use, and give a summary of the important backward-incompatible API changes introduced in this version.[All rights reserved Elsevier].",QuTiP 2 - Python framework - open quantum system dynamics - quantum toolbox - application programming interface - API - scientific software packages - arbitrary time-dependent Hamiltonians - collapse operators - Floquet formalism - Bloch-Redfield master equations - Floquet-Markov master equations,"Johansson, J.R.(1); Nation, P.D.(2); Nori, F.(1)",2013.0,Journal,Computer Physics Communications,10.1016/j.cpc.2012.11.019,"(1) Adv. Sci. Inst., RIKEN, Wako, Japan; (2) Dept. of Phys., Korea Univ., Seoul, Korea, Republic of",Elsevier Science B.V.,English,0010-4655,
Inspec,Nmrglue: an open source Python package for the analysis of multidimensional NMR data,"Nmrglue, an open source Python package for working with multidimensional NMR data, is described. When used in combination with other Python scientific libraries, nmrglue provides a highly flexible and robust environment for spectral processing, analysis and visualization and includes a number of common utilities such as linear prediction, peak picking and lineshape fitting. The package also enables existing NMR software programs to be readily tied together, currently facilitating the reading, writing and conversion of data stored in Bruker, Agilent/Varian, NMRPipe, Sparky, SIMPSON, and Rowland NMR Toolkit file formats. In addition to standard applications, the versatility offered by nmrglue makes the package particularly suitable for tasks that include manipulating raw spectrometer data files, automated quantitative analysis of multidimensional NMR spectra with irregular lineshapes such as those frequently encountered in the context of biomacromolecular solid-state NMR, and rapid implementation and development of unconventional data processing methods such as covariance NMR and other non-Fourier approaches. Detailed documentation, install files and source code for nmrglue are freely available at http://nmrglue.com. The source code can be redistributed and modified under the New BSD license.",Nmrglue - open source Python package - multidimensional NMR data analysis - Python scientific libraries - spectral processing - linear prediction - peak picking - line shape fitting - NMR software programs - Rowland NMR toolkit file formats - Bruker NMR toolkit file formats - Agilent-Varian NMR toolkit file formats - NMRPipe NMR toolkit file formats - Sparky NMR toolkit file formats - SIMPSON NMR toolkit file formats - raw spectrometer data file manipulation - biomacromolecular solid-state NMR - multidimensional NMR spectra - automated quantitative analysis - unconventional data processing methods - covariance NMR - nonFourier approaches - source code - new BSD license - data visualization,"Helmus, J.J.(1); Jaroniec, C.P.(1)",2013.0,Journal,Journal of Biomolecular NMR,10.1007/s10858-013-9718-x,"(1) Dept. of Chem. & Biochem., Ohio State Univ., Columbus, OH, United States",Springer Netherlands,English,0925-2738,
Inspec,Python and finite elements,"Many science and engineering problems can be reduced to the form of partial differential equations it (PDEs), among which elliptic equations play an important role. Problems that can be described by elliptic PDEs include the distribution of electric potential in a dielectric, the propagation of stationary waves, the incompressible flow around a wing, vibrations in a membrane, and the problem of heat conduction, to name just a few. In the article, I present a finite element (FE) package called ELLIPT2D designed to solve elliptic equations in two dimensions. While most FE programs are written in C or Fortran, ELLIPT2D is implemented in Python.",Python - interpreted language - science problems - engineering problems - partial differential equations - elliptic equations - ELLIPT2D,"Pletzer, A.(1)",2002.0,Journal,Dr. Dobb's Journal,,"(1) Plasma Phys. Lab., Princeton Univ., Princeton, NJ, United States",CMP Media LLC,English,1044-789X,
Inspec,How Do Developers Fix Cross-Project Correlated Bugs? A Case Study on the GitHub Scientific Python Ecosystem,"GitHub, a popular social-software-development platform, has fostered a variety of software ecosystems where projects depend on one another and practitioners interact with each other. Projects within an ecosystem often have complex inter-dependencies that impose new challenges in bug reporting and fixing. In this paper, we conduct an empirical study on cross-project correlated bugs, i.e., causally related bugs reported to different projects, focusing on two aspects: 1) how developers track the root causes across projects, and 2) how the downstream developers coordinate to deal with upstream bugs. Through manual inspection of bug reports collected from the scientific Python ecosystem and an online survey with developers, this study reveals the common practices of developers and the various factors in fixing cross-project bugs. These findings provide implications for future software bug analysis in the scope of ecosystem, as well as shed light on the requirements of issue trackers for such bugs.",cross-project correlated bugs - GitHub scientific Python ecosystem - upstream bugs - bug reports,Wanwangying Ma(1); Lin Chen(1); Xiangyu Zhang(2); Yuming Zhou(1); Baowen Xu(1),2017.0,Conference,2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). Proceedings,10.1109/ICSE.2017.42,"(1) State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China; (2) Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, United States",IEEE Computer Society,English,,
Inspec,Climate analysis routines using Python,"Python is an interactive and powerful programming language which allows the fast development of applications. There exists a set of array-oriented extensions (Numerical Python) that allow numerical operations to be performed using C native code, with much better performance than the Python interpreter. Pyclimate, a set of subroutines built to be used in climate variability analysis is presented. They perform some of the most usual tasks during climate variability analysis. All of them are written using the numerical extensions to Python, with high numerical performance in mind. However, the simplicity of the original Python language remains in the programs built using these routines and other complementary packages. This simplicity allows easy data analysis of multivariate datasets from the interactive Python interpreter.",climate analysis routines - Python programming language - array-oriented extensions - Numerical Python - C native code - Pyclimate subroutines - climate variability analysis - multivariate datasets - interactive Python interpreter - data analysis,"Saenz, J.(1); Zubillaga, J.",2000.0,Conference,Development and Application of Computer Techniques to Environmental Studies VIII. Eighth International Conference. ENVIROSOFT 2000,,"(1) Dept. de Fis. Apl. II, Pais Vasco Univ., Bilbao, Spain",WIT Press,English,,1-85312-819-8
Inspec,And now for something completely different? [Python language],"The author discusses the obscurity of the Python language. Python has attracted some very serious interest in the way of interfaces and support libraries. It has come a long way from its roots as a scripting language for the Amoeba operating system. Python has SQL interfaces, CGI facilities, BSD-style sockets, interfaces to different GUI toolkits and APIs, and the ability to do client-server work with shared objects (ILU and CORBA).",Python language - software libraries - scripting language - Amoeba operating system - SQL interfaces - CGI facilities - BSD-style sockets - GUI toolkits - API - client-server system - shared objects - ILU - CORBA - graphical user interface,"Orlowski, A.",1997.0,Journal,EXE,,,Centaur Communications,English,0268-6872,
Inspec,Troppo - A Python Framework for the Reconstruction of Context-Specific Metabolic Models,"The surge in high-throughput technology availability for molecular biology has enabled the development of powerful predictive tools for use in many applications, including (but not limited to) the diagnosis and treatment of human diseases such as cancer. Genome-scale metabolic models have shown some promise in clearing a path towards precise and personalized medicine, although some challenges still persist. The integration of omics data and subsequent creation of context-specific models for specific cells/tissues still poses a significant hurdle, and most current tools for this purpose have been implemented using proprietary software. Here, we present a new software tool developed in Python, troppo - Tissue-specific RecOnstruction and Phenotype Prediction using Omics data, implementing a large variety of context-specific reconstruction algorithms. Our framework and workflow are modular, which facilitates the development of newer algorithms or omics data sources.",context-specific metabolic models - technology availability - molecular biology - predictive tools - human diseases - genome-scale metabolic models - personalized medicine - context-specific models - proprietary software - software tool - Tissue-specific RecOnstruction - Phenotype Prediction - context-specific reconstruction algorithms - troppo - Python framework - omics data sources,"Ferreira, J.(1); Vieira, V.(1); Gomes, J.(1); Correia, S.(1); Rocha, M.(1)",2020.0,Conference,"Practical Applications of Computational Biology and Bioinformatics, 13th International Conference. Advances in Intelligent Systems and Computing (1005)",10.1007/978-3-030-23873-5_18,"(1) Centre of Biol. Eng., Univ. of Minho, Braga, Portugal",Springer International Publishing,English,,
Inspec,"PythonTeX: reproducible documents with LaTeX, Python, and more","PythonTeX is a LaTeX package that allows Python code in LaTeX documents to be executed and provides access to the output. This makes possible reproducible documents that combine results with the code required to generate them. Calculations and figures may be next to the code that created them. Since code is adjacent to its output in the document, editing may be more efficient. Since code output may be accessed programmatically in the document, copy-and-paste errors are avoided and output is always guaranteed to be in sync with the code that generated it. This paper provides an introduction to PythonTeX and an overview of major features, including performance optimizations, debugging tools, and dependency tracking. Several complete examples are presented. Finally, advanced features are summarized. Though PythonTeX was designed for Python, it may be extended to support additional languages; support for the Ruby and Julia languages is already included. PythonTeX contains a utility for converting documents into plain LaTeX, suitable for format conversion, sharing, and journal submission.",journal submission - format conversion - Ruby language - Julia language - dependency tracking - debugging tools - performance optimizations - LaTeX documents - Python code - PythonTeX,"Poore, G.M.(1)",2015.0,Journal,Computational Science and Discovery,10.1088/1749-4699/8/1/014010,"(1) Dept. of Phys., Union Univ., Jackson, TN, United States",IOP Publishing,English,1749-4680,
Inspec,PyCDT: a Python toolkit for modeling point defects in semiconductors and insulators [arXiv],"Point defects have a strong impact on the performance of semiconductor and insulator materials used in technological applications, spanning microelectronics to energy conversion and storage. The nature of the dominant defect types, how they vary with processing conditions, and their impact on materials properties are central aspects that determine the performance of a material in a certain application. This information is, however, difficult to access directly from experimental measurements. Consequently, computational methods, based on electronic density functional theory (DFT), have found widespread use in the calculation of point-defect properties. Here we have developed the Python Charged Defect Toolkit (PyCDT) to expedite the setup and post-processing of defect calculations with widely used DFT software. PyCDT has a user-friendly command-line interface and provides a direct interface with the Materials Project database. This allows for setting up many charged defect calculations for any material of interest, as well as post-processing and applying state-of-the-art electrostatic correction terms. Our paper serves as a documentation for PyCDT, and demonstrates its use in an application to the well-studied GaAs compound semiconductor. We anticipate that the PyCDT code will be useful as a framework for undertaking readily reproducible calculations of charged point-defect properties, and that it will provide a foundation for automated, high-throughput calculations.",insulators - Python charged defect toolkit - DFT software - electronic density functional theory - user-friendly command-line interface - material project database - electrostatic correction terms - compound semiconductor - PyCDT code - charged point-defect properties - GaAs,"Broberg, D.(1); Medasani, B.(2); Zimmermann, N.(2); Canning, A.(2); Haranczyk, M.(2); Asta, M.(1); Hautier, G.(3)",2016.0,arXiv,arXiv,,"(1) Dept. of Mater. Sci. & Eng., Univ. of California, Berkeley, Berkeley, CA, United States; (2) Comput. Res. Div., Lawrence Berkeley Nat. Lab., Berkeley, CA, United States; (3) Inst. of Condensed Matter & Nanosci., Univ. Catholique de Louvain, Louvain-la-Neuve, Belgium",arXiv,English,,
Inspec,High-Performance Python-C++ Bindings with PyPy and Cling,"The use of Python as a high level productivity language on top of high performance libraries written in C++ requires efficient, highly functional, and easy-to-use cross-language bindings. C++ was standardized in 1998 and up until 2011 it saw only one minor revision. Since then, the pace of revisions has increased considerably, with a lot of improvements made to expressing semantic intent in interface definitions. For automatic Python-C++ bindings generators it is both the worst of times, as parsers need to keep up, and the best of times, as important information such as object ownership and thread safety can now be expressed. We present cppyy, which uses Cling, the Clang/LLVM-based C++ interpreter, to automatically generate Python-C++ bindings for PyPy. Cling provides dynamic access to a modern C++ parser and PyPy brings a full toolbox of dynamic optimizations for high performance. The use of Cling for parsing, provides up-to-date C++ support now and in the foreseeable future. We show that with PyPy the overhead of calls to C++ functions from Python can be reduced by an order of magnitude compared to the equivalent in CPython, making it sufficiently low to be unmeasurable for all but the shortest C++ functions. Similarly, access to data in C++ is reduced by two orders of magnitude over access from CPython. Our approach requires no intermediate language and more pythonistic presentations of the C++ libraries can be written in Python itself, with little performance cost due to inlining by PyPy. This allows for future dynamic optimizations to be fully transparent.",private Boolean query processing - encrypted data - data outsourcing - privacy risks - data encryption - data confidentiality - support complex queries - security requirements - privacy-preserving query processing framework - Bloom filter - additive homomorphic encryption - query evaluation - PyPy - Cling - high level productivity language - high performance libraries - Python-C++ bindings generators - thread safety - C++ parser - dynamic optimizations - CPython - C++ functions - C++ libraries,"Lavrijsen, W.T.L.P.(1); Dutta, A.(2)",2016.0,Conference,2016 6th Workshop on Python for High-Performance and Scientific Computing (PyHPC),10.1109/PyHPC.2016.008,"(1) Lawrence Berkeley Nat. Lab., Berkeley, CA, United States; (2) Nanyang Technol. Univ., Singapore, Singapore",IEEE,English,,
Inspec,Toolbox of image processing using the Python language,"This work consists in the study, development and implementation of a toolbox for image processing using the Python language and the numerical Python package. This set has ""open source"" distribution and is adequate for multidimensional mathematical processing. Python is a modern and well projected language, interpreted, ""very-high-level"", object oriented and extremely portable, apart from being suitable for rapid application development (RAD). The system is generated using the methodology of the Adesso project for construction of scientific software. This environment is useful in education, research and development of final applications.",Python language - image processing toolbox - numerical Python package - open source distribution - mathematical processing - very-high-level language - rapid application development - Adesso project,"Silva, A.G.(1); Lotufo, R.D.A.(1); Machado, R.C.; Saude, A.V.",2003.0,Conference,Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429),,"(1) DCA-FEEC, Campinas Univ., Brazil",IEEE,English,,0-7803-7750-8
Inspec,State management for distributed Python applications,"We present a novel state management mechanism that can be used to capture the complete execution state of distributed Python applications. This mechanism can serve as the foundation for a variety of dependability strategies including checkpointing, replication, and migration. Python is increasingly used for rapid prototyping parallel pro grams and, in some cases, used for high-performance application development using libraries such as NumPy. Building on Stackless Python and the River parallel and distributed programming environment, we have developed mechanisms for state capture at the language level. Our approach allows for migration and checkpointing of applications in heterogeneous environments. In addition, we allow for preemptive state capture so that programmers need not introduce explicit snapshot requests. Our mechanism can be extended to support application or domain-specific state capture. To our knowledge, this is the first general checkpointing scheme for Python. We describe our system, the implementation, and give some initial performance figures.",state management - distributed Python applications - dependability strategy - replication - rapid prototyping - NumPy - Stackless Python - River parallel programming - distributed programming environment - application migration - application checkpointing - heterogeneous environment - preemptive state capture - domain-specific state capture,"Benson, G.D.(1)",2008.0,Conference,2008 IEEE International Parallel & Distributed Processing Symposium,,"(1) Dept. of Comput. Sci., Univ. of San Francisco, San Francisco, CA, United States",IEEE,English,,
Inspec,Genetic algorithm implementation in Python,"This paper deals with genetic algorithm implementation in Python. Genetic algorithm is a probabilistic search algorithm based on the mechanics of natural selection and natural genetics. In genetic algorithms, a solution is represented by a list or a string. List or string processing in Python is more productive than in C/C++/Java. Genetic algorithms implementation in Python is quick and easy. In this paper, we introduce genetic algorithm implementation methods in Python. And we discuss various tools for speeding up Python programs.",genetic algorithm - Python - probabilistic search algorithm - natural selection - natural genetics - list processing - string processing - C language - C++ language - Java language - program tool,Wonjae Lee(1); Hak-Young Kim(1),2005.0,Conference,Proceedings. Fourth Annual ACIS International Conference on Computer and Information Science,,"(1) Electron. & Telecommun. Res. Inst., Korea, Republic of",IEEE Computer Society,English,,0-7695-2296-3
Inspec,TRAPping Modelica with Python,"This paper introduces TRAP, a small but powerful compiler development system based on the object-oriented, dynamic language Python. Employing a very high level language as a compiler tool's base language reduces the need for additional tool support and importing library functionality to a minimum. Python in particular has the additional advantage of being a powerful and already quite popular general-purpose component integration framework, which can be utilized both for incorporating subcomponents and for embedding the compiler developed into a larger system. Exploiting these strengths, TRAP enables rapid prototyping and development of compilers-in particular, translators for medium-complexity special purpose languages-on a very high level of abstraction.",TRAP - compiler development system - object-oriented dynamic language - Python - high level language - compiler tool base language - component integration framework - subcomponent incorporation - compiler embedding - rapid prototyping - translators - medium-complexity special purpose languages - abstraction - Modelica,"Ernst, T.(1)",1999.0,Conference,"Compiler Construction. 8th International Conference, CC'99. Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS'99. Proceedings",,"(1) GMD First Res. Inst. for Comput. Archit. & Software Technol., Berlin, Germany",Springer-Verlag,English,,3-540-65717-7
Inspec,PVLIB Python 2015,"We describe improvements to the open source PVLIB-Python modeling package. PVLIB-Python provides most of the functionality of its parent PVLIB-MATLAB package and now follows standard Python design patterns and conventions, has improved unit test coverage, and is installable. PVLIBPython is hosted on GitHub.com and co-developed by GitHub contributors. We also describe a roadmap for the future of the PVLIB-Python package.",open source PVLIB-Python modeling package - standard Python design patterns - GitHub.com - GitHub contributor,"Holmgren, W.F.(1); Andrews, R.W.(2); Lorenzo, A.T.(3); Stein, J.S.(4)",2015.0,Conference,2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings,10.1109/PVSC.2015.7356005,"(1) Dept. of Atmos. Sci., Univ. of Arizona, Tucson, AZ, United States; (2) Heliolytics, Toronto, ON, Canada; (3) Coll. of Opt. Sci., Univ. of Arizona, Tucson, AZ, United States; (4) Sandia Nat. Labs., Albuquerque, NM, United States",IEEE,English,,
Inspec,Python tools for reproducible research on hyperbolic problems,Reproducible research in computational science is only possible if the computer codes used to generate published results are distributed and/or archived in a form that can later be used to regenerate the results and can be examined to determine details of the method used. The author discusses some difficulties in achieving this goal and surveys a set of Python tools for facilitating reproducible research on finite volume methods for hyperbolic conservation laws using the Clawpack software.,Python tools - hyperbolic problems - computational science - computer codes - finite volume methods,"LeVeque, R.J.(1)",2009.0,Journal,Computing in Science & Engineering,10.1109/MCSE.2009.13,"(1) Univ. of Washington, Seattle, WA, United States",IEEE,English,1521-9615,
Inspec,Lowering the learning curve for declarative programming: a python API for the IDP system,"Programmers may be hesitant to use declarative systems, because of the associated learning curve. In this paper, we present an API that integrates the IDP Knowledge Base system into the Python programming language. IDP is a state-of-the-art logical system, which uses SAT, SMT, Logic Programming and Answer Set Programming technology. Python is currently one of the most widely used (teaching) languages for programming. The first goal of our API is to allow a Python programmer to use the declarative power of IDP, without needing to learn any new syntax or semantics. The second goal is allow IDP to be added to/removed from an existing code base with minimal changes.",declarative programming - Python API - IDP knowledge base system - Python programming language - SAT - SMT - logic programming - answer set programming technology - Python programmer,"Vennekens, J.(1)",2017.0,Conference,"Practical Aspects of Declarative Languages. 19th International Symposium, PADL 2017. Proceedings: LNCS 10137",10.1007/978-3-319-51676-9_6,"(1) Dept. Computerscience @ Technol. Campus De Nayer, KU Leuven, Sint-katelijne-waver, Belgium",Springer International Publishing,English,,
Inspec,pyGlobus: a Python interface to Globus Toolkit™,"Developing high-performance, problem-solving environments/applications that allow scientists to easily harness the power of the emerging national-scale 'Grid' infrastructure is currently a difficult task. Although many of the necessary low-level services, e.g. security, resource discovery, remote access to computation/data resource, etc., are available, it can be a challenge to rapidly integrate them into a new application. To address this difficulty we have begun the development of a Python-based high-level interface to the Grid services provided by the Globus Toolkit. In this paper we will explain why rapid application development using Grid services is important, look briefly at a motivating example, and finally look at the design and implementation of the pyGlobus package.",pyGlobus - Python interface - Globus Toolkit™ - high-level interface - Grid services,"Jackson, K.R.(1)",2002.0,Journal,Concurrency and Computation Practice & Experience,10.1002/cpe.683,"(1) Lawrence Berkeley Nat. Lab., Berkeley, CA, United States",Wiley,English,1532-0626,
Inspec,A Python library for provenance recording and querying,"In many application domains the provenance of data plays an important role. It is often required to get store detailed information of the underlying processes that led to the data (e.g., results of numerical simulations) for the purpose of documentation or checking the process for compliance to applicable regulations. Especially in science and engineering more and more applications are being developed in Python, which is used either for development of the whole application or as a glue language for coordinating codes written in other programming languages. To easily integrate provenance recording into applications developed in Python, a provenance client library with a suitable Python API is useful. In this paper we present such a Python client library for recording and querying provenance information. We show an exemplary application, explain the overall architecture of the library, and give some details on the technologies used for the implementation.",Python library - provenance recording - provenance querying - API - exemplary application - grid computing,"Bochner, C.(1); Gude, R.(1); Schreiber, A.(1)",2008.0,Conference,"Provenance and Annotation of Data and Processes. Second International Provenance and Annotation Workshop, IPAW 2008. Revised Selected Papers",10.1007/978-3-540-89965-5_24,"(1) Simulation & Software Technol., German Aerosp. Center, Cologne, Germany",Springer-Verlag,English,,
Inspec,Migrating legacy Fortran to Python while retaining Fortran-level performance through transpilation and type hints,"We propose a method of accelerating Python code by just-in-time compilation leveraging type hints mechanism introduced in Python 3.5. In our approach performance-critical kernels are expected to be written as if Python was a strictly typed language, however without the need to extend Python syntax. This approach can be applied to any Python application, however we focus on a special case when legacy Fortran applications are automatically translated into Python for easier maintenance. We developed a framework implementing two-way transpilation and achieved performance equivalent to that of Python manually translated to Fortran, and better than using other currently available JIT alternatives (up to 5x times faster than Numba in some experiments).",legacy FORTRAN migration - FORTRAN-level performance - just-in-time compilation - type hints mechanism - Python 3.5 - performance-critical kernels - Python syntax - two-way transpilation,"Bysiek, M.(1); Drozd, A.(1); Matsuoka, S.(1)",2016.0,Conference,2016 6th Workshop on Python for High-Performance and Scientific Computing (PyHPC),10.1109/PyHPC.2016.006,"(1) Tokyo Inst. of Technol., Tokyo, Japan",IEEE,English,,
Inspec,Stage: Python with actors,"Programmers hoping to exploit multi-core processors must split their applications into threads suitable for independent, concurrent execution. The lock-based concurrency of many existing languages is clumsy and error prone - a barrier to writing fast and correct concurrent code. The Actor model exudes concurrency - each entity in the model (an Actor) executes concurrently. Interaction is restricted to message passing which prevents many of the errors associated with shared mutable state and locking, the common alternative. By favouring message passing over method calling the Actor model makes distribution straightforward. Early Actor-based languages enjoyed only moderate success, probably because they were before their time. More recent Actor languages have enjoyed greater success, the most successful being ERLANG, but the language is functional; a paradigm unfamiliar to many programmers. There is a need for a language that presents a familiar and fast encoding of the Actor model. In this paper we present STAGE, our mobile Actor language based on PYTHON.",Python programming language - multicore processor - independent concurrent execution - lock-based concurrency - actor model - message passing - actor-based language - ERLANG - STAGE mobile actor language,"Ayres, J.(1); Eisenbach, S.(1)",2009.0,Conference,2009 ICSE Workshop on Multicore Software Engineering (IWMSE 2009),10.1109/IWMSE.2009.5071380,"(1) Dept. of Comput., Imperial Coll. London, London, United Kingdom",IEEE,English,,
Inspec,Fermipy: An open-source Python package for analysis of Fermi-LAT Data [arXiv],"Fermipy is an open-source python framework that facilitates analysis of data collected by the Fermi Large Area Telescope (LAT). Fermipy is built on the Fermi Science Tools, the publicly available software suite provided by NASA for the LAT mission. Fermipy provides a high-level interface for analyzing LAT data in a simple and reproducible way. The current feature set includes methods for extracting spectral energy distributions and lightcurves, generating test statistic maps, finding new source candidates, and fitting source position and extension. Fermipy leverages functionality from other scientific python packages including NumPy, SciPy, Matplotlib, and Astropy and is organized as a community-developed package following an open-source development model. We review the current functionality of Fermipy and plans for future development.",Fermipy - open-source Python framework - Fermi-LAT data - Fermi large area telescope - high-level interface - spectral energy distributions - NumPy - SciPy - Matplotlib - Astropy - open-source development model,"Wood, M.; Caputo, R.; Charles, E.; Di Mauro, M.; Magill, J.",2017.0,arXiv,arXiv,,,arXiv,English,,
Inspec,Python bindings for libcloudph++ [arXiv],This technical note introduces the Python bindings for libcloudph++. The libcloudph++ is a C++ library of algorithms for representing atmospheric cloud microphysics in numerical models. The bindings expose the complete functionality of the library to the Python users. The bindings are implemented using the Boost.Python C++ library and use NumPy arrays. This note includes listings with Python scripts exemplifying the use of selected library components. An example solution for using the Python bindings to access libcloudph++ from Fortran is presented.,Python bindings - libcloudph++ - atmospheric cloud microphysics - numerical models - Boost.Python C++ library - NumPy arrays - Python scripts - Fortran,"Jarecka, D.(1); Arabas, S.(1); Del Vento, D.(2)",2015.0,arXiv,arXiv,,"(1) Inst. of Geophys., Univ. of Warsaw, Warsaw, Poland; (2) Nat. Center for Atmos. Res., Boulder, CO, United States",arXiv,English,,
Inspec,MGtoolkit: A python package for implementing metagraphs,In this paper we present MGtoolkit : an open-source Python package for implementing metagraphs - a first of its kind. Metagraphs are commonly used to specify and analyse business and computer-network policies alike. MGtoolkit can help verify such policies and promotes learning and experimentation with metagraphs. The package currently provides purely textual output for visualising metagraphs and their analysis results. [All rights reserved Elsevier].,MGtoolkit - metagraphs - open-source Python package - business - computer-network policies,"Ranathunga, D.(1); Nguyen, H.(1); Roughan, M.(2)",2017.0,Journal,SoftwareX,10.1016/j.softx.2017.04.001,"(1) Teletraffic Res. Centre, Univ. of Adelaide, Adelaide, SA, Australia; (2) ARC Centre of Excellence for Math. & Stat. Frontiers, Univ. of Adelaide, Adelaide, SA, Australia",Elsevier B.V.,English,2352-7110,
Inspec,Pyverilog: a python-based hardware design processing toolkit for verilog HDL,"Verilog HDL is the most-used hardware design language for FPGAs. In this paper, we introduce Pyverilog, an open-source toolkit for RTL design analysis and code generation of Verilog HDL. Pyverilog offers efficient functionality to implement a CAD tool that treats Verilog HDL with small amount of effort. Pyverilog consists of four key libraries: (1) parser, (2) dataflow analyzer, (3) control-flow analyzer, and (4) Verilog code generator. We show a case study that uses Pyverilog as the fundamental back-end library. We have developed flipSyrup, a framework for efficient rapid prototyping by virtually enlarging FPGA resources. By using Pyverilog, the framework is implemented with small amount of additional codes; it is implemented in about 2700 lines of code in Python.",Pyverilog - Python-based hardware design processing toolkit - Verilog HDL - hardware design language - FPGA - open-source toolkit - RTL design analysis - code generation - CAD tool - parser - dataflow analyzer - control-flow analyzer - Verilog code generator - back-end library - flipSyrup - FPGA resources,"Takamaeda-Yamazaki, S.(1)",2015.0,Conference,"Applied Reconfigurable Computing. 11th International Symposium, ARC 2015. Proceedings: LNCS 9040",10.1007/978-3-319-16214-0_42,"(1) Nara Inst. of Sci. & Technol., Ikoma, Japan",Springer International Publishing,English,,
Inspec,PVLIB: open source photovoltaic performance modeling functions for matlab and python,"PVLIB is a set of open source modeling functions that allow users to simulate most aspects of PV system performance. The functions, in Matlab and Python, are freely available under a BSD 3 clause open source license. The Matlab version is maintained by Sandia and is available on the PV Performance Modeling Collaborative (PVPMC) website (pvpmc.sandia.gov). The Python version is available on GitHub with packages easily installable through conda and pip. New functions were released on the Matlab version 1.3 in January 2016 and are actively being ported to Python.",PVLIB - open source modeling functions - PV system performance - open source photovoltaic performance modeling,"Stein, J.S.(1); Holmgren, W.F.(2); Forbess, J.(3); Hansen, C.W.(1)",2017.0,Conference,2017 IEEE 44th Photovoltaic Specialist Conference (PVSC),10.1109/PVSC.2017.8366805,"(1) Sandia Nat. Labs., Albuquerque, NM, United States; (2) Dept. of Atmos. Sci., Univ. of Arizona, Tucson, AZ, United States; (3) Sunshine Analytics, Oakland, CA, United States",IEEE,English,,
Inspec,An intuitive Python interface for Bioconductor libraries demonstrates the utility of language translators,"Background: Computer languages can be domain-related, and in the case of multidisciplinary projects, knowledge of several languages will be needed in order to quickly implements ideas. Moreover, each computer language has relative strong points, making some languages better suited than others for a given task to be implemented. The Bioconductor project, based on the R language, has become a reference for the numerical processing and statistical analysis of data coming from high-throughput biological assays, providing a rich selection of methods and algorithms to the research community. At the same time, Python has matured as a rich and reliable language for the agile development of prototypes or final implementations, as well as for handling large data sets. Results: The data structures and functions from Bioconductor can be exposed to Python as a regular library. This allows a fully transparent and native use of Bioconductor from Python, without one having to know the R language and with only a small community of translators required to know both. To demonstrate this, we have implemented such Python representations for key infrastructure packages in Bioconductor, letting a Python programmer handle annotation data, microarray data, and next-generation sequencing data. Conclusions: Bioconductor is now not solely reserved to R users. Building a Python application using Bioconductor functionality can be done just like if Bioconductor was a Python package. Moreover, similar principles can be applied to other languages and libraries. Our Python package is available at: http://pypi.python.org/pypi/rpy2bioconductor-extensions/.",intuitive Python interface - Bioconductor libraries - language translators - computer languages - multidisciplinary projects - R language - numerical processing - statistical analysis - high-throughput biological assays - Python programmer - annotation data - microarray data - next-generation sequencing data,"Gautier, L.(1)",2010.0,Journal,BMC Bioinformatics,10.1186/1471-2105-11-S12-S11,"(1) Dept. of Syst. Biol., Tech. Univ. of Denmark, Lyngby, Denmark",BioMed Central Ltd.,English,1471-2105,
Inspec,How Do Python Framework APIs Evolve? An Exploratory Study,"Python is a popular dynamic programming language. In recent years, many frameworks implemented in Python have been widely used for data science and web development. Similar to frameworks in other languages, the APIs provided by Python frameworks often evolve, which would inevitably induce compatibility issues in client applications. While existing work has studied the evolution of frameworks in static programming languages such as Java, little is known on how Python framework APIs evolve and the characteristics of the compatibility issues induced by such evolution. To bridge this gap, we take a first look at the evolution of Python framework APIs and the resulting compatibility issues in client applications. We analyzed 288 releases of six popular Python frameworks from three different domains and 5,538 open-source projects built on these frameworks. We investigated the evolution patterns of Python framework APIs and found that they largely differ from those of Java framework APIs. We also investigated the compatibility issues in client applications and identified common strategies that developers adopt to fix these issues. Based on the empirical findings, we designed and implemented a tool, PYCOMPAT, to automatically detect compatibility issues caused by misusing evolved framework APIs in Python applications. Experiments on 10 real-world projects show that our tool can effectively detect compatibility issues of developers' concern.",static programming languages - Python framework - client applications - Java framework APIs - dynamic programming language - open-source projects,Zhaoxu Zhang(1); Hengcheng Zhu(1); Ming Wen(2); Yida Tao(3); Yepang Liu(1); Yingfei Xiong(4),2020.0,Conference,"2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). Proceedings",10.1109/SANER48275.2020.9054800,"(1) Dept. of Comput. Sci. & Eng., Southern Univ. of Sci. & Technol., Shenzhen, China; (2) Sch. of Cyber Sci. & Eng., Huazhong Univ. of Sci. & Tech., Wuhan, China; (3) Coll. of Comp. Sci. & Soft. Eng., Shenzhen Univ., Shenzhen, China; (4) Dept. of Comput. Sci. & Technol., Peking Univ., Beijing, China",IEEE,English,,
Inspec,Calculations of lattice vibrational mode lifetimes using Jazz: a Python wrapper for LAMMPS,"Jazz is a new python wrapper for LAMMPS [1], implemented to calculate the lifetimes of vibrational normal modes based on forces as calculated for any interatomic potential available in that package. The anharmonic character of the normal modes is analyzed via the Monte Carlo-based moments approximation as is described in Gao and Daw [2]. It is distributed as open-source software and can be downloaded from the website http://jazz.sourceforge.net/.",lattice vibrational mode lifetimes - Jazz python wrapper - LAMMPS - vibrational normal modes - interatomic potential - software package - anharmonic character - Monte Carlo-based moments approximation - open-source software - website,"Gao, Y.(1); Wang, H.(1); Daw, M.S.(1)",2015.0,Journal,Modelling and Simulation in Materials Science and Engineering,10.1088/0965-0393/23/4/045002,"(1) Dept. of Phys. & Astron., Clemson Univ., Clemson, SC, United States",IOP Publishing,English,0965-0393,
Inspec,CoAPthon: Easy development of CoAP-based IoT applications with Python,"The Internet of Things (IoT) vision foresees billions of devices seamlessly integrated into information systems. In this context, the Constrained Application Protocol (CoAP) has been defined as a technology enabler to allow applications to interact with physical objects. In this work we present CoAPthon, an open-source Python-based CoAP library, which aims at simplifying the development of CoAP-enabled IoT applications. The library offers software developers a simple and easy-to-use programming interface to exploit CoAP as a communication protocol for rapid prototyping and deployment of IoT systems. The CoAPthon library is fully compliant with the CoAP RFC and implements in addition popular extensions such as the block-wise transfer and resource observing.",CoAPthon library - IoT - Internet of Things - constrained application protocol - open-source Python - CoAP RFC - block-wise transfer - resource observing,"Tanganelli, G.(1); Vallati, C.(1); Mingozzi, E.(1)",2015.0,Conference,2015 IEEE 2nd World Forum on Internet of Things (WF-IoT),10.1109/WF-IoT.2015.7389028,"(1) Dip. Ing. dell'Inf., Univ. of Pisa, Pisa, Italy",IEEE,English,,
Inspec,Data Poisoning: Lightweight Soft Fault Injection for Python [arXiv],"This paper introduces and explores the idea of data poisoning, a light-weight peer-architecture technique to inject faults into Python programs. This method requires very small modification to the original program, which facilitates evaluation of sensitivity of systems that are prototyped or modeled in Python. We propose different fault scenarios that can be injected to programs using data poisoning. We use Dijkstra's Self Stabilizing Ring Algorithm to illustrate the approach.",data poisoning - lightweight soft fault injection - light-weight peer-architecture - Python programs - systems sensitivity - data poisoning - Dijkstra self stabilizing ring algorithm,"Alipour, M.A.; Groce, A.",2016.0,arXiv,arXiv,,,arXiv,English,,
Inspec,lPy4Syn: python for synchrotrons,"In this report, Py4Syn, an open-source Python-based library for data acquisition, device manipulation, scan routines and other helper functions, is presented. Driven by easy-to-use and scalability ideals, Py4Syn offers control system agnostic solution and high customization level for scans and data output, covering distinct techniques and facilities. Here, most of the library functionalities are described, examples of use are shown and ideas for future implementations are presented.",lPy4Syn - synchrotrons - open-source Python-based library - data acquisition - device manipulation - scan routines - library functionalities,"Slepicka, H.H.(1); Canova, H.F.(1); Beniz, D.B.(1); Piton, J.R.(1)",2015.0,Journal,Journal of Synchrotron Radiation,10.1107/S1600577515013715,"(1) Brazilian Synchrotron Light Lab., CNPEM, Campinas, Brazil",IUCr - International Union of Crystallography,English,0909-0495,
Inspec,Inflationary Constant Factors and why Python is Faster Than C++ [arXiv],"Constant-factor differences are frequently ignored when analyzing the complexity of algorithms and implementations, as they appear to be insignificant in practice In this paper, we demonstrate that this assumption can in fact have far more profound implications on time complexity than is obvious at first glance, and that a poor consideration of trade-offs can result in \textit{polynomially} slower algorithms whose roots can be deeply and fundamentally ingrained into a programming language itself While the general observation may not be novel from a theoretical standpoint, it is rarely (if ever) presented in traditional computer science curricula or other settings, and appears to be far from common knowledge in practical software engineering We thus hope bring awareness to this issue and urge careful consideration of significant trade-offs that can result from trivial decisions made while programming.",time complexity - programming language - general observation - theoretical standpoint - traditional computer science curricula - practical software engineering - significant trade-offs - inflationary constant factors - python - constant-factor differences - profound implications,"Niknami, M.(1)",2019.0,arXiv,arXiv,,"(1) Univ. of California, Berkeley, Berkeley, CA, United States",arXiv,English,,
Inspec,CoastSat: A Google Earth Engine-enabled Python toolkit to extract shorelines from publicly available satellite imagery,"CoastSat is an open-source software toolkit written in Python that enables the user to obtain time-series of shoreline position at any sandy coastline worldwide from 30+ years (and growing) of publicly available satellite imagery. The toolkit exploits the capabilities of Google Earth Engine to efficiently retrieve Landsat and Sentinel-2 images cropped to any user-defined region of interest. The resulting images are pre-processed to remove cloudy pixels and enhance spatial resolution, before applying a robust and generic shoreline detection algorithm. This novel shoreline detection technique combines a supervised image classification and a sub-pixel resolution border segmentation to map the position of the shoreline with an accuracy of ~10 m. The purpose of CoastSat is to provide coastal managers, engineers and scientists a user-friendly and practical toolkit to monitor and explore their coastlines. The software is freely-available on GitHub (https://github.com/kvos/CoastSat) and is accompanied by guided examples (Jupyter Notebook) plus step-by-step README documentation. [All rights reserved Elsevier].",CoastSat - Google Earth Engine-enabled Python toolkit - publicly available satellite imagery - open-source software toolkit - shoreline position - sandy coastline worldwide - Sentinel-2 images - cloudy pixels - spatial resolution - robust shoreline detection algorithm - generic shoreline detection algorithm - supervised image classification - sub-pixel resolution border segmentation - shoreline detection technique,"Vos, K.(1); Splinter, K.D.(1); Harley, M.D.(1); Simmons, J.A.(1); Turner, I.L.(1)",2019.0,Journal,Environmental Modelling & Software,10.1016/j.envsoft.2019.104528,"(1) Water Res. Lab., UNSW Sydney, Manly Vale, NSW, Australia",Elsevier B.V.,English,1364-8152,
Inspec,Exploring fitness and edit distance of mutated python programs,"Genetic Improvement (GI) is the process of using computational search techniques to improve existing software e.g. in terms of execution time, power consumption or correctness. As in most heuristic search algorithms, the search is guided by fitness with GI searching the space of program variants of the original software. The relationship between the program space and fitness is seldom simple and often quite difficult to analyse. This paper makes a preliminary analysis of GI's fitness distance measure on program repair with three small Python programs. Each program undergoes incremental mutations while the change in fitness as measured by proportion of tests passed is monitored. We conclude that the fitnesses of these programs often does not change with single mutations and we also confirm the inherent discreteness of bug fixing fitness functions. Although our findings cannot be assumed to be general for other software they provide us with interesting directions for further investigation.",edit distance - mutated Python programs - genetic improvement - computational search techniques - execution time - power consumption - heuristic search algorithms - GI searching - fitness distance measure - program repair - bug fixing fitness functions,"Haraldsson, S.O.(1); Woodward, J.R.(1); Brownlee, A.E.I.(1); Cairns, D.(1)",2017.0,Conference,"Genetic Programming. 20th European Conference, EuroGP 2017. Proceedings: LNCS 10196",10.1007/978-3-319-55696-3_2,"(1) Univ. of Stirling, Stirling, United Kingdom",Springer International Publishing,English,,
Inspec,Co-array Python: a parallel extension to the Python language,"A parallel extension to the Python language is introduced that is modeled after the Co-Array Fortran extensions to Fortran 95. A new Python module, CoArray, has been developed to provide co-array syntax that allows a Python programmer to address co-array data on a remote processor. An example of Jacobi iteration using the CoArray module is shown and corresponding performance results are presented.",co-array Python - Python language - co-array Fortran extension - Fortran 95 - co-array data - remote processor - Jacobi iteration,"Rasmussen, C.E.(1); Sottile, M.J.(1); Nieplocha, J.; Numrich, R.W.; Jones, E.",2004.0,Conference,Euro-Par 2004 Parallel Processing. 10th International Euro-Par Conference. Proceedings (Lecture Notes in Comput. Sci. Vol.3149),,"(1) Los Alamos Nat. Lab., Los Alamos, NM, United States",Springer-Verlag,English,,3-540-22924-8
Inspec,Python for Microwave and RF Engineers,"Python is a powerful programming language for handling engineering and scientific computational tasks efficiently [1]-[5]. Used by companies such as Google and Intel and by organizations including NASA and Los Alamos National Laboratory, it offers an extremely wide selection of tools for tasks such as scientific computing, signal processing, Web site construction, database programming, and graphical user interface (GUI) design. The language is platform independent with most programs running on Linux, Microsoft Windows, or MAC OS virtually unchanged. Python has been distributed as a part of Open Source Initiative, and most versions are General Public License (GPL) compatible. In microwave and radio frequency (RF) engineering, it can be used for numerical programming, automated RF testing, automated monolithic microwave integrated-circuit (MMIC) layout generation, automated netlist generation and simulator sequencing, and other tasks. In this article, we are going to provide examples demonstrating the application areas of Python in microwave and RF engineering. We are also going to give a brief introduction to the language highlighting its salient features.",microwave engineers - RF engineers - Python - programming language - platform independent - Linux - Microsoft Windows - MAC OS - open source initiative - general public license - GPL - numerical programming - automated monolithic microwave integrated-circuit - MMIC layout generation,"Kinayman, N.(1)",2011.0,Journal,IEEE Microwave Magazine,10.1109/MMM.2011.942704,"(1) Analog Device Technol. Group, M.I.T. Lincoln Lab., Lexington, MA, United States",IEEE,English,1527-3342,
Inspec,Numerical Solution of Large Scale Sparse Matrix Equations in Python,"The M.E.S.S. software suite for solving large scale matrix equations and related problems is the successor of the obsolete LyaPack MATLAB R toolbox. The software suite consists of a new MATLAB toolbox and a separate C library C-M.E.S.S. which works independent from MATLAB. Due to the fact that many scientists use Python with NumPy and SciPy for their computations, we want to provide the key algorithms of M.E.S.S. there as well. In this paper, we describe and compare two possible approaches for the implementation, with special focus on their multicore performance. (© 2014 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim).",MESS software suite - large scale matrix equations - obsolete LyaPack MATLAB toolbox - C library - C-MESS - Python - NumPy - SciPy - multicore performance - numerical solution,"Baran, B.(1); Ko¨hler, M.(1); Prasad, N.(2); Saak, J.(1)",2014.0,Journal,Proceedings in Applied Mathematics and Mechanics,10.1002/pamm.201410460,"(1) Comput. Methods in Syst. & Control Theor., Max Planck Inst. for Dynamics of Complex Tech. Syst., Magdeburg, Germany; (2) Dept. of Electr. Eng., Indian Inst. of Technol. Madras, Chennai, India",Wiley-VCH,English,1617-7061,
Inspec,BindsNET: A machine learning-oriented spiking neural networks library in Python [arXiv],"The development of spiking neural network simulation software is a critical component enabling the modeling of neural systems and the development of biologically inspired algorithms. Existing software frameworks support a wide range of neural functionality, software abstraction levels, and hardware devices, yet are typically not suitable for rapid prototyping or application to problems in the domain of machine learning. In this paper, we describe a new Python package for the simulation of spiking neural networks, specifically geared towards machine learning and reinforcement learning. Our software, called BindsNET, enables rapid building and simulation of spiking networks and features user-friendly, concise syntax. BindsNET is built on top of the PyTorch deep neural networks library, enabling fast CPU and GPU computation for large spiking networks. The BindsNET framework can be adjusted to meet the needs of other existing computing and hardware environments, e.g., TensorFlow. We also provide an interface into the OpenAI gym library, allowing for training and evaluation of spiking networks on reinforcement learning problems. We argue that this package facilitates the use of spiking networks for large-scale machine learning experimentation, and show some simple examples of how we envision BindsNET can be used in practice. BindsNET code is available at https://github.com/Hananel-Hazan/bindsnet.",neural network simulation software - neural systems - software frameworks - neural functionality - software abstraction levels - BindsNET framework - reinforcement learning problems - large-scale machine learning experimentation - PyTorch deep neural network library - machine learning-oriented spiking neural network library - Python - biologically inspired algorithms - TensorFlow - OpenAI gym library,"Hazan, H.(1); Saunders, D.J.(1); Khan, H.(1); Sanghavi, D.T.(1); Siegelmann, H.T.(1); Kozma, R.(1)",2018.0,arXiv,arXiv,,"(1) Biologically Inspired Neural & Dynamical Syst. Lab., Univ. of Massachusetts Amherst, Amherst, MA, United States",arXiv,English,,
Inspec,Owlready: Ontology-oriented programming in Python with automatic classification and high level constructs for biomedical ontologies,"Objective: Ontologies are widely used in the biomedical domain. While many tools exist for the edition, alignment or evaluation of ontologies, few solutions have been proposed for ontology programming interface, i.e. for accessing and modifying an ontology within a programming language. Existing query languages (such as SPARQL) and APIs (such as OWLAPI) are not as easy-to-use as object programming languages are. Moreover, they provide few solutions to difficulties encountered with biomedical ontologies. Our objective was to design a tool for accessing easily the entities of an OWL ontology, with high-level constructs helping with biomedical ontologies. Method: From our experience on medical ontologies, we identified two difficulties: (1) many entities are represented by classes (rather than individuals), but the existing tools do not permit manipulating classes as easily as individuals, (2) ontologies rely on the open-world assumption, whereas the medical reasoning must consider only evidence-based medical knowledge as true. We designed a Python module for ontology-oriented programming. It allows access to the entities of an OWL ontology as if they were objects in the programming language. We propose a simple high-level syntax for managing classes and the associated “role-filler” constraints. We also propose an algorithm for performing local closed world reasoning in simple situations. Result: We developed Owlready, a Python module for a high-level access to OWL ontologies. The paper describes the architecture and the syntax of the module version 2. It details how we integrated the OWL ontology model with the Python object model. The paper provides examples based on Gene Ontology (GO). We also demonstrate the interest of Owlready in a use case focused on the automatic comparison of the contraindications of several drugs. This use case illustrates the use of the specific syntax proposed for manipulating classes and for performing local closed world reasoning. Conclusion: Owlready has been successfully used in a medical research project. It has been published as Open-Source software and then used by many other researchers. Future developments will focus on the support of vagueness and additional non-monotonic reasoning feature, and automatic dialog box generation. [All rights reserved Elsevier].",biomedical ontologies - role-filler constraints - Gene Ontology - Python object model - high-level access - local closed world reasoning - simple high-level syntax - Python module - medical ontologies - high-level constructs - OWL ontology - object programming languages - ontology programming interface - high level constructs - ontology-oriented programming,"Lamy, J.-B.(1)",2017.0,Journal,Artificial Intelligence in Medicine,10.1016/j.artmed.2017.07.002,"(1) LIMICS, Univ. Paris, Paris, France",Elsevier B.V.,English,0933-3657,
Inspec,IB2d: a Python and MATLAB implementation of the immersed boundary method [arXiv],"The development of fluid-structure interaction (FSI) software involves trade-offs between ease of use, generality, performance, and cost. Typically there are large learning curves when using low-level software to model the interaction of an elastic structure immersed in a uniform density fluid. Many existing codes are not publicly available, and the commercial software that exists usually requires expensive licenses and may not be as robust or allow the necessary flexibility that in house codes can provide. We present an open source immersed boundary software package, IB2d, with full implementations in both MATLAB and Python, that is capable of running a vast range of biomechanics models and is accessible to scientists who have experience in high-level programming environments. IB2d contains multiple options for constructing material properties of the fiber structure, as well as the advection-diffusion of a chemical gradient, muscle mechanics models, and artificial forcing to drive boundaries with a preferred motion.",artificial forcing - muscle mechanics models - chemical gradient - advection-diffusion - fiber structure material properties - high-level programming environments - biomechanics models - open source immersed boundary software package - Python - MATLAB - IB2d,"Battista, N.A.(1); Strickland, W.C.(1); Miller, L.A.(1)",2016.0,arXiv,arXiv,,"(1) Dept. of Math., Univ. of North Carolina, Chapel Hill, NC, United States",arXiv,English,,
Inspec,IB2d: a Python and MATLAB implementation of the immersed boundary method,"The development of fluid-structure interaction (FSI) software involves trade-offs between ease of use, generality, performance, and cost. Typically there are large learning curves when using low-level software to model the interaction of an elastic structure immersed in a uniform density fluid. Many existing codes are not publicly available, and the commercial software that exists usually requires expensive licenses and may not be as robust or allow the necessary flexibility that in house codes can provide. We present an open source immersed boundary software package, IB2d, with full implementations in both MATLAB and Python, that is capable of running a vast range of biomechanics models and is accessible to scientists who have experience in high-level programming environments. IB2d contains multiple options for constructing material properties of the fiber structure, as well as the advection-diffusion of a chemical gradient, muscle mechanics models, and artificial forcing to drive boundaries with a preferred motion.",IB2d - Python - MATLAB - immersed boundary method - fluid-structure interaction - FSI software - open source software package - fiber structure - advection-diffusion,"Battista, N.A.(1); Strickland, W.C.(1); Miller, L.A.(1)",2017.0,Journal,Bioinspiration & Biomimetics,10.1088/1748-3190/aa5e08,"(1) Dept. of Math., Univ. of North Carolina, Chapel Hill, NC, United States",IOP Publishing,English,1748-3190,
Inspec,"Mushu, a free- and open source BCI signal acquisition, written in Python","The following paper describes Mushu, a signal acquisition software for retrieval and online streaming of Electroencephalography (EEG) data. It is written, but not limited, to the needs of Brain Computer Interfacing (BCI). It's main goal is to provide a unified interface to EEG data regardless of the amplifiers used. It runs under all major operating systems, like Windows, Mac OS and Linux, is written in Python and is free- and open source software licensed under the terms of the GNU General Public License.",free-source BCI signal acquisition - open source BCI signal acquisition - Mushu - Python - signal acquisition software - signal retrieval - online streaming - electroencephalography data - EEG data - brain-computer interface - major operating systems - Windows - Mac OS - Linux - GNU General Public License,"Venthur, B.(1); Blankertz, B.(1)",2012.0,Conference,2012 34th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),10.1109/EMBC.2012.6346296,"(1) Berlin Inst. of Technol., Berlin, Germany",IEEE,English,,
Inspec,Pynamic: the python dynamic benchmark,"Python is widely used in scientific computing to facilitate application development and to support features such as computational steering. Making full use of some of Python's popular features, which improve programmer productivity, leads to applications that access extremely high numbers of dynamically linked libraries (DLLs). As a result, some important Python-based applications severely stress a system's dynamic linking and loading capabilities and also cause significant difficulties for most development environment tools, such as debuggers. Furthermore, using the Python paradigm for large scale MPI-based applications can create significant file IO and further stress tools and operating systems. In this paper, we present Pynamic, the first benchmark program to support configurable emulation of a wide-range of the DLL usage of Python-based applications for large scale systems. Pynamic has already accurately reproduced system software and tool issues encountered by important large Python-based scientific applications on our supercomputers. Pynamic provided insight for our system software and tool vendors, and our application developers, into the impact of several design decisions. As we describe the Pynamic benchmark, we will highlight some of the issues discovered in our large scale system software and tools using Pynamic.",python dynamic benchmark - computational steering - dynamically linked library - MPI - operating system - system software - message passing - Pynamic benchmark,"Lee, G.L.(1); Ahn, D.H.(1); de Supinski, B.R.(1); Gyllenhaal, J.(1); Miller, P.(1)",2007.0,Conference,2007 IEEE International Symposium on Workload Characterization,,"(1) Lawrence Livermore Nat. Lab., Livermore, CA, United States",IEEE,English,,1-4244-1562-4
Inspec,PyDEns: a Python Framework for Solving Differential Equations with Neural Networks [arXiv],"Recently, a lot of papers proposed to use neural networks to approximately solve partial differential equations (PDEs). Yet, there has been a lack of flexible framework for convenient experimentation. In an attempt to fill the gap, we introduce a PyDEns-module open-sourced on GitHub. Coupled with capabilities of BatchFlow, open-source framework for convenient and reproducible deep learning, PyDEns-module allows to 1) solve partial differential equations from a large family, including heat equation and wave equation 2) easily search for the best neural-network architecture among the zoo, that includes ResNet and DenseNet 3) fully control the process of model-training by testing different point-sampling schemes. With that in mind, our main contribution goes as follows: implementation of a ready-to-use and open-source numerical solver of PDEs of a novel format, based on neural networks.",neural networks - partial differential equations - flexible framework - convenient experimentation - PyDEns-module - open-source framework - convenient learning - reproducible deep learning - heat equation - wave equation - neural-network architecture - ready-to-use - open-source numerical solver - python framework,"Koryagin, A.(1); Khudorozkov, R.(1); Tsimfer, S.(1)",2019.0,arXiv,arXiv,,"(1) Data Anal. Center, Gazpromneft, St. Petersburg, Russia",arXiv,English,,
Inspec,PolyPy: A Web-Platform for Generating Quasi-Random Python Code and Gaining Insights on Student Learning,"This Innovative Practice Full paper introduces PolyPy, a freely available web-platform that allows instructors to automate the creation of many different coding question instances from a single template. Interactive web platforms offer a way of engaging students with practice material while also providing them with real-time feedback. However, many of these platforms depend on manually pre-setting a static pool of questions and answers, which limits 1) the number of unique coding challenges presented to students, 2) the ability of instructors to dynamically customize challenges, and 3) the ability to recognize and adapt to individual student needs. PolyPy bypasses these limitations by providing a flexible and easy-to-use framework that lets instructors define question templates. These templates contain segments that can exhibit one of many pre-set values; we refer to these segments as ldquorandomizable elements.rdquo The question instances are generated (from the templates) on-the-fly every time a student requests a new question via the student interface. To verify the correctness of students' answers, PolyPy interprets these question instances and compares their output to the students' submissions in real-time. All students' attempts, both correct and incorrect, are stored and can be accessed by instructors; this information can be used to gain insight on the strengths and weaknesses of student comprehension. This paper presents the PolyPy system architecture and describes the student and instructor interfaces. It reports promising preliminary results of students' use of PolyPy along with feedback obtained regarding their learning experience.",student learning - real-time feedback - individual student - flexible use framework - easy-to-use framework - question templates - student requests - student interface - student comprehension - PolyPy system architecture - instructor interfaces - preset values - interactive Web platforms - freely available Web-platform - quasirandom Python code,"Hajja, A.(1); Hunt, A.J.(1); McCauley, R.(1)",2019.0,Conference,2019 IEEE Frontiers in Education Conference (FIE),10.1109/FIE43999.2019.9028712,"(1) Dept. of Comput. Sci., Coll. of Charleston, Charleston, SC, United States",IEEE,English,,
Inspec,Using Python scripts in Blender,"There is described an usage of the Python scripts in Blender. Blender is an open source software for 3D modeling, animation, rendering, postproduction, interactive creation and playback. We use the program Blender for the educational 3D graphics and demonstration of models creation on our university. Python is an interpreted, interactive, object-oriented programming language. It is often compared to Tcl, Perl, Scheme or Java. We program miscellaneous plug-ins with the help of Python. We can open and run in Blender environment with these plug-ins.",Python scripts - Blender - open source software - 3D graphics - object-oriented programming language - interactive programming,"Pokorny, P.; Sysel, M.",2005.0,Conference,"Annals of DAAM for 2005 & Proceedings of the 16th International DAAM Symposium ""Intelligent Manufacturing & Automation: Focus on Young Researches and Scientists""",,,DAAAM International Vienna,English,,3-901509-46-1
Inspec,Simulation and exergy analysis of energy conversion processes using a free and open-source framework-Python-based object-oriented programming for gas- and steam turbine cycles,"State-of-the-art thermodynamic simulation of energy conversion processes requires proprietary software. This article is an attempt to refute this statement. Based on object-oriented programming a simulation and exergy analysis of a combined cycle gas turbine is carried out in a free and open-source framework. Relevant basics of a thermodynamic analysis with exergy-based methods and necessary fluid property models are explained. Thermodynamic models describe the component groups of a combined heat and power system. The procedure to transform a physical model into a Python-based simulation program is shown. The article contains a solving algorithm for a precise gas turbine model with sophisticated equations of state. As an example, a system analysis of a combined cycle gas turbine with district heating is presented. Herein, the gas turbine model is validated based on literature data. The exergy analysis identifies the thermodynamic inefficiencies. The results are graphically presented in a Grassmann chart. With a sensitivity analysis a thermodynamic optimization of the district heating system is discussed. Using the exergy destruction rate in heating condensers or the overall efficiency as the objective function yields to different results.",thermodynamic simulation - gas-and steam turbine cycles - open-source framework-Python-based object-oriented programming - free source framework-Python-based object-oriented programming - exergy destruction rate - district heating system - thermodynamic optimization - sensitivity analysis - system analysis - Python-based simulation program - power system - necessary fluid property models - thermodynamic analysis - combined cycle gas turbine - energy conversion processes - exergy analysis,"Zoder, M.(1); Balke, J.(1); Hofmann, M.(1); Tsatsaronis, G.(1)",2018.0,Journal,Energies,10.3390/en11102609,"(1) Inst. for Energy Eng., Tech. Univ. Berlin, Berlin, Germany",MDPI,English,1996-1073,
Inspec,Building hybrid systems with Boost.Python,"Python and C++ are in many ways as different as two languages could be: while C++ is compiled to machine-code, Python is interpreted. Python's dynamic type system is cited as the foundation of its flexibility, while in C++ static typing is the cornerstone of its efficiency. C++ has an intricate compile-time meta-language, while in Python, practically everything happens at runtime. Still, for many programmers, these very differences mean that Python and C++ complement one another perfectly. Performance bottlenecks in Python programs can be rewritten in C++ for maximal speed, and authors of powerful C++ libraries choose Python as a middleware language for its flexible system integration capabilities. Furthermore, the surface differences mask some strong similarities which are outlined. The primary goal of Boost.Python is to allow users to expose C++ classes and functions to Python using nothing more than a C++ compiler. In broad strokes, the user experience should be one of directly manipulating C++ objects from Python.",Boost.Python - Python - C++ - dynamic type system - static typing - C++ library - middleware language,"Abrahams, D.; Grosse-Kunstleve, R.W.",2003.0,Journal,C/C++ Users Journal,,,CMP Media Inc.,English,1075-2838,
Inspec,modlAMP: Python for antimicrobial peptides,"We have implemented the molecular design laboratory's antimicrobial peptides package (modlAMP), a Python-based software package for the design, classification and visual representation of peptide data. modlAMP offers functions for molecular descriptor calculation and the retrieval of amino acid sequences from public or local sequence databases, and provides instant access to precompiled datasets for machine learning. The package also contains methods for the analysis and representation of circular dichroism spectra.",circular dichroism spectra - molecular descriptor calculation - modlAMP offers functions - peptide data - visual representation - classification - Python-based software package - molecular design laboratory - antimicrobial peptides - local sequence databases - public sequence databases - amino acid sequences,"Muller, A.T.(1); Gabernet, G.(1); Hiss, J.A.(1); Schneider, G.(1)",2017.0,Journal,Bioinformatics,10.1093/bioinformatics/btx285,"(1) Dept. of Chem. & Appl. Biosci., ETH Zurich, Zurich, Switzerland",Oxford University Press,English,1367-4803,
Inspec,Research and implementation of OPD algorithm for spatial gravitational wave telescope based on ZEMAX and Python softwares,"The optical design softwares ZEMAX and Python were used to realize the precision solution of optical path difference (OPD) for spatial gravitational wave telescope. The dynamic data exchange (DDE) closed-loop communication between ZEMAX and Python was realized. First, the Python software processed the data of telescope mirror after the finite element analysis ,and transmitted the analysis results to the ZEMAX with DDE for tracing ray. Secondly,the ZEMAX software transferred the ray coordinate value to the Python software through the DDE. Lastly, the Python software calculated the OPD and wavefront changes caused by rigid body translation through the global coordinate system. Through simulating the deformation of the gravitational wave telescope with the temperature change of 1 mK, the OPD and wavefront variation of the spatial gravitational wave telescope was solved by means of ZEMAX software and Python software. The results show that the OPD precision reaches the order of 1e-13 meter, which can satisfy the requirements of telescope for Pico-level stability . It is concluded that the method is feasible to calculate the OPD, and it provides a technical reference for the OPD analysis for the further mechanism design of the gravitational wave telescope.",OPD algorithm - optical design softwares - optical path difference - telescope mirror - finite element analysis - ray tracing - ray coordinate value - rigid body translation - global coordinate system - ZEMAX software - DDE - dynamic data exchange closed-loop communication - Python software - spatial gravitational wave telescope - temperature 1.0 mK,Xu Mingming(1); Xu Teng(1); Hu Zhongwen(1); Zhang Huatao(1); Ji Hangxin(1); Jiang Haijiao(1); Wang Lei(1),2017.0,Journal,Journal of Applied Optics,10.5768/JAO201738.0601003,"(1) Nat. Astron. Obs., Nanjing Inst. of Astron. Opt. &. Technol., Nanjing, China",No. 205 Research Institute of China Ordnance Industry,Chinese,1002-2082,
Inspec,PySS3: A Python package implementing a novel text classifier with visualization tools for Explainable AI [arXiv],"A recently introduced text classifier, called SS3, has obtained state-of-the-art performance on the CLEF's eRisk tasks. SS3 was created to deal with risk detection over text streams and therefore not only supports incremental training and classification but also can visually explain its rationale. However, little attention has been paid to the potential use of SS3 as a general classifier. We believe this could be due to the unavailability of an open-source implementation of SS3. In this work, we introduce PySS3, a package that not only implements SS3 but also comes with visualization tools that allow researchers deploying robust, explainable and trusty machine learning models for text classification.",PySS3 - Python package - visualization tools - explainable AI - text streams - general classifier - open-source implementation - text classification - CLEF eRisk tasks - text classifier - risk detection - machine learning,"Burdisso, S.G.(1); Errecalde, M.(1); Montes-y-Goacutemez, M.(2)",2019.0,arXiv,arXiv,,"(1) Univ. Nac. de San Luis, San Luis, Argentina; (2) Inst. Nac. de Astrofis., Puebla, Mexico",arXiv,English,,
Inspec,Learning Python Code Suggestion with a Sparse Pointer Network [arXiv],"To enhance developer productivity, all modern integrated development environments (IDEs) include code suggestion functionality that proposes likely next tokens at the cursor. While current IDEs work well for statically-typed languages, their reliance on type annotations means that they do not provide the same level of support for dynamic programming languages as for statically-typed languages. Moreover, suggestion engines in modern IDEs do not propose expressions or multi-statement idiomatic code. Recent work has shown that language models can improve code suggestion systems by learning from software repositories. This paper introduces a neural language model with a sparse pointer network aimed at capturing very long-range dependencies. We release a large-scale code suggestion corpus of 41M lines of Python code crawled from GitHub. On this corpus, we found standard neural language models to perform well at suggesting local phenomena, but struggle to refer to identifiers that are introduced many tokens in the past. By augmenting a neural language model with a pointer network specialized in referring to predefined classes of identifiers, we obtain a much lower perplexity and a 5 percentage points increase in accuracy for code suggestion compared to an LSTM baseline. In fact, this increase in code suggestion accuracy is due to a 13 times more accurate prediction of identifiers. Furthermore, a qualitative analysis shows this model indeed captures interesting long-range dependencies, like referring to a class member defined over 60 tokens in the past.",Python code suggestion learning - sparse pointer network - integrated development environment - IDE - code suggestion system improvement - software repositories - neural language model - large-scale code suggestion corpus - GitHub - qualitative analysis,"Bhoopchand, A.(1); Rockta¨schel, T.(1); Barr, E.(1); Riedel, S.(1)",2016.0,arXiv,arXiv,,"(1) Dept. of Comput. Sci., Univ. Coll. London, London, United Kingdom",arXiv,English,,
Inspec,"Marine Geospatial Ecology Tools: An integrated framework for ecological geoprocessing with ArcGIS, Python, R, MATLAB, and C++","With the arrival of GPS, satellite remote sensing, and personal computers, the last two decades have witnessed rapid advances in the field of spatially-explicit marine ecological modeling. But with this innovation has come complexity. To keep up, ecologists must master multiple specialized software packages, such as ArcGIS for display and manipulation of geospatial data, R for statistical analysis, and MATLAB for matrix processing. This requires a costly investment of time and energy learning computer programming, a high hurdle for many ecologists. To provide easier access to advanced analytic methods, we developed Marine Geospatial Ecology Tools (MGET), an extensible collection of powerful, easy-to-use, open-source geoprocessing tools that ecologists can invoke from ArcGIS without resorting to computer programming. Internally, MGET integrates Python, R, MATLAB, and C++, bringing the power of these specialized platforms to tool developers without requiring developers to orchestrate the interoperability between them.In this paper, we describe MGET's software architecture and the tools in the collection. Next, we present an example application: a habitat model for Atlantic spotted dolphin (Stenella frontalis) that predicts dolphin presence using a statistical model fitted with oceanographic predictor variables. We conclude by discussing the lessons we learned engineering a highly integrated tool framework. [All rights reserved Elsevier].",marine geospatial ecology tool - ecological geoprocessing - ArcGIS - Python - MATLAB - C++ - GPS - satellite remote sensing - personal computer - marine ecological modeling - software package - geospatial data - statistical analysis - matrix processing - computer programming - analytic method - open source geoprocessing tool - MGET - software architecture - Atlantic spotted dolphin - oceanographic predictor variable,"Roberts, J.J.(1); Best, B.D.(1); Dunn, D.C.(1); Treml, E.A.(2); Halpin, P.N.(1)",2010.0,Journal,Environmental Modelling & Software,10.1016/j.envsoft.2010.03.029,"(1) Marine Geospatial Ecology Lab., Duke Univ., Durham, NC, United States; (2) Sch. of Biol. Sci., Univ. of Queensland, St. Lucia, QLD, Australia",Elsevier Science Ltd.,English,1364-8152,
Inspec,Pykat: Python package for modelling precision optical interferometers [arXiv],"PYKAT is a Python package which extends the popular optical interferometer modelling software FINESSE. It provides a more modern and efficient user interface for conducting complex numerical simulations, as well as enabling the use of Python's extensive scientific software ecosystem. In this paper we highlight the relationship between PYKAT and FINESSE, how it is used, and provide an illustrative example of how it has helped to better understand the characteristics of the current generation of gravitational wave interferometers.",PYKAT - Python package - popular optical interferometer modelling software FINESSE - modern user interface - efficient user interface - complex numerical simulations - Python's extensive scientific software ecosystem - gravitational wave interferometers - modelling precision optical interferometers,"Brown, D.D.(1); Jones, P.(2); Rowlinson, S.(2); Freise, A.(2); Leavey, S.; Green, A.C.(3); Toyra, D.(4)",2020.0,arXiv,arXiv,,"(1) OzGrav, Univ. of Adelaide, Adelaide, SA, Australia; (2) Sch. of Phys. & Astron., Univ. of Birmingham, Birmingham, United Kingdom; (3) Univ. of Florida, Gainesville, FL, United States; (4) OzGrav, Australian Nat. Univ., Canberra, ACT, Australia",arXiv,English,,
Inspec,"Python for Rapid Science Operations Analysis, Prototyping and Planning for BepiColombo","The Python programming language is fast becoming the go-to language among scientists and engineers, across many disciplines, for a broad range of tasks, from on-the-fly data analysis and problem solving through quick and light solution prototyping to large scale system development. Python's relatively shallow learning curve coupled with the seemingly endless quantities of online learning materials has allowed the language to make a considerable dent in the number of new and old users of languages such as Matlab, IDL, R, Perl and others. While Python may run slower than compiled languages like Java, C or C++, more often than not it requires less time to develop with up to 3 to 5 times less code. This, together with the fact that it does not require a paid license, has contributed heavily to its broad adoption. In addition to Python's extensive built-in library, the language's extensibility is evident by the large and growing number of freely available community-developed packages, which provide added-functionality across a broad range of disciplines. As part of the long-term science operations analysis and planning for the ESA/JAXA BepiColombo mission to Mercury, the Science Ground Segment has embraced the power and flexibility of Python for, among other things, the preparation of inputs to and processing of outputs from in-house simulation software; this software is centrally and generically developed for several ESA missions and as such does not lend itself to the rapid and flexible addition of experimental-functionality; python, often called a “glue” language, provides a quick and robust means to prototype required functionalities external to large legacy software. Python has allowed, in a short time and succinct manner, many labor-intensive workflows to be reduced to the execution of single scripts. Repetitively manual operations analysis and reporting tasks have been superseded with easily shared, browser-based analysis notebooks that combine analysis, reporting and knowledge management into a single user interface. Data models and web-based interfaces for science observation definition and specification have been prototyped using intuitive yet powerful objectrelational-mapping and micro-web frameworks. Command scripts for instrument functional tests have been processed into different required formats using Python's powerful regular expression functionalities and libraries for reading and writing commonly used data exchange formats such as Microsoft Word and Excel. This paper presents several specific use-cases for Python in Science Operations Analysis, Prototyping and Planning, demonstrates a number of examples, and outlines the gains experienced to-date through the employment of Python in the BepiColombo Science Ground Segment.",micro-web frameworks - object-relational-mapping - knowledge management - browser-based analysis notebooks - in-house simulation software - science ground segment - ESA/JAXA BepiColombo mission - online learning - large scale system development - problem solving - on-the-fly data analysis - Python programming language - planning - prototyping - rapid science operations analysis,"McAuliffe, J.P.(1); Lanaspa, P.(1)",2016.0,Conference,14th International Conference on Space Operations,,"(1) Eur. Space Astron. Centre, Madrid, Spain",AIAA - American Institute of Aeronautics and Astronautics,English,,
Inspec,Open-source python-OpenDSS interface for hybrid simulation of PV impact studies,"This study introduces an open-source Python-OpenDSS simulation tool where the phasor simulation software OpenDSS is interfaced with an electromagnetic transient (EMT) program-type simulation tool implemented in Python environment. The tool is designed to perform impact study of photovoltaic (PV) integration in distribution systems. It is composed of an EMT model of a grid-tied PV system interfaced with a phasor model of the distribution network. The proposed tool provides an add-on that expands OpenDSS capabilities in order to perform various PV impact studies that cannot be performed inherently by OpenDSS since they require detailed modelling. This study describes the methodology and theory behind the interfacing of the EMT model with OpenDSS. The tool is tested with various case studies using the IEEE 37-bus system with multiple interconnected PV systems. The tool is validated by comparing its results with those of a full EMT model of the IEEE 37-bus system simulated using SimPowerSystems. The results indicate that the hybrid tool offers significant advantages over single-rate simulations that use either full phasor or full EMT simulation approach. It provides faster simulation time and less computational intensity, and the accuracy is remarkably close to the full blown, more complex and slower, EMT simulation.",computational intensity - multiple interconnected PV systems - IEEE 37-bus system - EMT model - distribution network - grid-tied PV system - transient model - distribution systems - PV integration - photovoltaic integration - EMTP-type simulation tool - phasor simulation software - open-source Python-OpenDSS simulation tool - PV impact studies - hybrid simulation - open-source Python-openDSS interface,"Hariri, A.(1); Newaz, A.(1); Faruque, M.O.(1)",2017.0,Journal,"IET Generation, Transmission & Distribution",10.1049/iet-gtd.2016.1572,"(1) Dept. of Electr. & Comput. Eng. & the Center for Adv. Power Syst., Florida State Univ., Tallahassee, FL, United States",IET,English,1751-8687,
Inspec,PYSAT: python satellite data analysis toolkit,"A common problem in space science data analysis is combining complementary data sources that are provided and analyzed in different formats and programming languages. The Python Satellite Data Analysis Toolkit (pysat) addresses this issue by providing an open source toolkit that implements the general process of space science data analysis, from beginning to end, in an instrument-independent manner. This toolkit uses an Instrument object that enables systematic analysis of science data from a variety of platforms within a single interface. Basic functions such as downloading, loading, and cleaning are included for all supported instruments. Common analysis routines are also included, which are instrument and data source independent. A nanokernel is used to provide instrument independence, it is attached to the Instrument object and mediates the systematic and arbitrary modification of loaded data. Pysat uses the nanokernel to improve the rigor of time series analysis, support on-the-fly orbit determination, and cleanly span file breaks. Pysat's functions and higher-level scientific analysis features are validated through the use of unit testing. Further adoption by the community provides a set of scientific results produced by a common core, constituting a distributed heritage that supports the validity of the underlying processing and scientific output. These features are used to demonstrate consistency between derived electron density profiles and measured ion drifts, particularly downward ion drifts in the afternoon hours during extreme solar minimum. Pysat builds upon open source Python software that is freely available and encourages community-driven development.",time series analysis - loaded data - instrument independence - data source - systematic analysis - instrument-independent manner - open source toolkit - programming languages - complementary data sources - space science data analysis - python satellite data analysis toolkit - PYSAT - open source Python software - higher-level scientific analysis features,"Stoneback, R.A.(1); Burrell, A.G.(1); Klenzing, J.(2); Depew, M.D.(1)",2018.0,Journal,Journal of Geophysical Research: Space Physics,10.1029/2018JA025297,"(1) Phys. Dept., Univ. of Texas at Dallas, Richardson, TX, United States; (2) NASA Goddard Space Flight Center, Greenbelt, MD, United States",Wiley,English,2169-9380,
Inspec,Are There Any Unit Tests? An Empirical Study on Unit Testing in Open Source Python Projects,"Unit testing is an essential practice in Extreme Programming (XP) and Test-driven Development (TDD) and used in many software lifecycle models. Additionally, a lot of literature deals with this topic. Therefore, it can be expected that it is widely used among developers. Despite its importance, there is no empirical study which investigates, whether unit tests are used by developers in real life projects at all. This paper presents such a study, where we collected and analyzed data from over 70K revisions of 10 different Python projects. Based on two different definitions of unit testing, we calculated the actual number of unit tests and compared it with the expected number (as inferred from the intentions of the developers), had a look at the mocking behavior of developers, and at the evolution of the number of unit tests. Our main findings show, (i) that developers believe that they are developing more unit tests than they actually do, (ii) most projects have a very small amount of unit tests, (iii) developers make use of mocks, but these do not have a significant influence on the number of unit tests, (iv) four different patterns for the evolution of the number of unit tests could be detected, and (v) the used unit test definition has an influence on the results.",unit testing - open source Python projects - extreme programming - XP - test-driven development - TDD - software lifecycle models - mocking behavior,"Trautsch, F.(1); Grabowski, J.(1)",2017.0,Conference,"2017 IEEE International Conference on Software Testing, Verification and Validation (ICST)",10.1109/ICST.2017.26,"(1) Inst. of Comput. Sci., Georg-August-Univ. Gottingen, Gottingen, Germany",IEEE Computer Society,English,,
Inspec,Implementation of a Motor Imagery based BCI System using Python Programming Language,"At present, there is a wide variety of free open-source brain-computer interface (BCI) software. Even though the available software is very complete, it often runs under a Matlab environment. Matlab is a high performance language for scientific computing, but its limitations concerning the license cost, the restricted access to the algorithm code, and the portability difficulties complicates its use. Therefore, we proposed to implement a motor imagery (MI) based BCI system using Python programming language. This system was called miBCI software, was designed to discriminate up to three control tasks and was structured on the basis of online and offline data analyses. The functionality and efficiency of the software were firstly assessed in a pilot study, and then, its applicability and utility were demonstrated in two subsequent studies associated with the external and internal influences on MI-related control tasks. Results of the pilot study and preliminary outcomes of the subsequent studies are herein presented. This work contributes by promoting the utilization of tools which facilitate the advance of BCI research. The advantage of using Python instead of Matlab, which is the widely used programming language at the moment, is the opportunity to develop BCI software in a public and collaborative way, without property license restrictions.",online data analysis - offline data analysis - miBCI software - high performance language - Matlab environment - open-source BCI software - open-source brain-computer interface software - Python programming language - motor imagery-based BCI system,"Alonso-Valerdi, L.M.(1); Sepulveda, F.(2)",2015.0,Conference,2nd International Conference on Physiological Computing Systems (PhyCS 2015). Proceedings,,"(1) Dept. of Res., Tecnol. de Monterrey, Mexico City, Mexico; (2) Sch. of Comput. Sci. & Electron. Eng., Univ. of Essex, Colchester, United Kingdom",INSTICC Press,English,,
Inspec,JARVIS: An interpretation of AIML with integration of gTTS and Python,"This paper presents JARVIS, a virtual integrated voice assistant comprising of gTTS, AIML[Artificial Intelligence Markup Language], and Python-based state-of-the-art technology in personalized assistant development. JARVIS incorporates the power of AIML and with the industry-leading Google platform for text-to-speech conversion and the voice of the Male Pitch in the gTTS libraries inspired from the Marvel World. This is the result of the adoption of the dynamic base Pythons pyttsx which considers intentionally in adjacent phases of gTTS and AIML, facilitating the establishment of considerably smooth dialogues between the assistant and the users. This is a unique result of the exaggerated contribution of several contributors such as the feasible use of AIML and its dynamic fusion with platforms like Python[pyttsx] and gTTS[Google Text to Speech] resulting into a consistent and modular structure of JARVIS exposing the widespread reusability and negligible maintenance.",dynamic base Pythons pyttsx - AIML - JARVIS - artificial intelligence markup language - personalized assistant development - industry-leading Google platform - text-to-speech conversion - gTTS libraries - virtual integrated voice assistant - Marvel World - Google text to speech - male pitch,"Sangpal, R.(1); Gawand, T.(1); Vaykar, S.(1); Madhavi, N.(1)",2019.0,Conference,"2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT)",10.1109/ICICICT46008.2019.8993344,"(1) Comput. Technol., Gov. Polytech. Pen, Pen, India",IEEE,English,,
Inspec,A python based testbed for real-time testing and visualization using TI's 77 GHz automotive radars,"In the paper, we introduce a Python based software library and a testbed based for TI's 77 GHz automotive radars using the FPGA based hi-speed ethernet link. The main design objective is to be able to test high level algorithms in real-time, show live results with minimal effort, avoid using low speed serial ports, and build the whole system on FPGA based hi-speed communication. All of these are possible using TI's C/C++ toolchain, but may require much more effort, especially for testing high DSP level algorithms. This is true even if all advanced MATLAB and Python DSP libraries are made available in TI's framework. To be able to test different high level algorithms with less effort, TI is providing a closed source Windows application to record raw ADC data for offline analysis in MATLAB. This setup requires a companion Lattice FPGA board, DCA1000, which sends raw ADC data from all receive antennas as UDP packets. However, this setup is useful only for offline analysis. That's why we have implemented a Python based software library and a testbed for real-time testing and visualization using this raw ADC data. Implemented library does all UDP processing, parsing, and returns numpy arrays representing raw ADC data for each receive antenna. A couple of code samples, including a real-time direction of arrival estimation program, are presented to demonstrate the simplicity and usefulness of the developed system.",TI 77 GHz automotive radars - real-time direction - implemented library - companion Lattice FPGA board - offline analysis - raw ADC data - different high level algorithms - TI's framework - Python DSP libraries - high DSP level algorithms - hi-speed communication - low speed serial ports - minimal effort - main design objective - hi-speed ethernet link - Python based software library - real-time testing - frequency 77.0 GHz,"Toker, O.(1); Kuhn, B.(1)",2019.0,Conference,2019 IEEE Vehicular Networking Conference (VNC),10.1109/VNC48660.2019.9062830,"(1) Dept. of Electr. & Comput. Eng., Florida Polytech. Univ., Lakeland, FL, United States",IEEE,English,,
Inspec,Hyperopt: a Python library for model selection and hyperparameter optimization,"Sequential model-based optimization (also known as Bayesian optimization) is one of the most efficient methods (per function evaluation) of function minimization. This efficiency makes it appropriate for optimizing the hyperparameters of machine learning algorithms that are slow to train. The Hyperopt library provides algorithms and parallelization infrastructure for performing hyperparameter optimization (model selection) in Python. This paper presents an introductory tutorial on the usage of the Hyperopt library, including the description of search spaces, minimization (in serial and parallel), and the analysis of the results collected in the course of minimization. This paper also gives an overview of Hyperopt-Sklearn, a software project that provides automatic algorithm configuration of the Scikit-learn machine learning library. Following Auto-Weka, we take the view that the choice of classifier and even the choice of preprocessing module can be taken together to represent a single large hyperparameter optimization problem. We use Hyperopt to define a search space that encompasses many standard components (e.g. SVM, RF, KNN, PCA, TFIDF) and common patterns of composing them together. We demonstrate, using search algorithms in Hyperopt and standard benchmarking data sets (MNIST, 20-newsgroups, convex shapes), that searching this space is practical and effective. In particular, we improve on best-known scores for the model space for both MNIST and convex shapes. The paper closes with some discussion of ongoing and future work.",Hyperopt library - Python library - model selection - single large hyperparameter optimization problem - sequential model-based optimization - Bayesian optimization - function minimization - machine learning algorithms - parallelization infrastructure - search spaces - Hyperopt-Sklearn - software project - automatic algorithm configuration - Scikit-learn machine learning library - Auto-Weka - standard benchmarking data set - MNIST - convex shapes,"Bergstra, J.(1); Komer, B.(1); Eliasmith, C.(1); Yamins, D.(2); Cox, D.D.(3)",2015.0,Journal,Computational Science and Discovery,10.1088/1749-4699/8/1/014008,"(1) Univ. of Waterloo, Waterloo, ON, Canada; (2) Massachusetts Inst. of Technol., Cambridge, MA, United States; (3) Harvard Univ., Cambridge, MA, United States",IOP Publishing,English,1749-4680,
Inspec,hankel: a Python library for performing simple and accurate Hankel transformations [arXiv],"This paper presents hankel, a pure-python code for solving Hankel-type integrals and transforms. Such transforms are common in the physical sciences, especially appearing as the radial solution to angularly symmetric Fourier Transforms in arbitrary dimensions. The code harnesses the advantages of solving such transforms via the one-dimensional Hankel transform -- an increase in conceptual simplicity and efficiency -- and implements them in the user-friendly and flexible Python language. We discuss several limitations of the adopted method, and point to the code's extensive documentation for further examples. [Journal of Open Source Software, 4(37), 1397 (2019) doi:10.21105/joss.01397].",Python library - simple Hankel transformations - accurate Hankel transformations - pure-python code - Hankel-type integrals - physical sciences - radial solution - angularly symmetric Fourier Transforms - one-dimensional Hankel - flexible Python language,"Murray, S.G.(1); Poulin, F.J.(2)",2019.0,arXiv,arXiv,,"(1) Int. Centre for Radio Astron. Res., Curtin Univ., Bentley, WA, Australia; (2) Dept. of Appl. Math., Univ. of Waterloo, Waterloo, ON, Canada",arXiv,English,,
Inspec,A Python based power electronics E-learning tool,"Simulation became an integral part of power electronics and electrical drives learning process. This paper presents a collection of software programs that can be useful in the teaching process of power electronics and electrical drives. This tool is developed with Python language and libraries, which can be freely distributed. Without going through complicated mathematics and software manuals, students can obtain steady state waveforms from power electronics circuits, their mean and RMS values, as well as spectra. Electrical machine principles are also shown, using animation tools.",Python based power electronics E-learning tool - electrical drives learning process - software programs - Python language - electrical machine principles - electrical engineering education,"Goldemberg, C.(1); Pellini, E.L.(1); Kaiser, W.(1); Komatsu, W.(1)",2009.0,Conference,2009 Brazilian Power Electronics Conference. COBEP 2009,10.1109/COBEP.2009.5347748,"(1) Polytech. Sch., Electr. Energy & Autom. Dept., Univ. of Sao Paulo, Sa˜o Paulo, Brazil",IEEE,English,,
Inspec,Devito: Towards a Generic Finite Difference DSL Using Symbolic Python,"Domain specific languages (DSL) have been used in a variety of fields to express complex scientific problems in a concise manner and provide automated performance optimization for a range of computational architectures. As such DSLs provide a powerful mechanism to speed up scientific Python computation that goes beyond traditional vectorization and pre-compilation approaches, while allowing domain scientists to build applications within the comforts of the Python software ecosystem. In this paper we present Devito, a new finite difference DSL that provides optimized stencil computation from high-level problem specifications based on symbolic Python expressions. We demonstrate Devito's symbolic API and performance advantages over traditional Python acceleration methods before highlighting its use in the scientific context of seismic inversion problems.",seismic inversion problems - symbolic API - high-level problem specifications - optimized stencil computation - finite difference DSL - Python software ecosystem - scientific Python computation - computational architectures - automated performance optimization - domain specific languages - symbolic Python - Devito,"Lange, M.(1); Kukreja, N.(2); Louboutin, M.(3); Luporini, F.(4); Vieira, F.(2); Pandolfo, V.(4); Velesko, P.(5); Kazakas, P.(6); Gorman, G.(1)",2016.0,Conference,2016 6th Workshop on Python for High-Performance and Scientific Computing (PyHPC),10.1109/PyHPC.2016.013,"(1) Dept. of Earth Sci. & Eng., Imperial Coll. London, London, United Kingdom; (2) SENAI, CIMATEC, Salvador, Brazil; (3) Seismic Lab. for Imaging & Modeling, Univ. of British Columbia, Vancouver, BC, Canada; (4) Dept. of Comput. Sci., Imperial Coll. London, London, United Kingdom; (5) Coll. of Electr. & Comput. Eng., Univ. of Oklahoma, Norman, OK, United States; (6) Dept. of Comput. Sci., Univ. of York, York, United Kingdom",IEEE,English,,
Inspec,"cyvcf2: fast, flexible variant analysis with Python","Motivation: Variant call format (VCF) files document the genetic variation observed after DNA sequencing, alignment and variant calling of a sample cohort. Given the complexity of the VCF format as well as the diverse variant annotations and genotype metadata, there is a need for fast, flexible methods enabling intuitive analysis of the variant data within VCF and BCF files. Results: We introduce cyvcf2, a Python library and software package for fast parsing and querying of VCF and BCF files and illustrate its speed, simplicity and utility.",Python - genetic variation - DNA sequencing - VCF format - genotype metadata - intuitive analysis - variant data - BCF files - software package - querying - cyvcf2 package,"Pedersen, B.S.(1); Quinlan, A.R.(1)",2017.0,Journal,Bioinformatics,10.1093/bioinformatics/btx057,"(1) Dept. of Human Genetics, Univ. of Utah, Salt Lake City, UT, United States",Oxford University Press,English,1367-4803,
Inspec,Open source photovoltaic system performance modeling with python,"Several tools exist for modeling the annual energy output of photovoltaic (PV) solar systems. However, open source frameworks are not widely available and tend to be procedural. Moreover, they are oriented toward the modeling of the solar resource instead of the optimization of PV system design. Open source software allows for peer revision, collaboration and rapid development. Furthermore, localized optimizations are possible such as adaptation to local requirements or different weather data formats. In this paper, solpy, an object oriented open source python implementation, is presented. This software is capable of using historic or forecasted weather data to predict system performance as well as validate certain design constraints such as system voltage and conductor sizing. The developed software, solpy, compares favorably against NREL PV Watts and System Advisor Model.",photovoltaic system performance modeling - Python - annual energy output - photovoltaic solar systems - open source software - solpy - object oriented computing,"Charles, N.(1); Kabalan, M.(2); Singh, P.(2)",2015.0,Conference,2015 IEEE Canada International Humanitarian Technology Conference (IHTC2015),10.1109/IHTC.2015.7238046,"(1) Sustainable Eng. Program, Villanova Univ., Villanova, PA, United States; (2) Electr. & Comput. Eng., Villanova Univ., Villanova, PA, United States",IEEE,English,,
Inspec,Extending the design of a blocks-based python environment to support complex types,"We are currently developing PyBlocks, a blocks-based environment which allows novice programmers to construct and execute Python programs. In the initial design of PyBlocks [1], Python's basic data types and lists are represented using colors, every expression block is colored according to its type, and each unfilled slot contains color indicating all valid argument types. In this paper we extend the design to include Python's most common built-in composite types (lists, tuples, dictionaries and sets) and to allow nesting of these where appropriate. Using example types from a pedagogical media computation library, we also show how further types may be supported. Together, these extensions provide almost any type novice Python programmers are likely to use.",type-novice Python programmers - PyBlocks - initial design - Python programs - novice programmers - python environment - composite types - valid argument types - expression block,"Poole, M.(1)",2017.0,Conference,2017 IEEE Blocks and Beyond Workshop (B&B). Proceedings,10.1109/BLOCKS.2017.8120400,"(1) Sch. of Comput., Univ. of Portsmouth, Portsmouth, United Kingdom",IEEE,English,,
Inspec,D2o: A distributed data object for parallel high-performance computing in Python,"We introduce D2o, a Python module for cluster-distributed multi-dimensional numerical arrays. It acts as a layer of abstraction between the algorithm code and the data-distribution logic. The main goal is to achieve usability without losing numerical performance and scalability. D2o's global interface is similar to the one of a numpy.ndarray, whereas the cluster node's local data is directly accessible for use in customized high-performance modules. D2o is written in pure Python which makes it portable and easy to use and modify. Expensive operations are carried out by dedicated external libraries like numpy and mpi4py. The performance of D2o is on a par with numpy for serial applications and scales well when moving to an MPI cluster. D2o is open-source software available under the GNU General Public License v3 (GPL-3) at https://gitlab.mpcdf.mpg.de/ift/D2O.",D2o - distributed data object - parallel high-performance computing - Python module - cluster-distributed multidimensional numerical arrays - abstraction layer - algorithm code - data-distribution logic - numpy.ndarray - cluster node local data - customized high-performance modules - dedicated external libraries - mpi4py - MPI cluster - open-source software - GNU General Public License v3,"Steininger, T.(1); Greiner, M.(1); Beaujean, F.(2); Ensslin, T.(1)",2016.0,Journal,Journal of Big Data,10.1186/s40537-016-0052-5,"(1) Max Planck Inst. fur Astrophys., Garching, Germany; (2) Ludwig-Maximilians-Univ. Munchen, Mu¨nchen, Germany",Springer,English,2196-1115,
Inspec,D2O - a distributed data object for parallel high-performance computing in Python [arXiv],"We introduce D2O, a Python module for cluster-distributed multi-dimensional numerical arrays. It acts as a layer of abstraction between the algorithm code and the data-distribution logic. The main goal is to achieve usability without losing numerical performance and scalability. D2O's global interface is similar to the one of a numpy.ndarray, whereas the cluster node's local data is directly accessible for use in customized high-performance modules. D2O is written in pure Python which makes it portable and easy to use and modify. Expensive operations are carried out by dedicated external libraries like numpy and mpi4py. The performance of D2O is on a par with numpy for serial applications and scales well when moving to an MPI cluster. D2O is open-source software available under the GNU General Public License v3 (GPL-3) at https://gitlab.mpcdf.mpg.de/ift/D2O.",D2O - distributed data object - parallel high-performance computing - Python module - cluster-distributed multidimensional numerical arrays - usability - scalability - numpy - mpi4py - MPI cluster - open-source software - GNU General Public License v3 - GPL-3,"Steininger, T.(1); Greiner, M.(1); Beaujean, F.(2); Enßlin, T.(2)",2016.0,arXiv,arXiv,,"(1) Max Planck Inst. fur Astrophys., Garching, Germany; (2) Ludwig-Maximilians-Univ. Munchen, Munich, Germany",arXiv,English,,
Inspec,scraps: an open-source Python-based analysis package for analyzing and plotting superconducting resonator data,"We present “scraps” (SuperConducting Analysis and Plotting Software), a Python package designed to aid in the analysis and visualization of large amounts of superconducting resonator data, specifically complex transmission as a function of frequency, acquired at many different temperatures and driving powers. The package includes a least squares fitting engine as well as a Monte Carlo Markov Chain sampler for sampling the posterior distribution given priors, marginalizing over nuisance parameters, and estimating covariances. A set of plotting tools for generating publication-quality figures is also provided in the package. We discuss the functionality of the software and provide some examples of its utility on data collected from a niobium-nitride coplanar waveguide resonator fabricated at Argonne National Laboratory.",scraps - open-source Python-based analysis package - superconducting resonator data plotting - superconducting resonator data analysis - superconducting analysis and plotting software - superconducting resonator data visualization - frequency function - least squares fitting engine - Monte Carlo Markov Chain sampler - posterior distribution sampling - nuisance parameters - covariance estimation - plotting tools - publication-quality figure generation - software functionality - niobium-nitride coplanar waveguide resonator,"Carter, F.W.(1); Khaire, T.S.(1); Novosad, V.(1); Chang, C.L.(1)",2017.0,Journal,IEEE Transactions on Applied Superconductivity,10.1109/TASC.2016.2625767,"(1) Argonne Nat. Lab., Argonne, IL, United States",IEEE,English,1051-8223,
Inspec,Using B SP and Python to simplify parallel programming,"Scientific computing is usually associated with compiled languages for maximum efficiency. However, in a typical application program, only a small part of the code is time-critical and requires the efficiency of a compiled language. It is often advantageous to use interpreted high-level languages for the remaining tasks, adopting a mixed-language approach. This will be demonstrated for Python, an interpreted object-oriented high-level language that is well suited for scientific computing. Particular attention is paid to high-level parallel programming using Python and the BSP model. We explain the basics of BSP and how it differs from other parallel programming tools like MPI. Thereafter we present an application of Python and BSP for solving a partial differential equation from computational science, utilizing high-level design of libraries and mixed-language (Python-C or Python-Fortran) programming. [All rights reserved Elsevier].",scientific computing - Python - interpreted object-oriented high-level language - BSP model - MPI - partial differential equation - software library - Python-C - Python-Fortran programming - Message Passing Interface,"Hinsen, K.(1); Langtangen, H.P.; Skavhaug, O.; degard, A.",2006.0,Journal,Future Generation Computer Systems,10.1016/j.future.2003.09.003,"(1) Centre de Biophys. Moleculaire, UPR CNRS, Orleans, France",Elsevier,English,0167-739X,
Inspec,"PyFITS, a FITS module for Python","PyFITS is a module for reading, writing, and manipulating FITS files using the interactive, object-oriented language, Python. The module is composed of two files: a generic low-level C library for manipulating multidimensional arrays of C-type structures and a high-level Python module. FITS files can be manipulated at several different levels, beginning with the header-data unit at the highest level to rows and columns of binary tables at the lowest level. In addition, header-data units and columns of binary tables are accessible by index or name. PyFITS also interfaces to NumPy, the Python numerical array module.",object-oriented language - Python language - FITS module,"Barrett, P.E.(1); Bridgman, W.T.(1)",1999.0,Conference,Astronomical Society of the Pacific Conference Series,,"(1) NASA Goddard Space Flight Center, Greenbelt, MD, United States",Astron. Soc. Pacific,English,1050-3390,
Inspec,Stably extracting text contents from email messages with Python,"Extracting text contents from email messages is a fundamental task in email processing, such as spam mail identifying and email filtering. Although Python is a rapid application development language, there is not a library in Python which can efficiently and stably accomplish this task when facing versatile email formats in a real application. This paper proposes an approach to fulfill the task with three software layers. How to automatically evaluate it in a busy server environment has also been documented. It has been deployed in our email processing platform to extract text content of email messages on 24 hours per day and 7 days per week base. Its stable and effective performance improves our email filtering service to our customers. The principles in the approach can also be adopted to stabilize the performance of other software.",text content extraction - email message - Python-rapid application development language - email processing - HTML file - software architecture,"Sun, S.(1)",2009.0,Conference,2009 Second International Conference on the Applications of Digital Information and Web Technologies (ICADIWT),10.1109/ICADIWT.2009.5273961,"(1) Firstwave Technol., VIC, Australia",IEEE,English,,
Inspec,Measuring polymorphism in Python programs,"Following the increased popularity of dynamic languages and their increased use in critical software, there have been many proposals to retrofit static type system to these languages to improve possibilities to catch bugs and improve performance. A key question for any type system is whether the types should be structural, for more expressiveness, or nominal, to carry more meaning for the programmer. For retrofitted type systems, it seems the current trend is using structural types. This paper attempts to answer the question to what extent this extra expressiveness is needed, and how the possible polymorphism in dynamic code is used in practise. We study polymorphism in 36 real-world open source Python programs and approximate to what extent nominal and structural types could be used to type these programs. The study is based on collecting traces from multiple runs of the programs and analysing the polymorphic degrees of targets at more than 7 million call-sites. Our results show that while polymorphism is used in all programs, the programs are to a great extent monomorphic. The polymorphism found is evenly distributed across libraries and program-specific code and occur both during program start-up and normal execution. Most programs contain a few ``megamorphic'' call-sites where receiver types vary widely. The non-monomorphic parts of the programs can to some extent be typed with nominal or structural types, but none of the approaches can type entire programs.",polymorphism - dynamic languages - static type system - bugs - retrofitted type systems - open source Python programs - polymorphic degrees - program-specific code - megamorphic call-sites - nominal types - structural types,"Kerblom, B.(1); Wrigstad, T.(2)",2016.0,Journal,ACM SIGPLAN Notices,10.1145/2936313.2816717,"(1) Stockholm Univ., Stockholm, Sweden; (2) Uppsala Univ., Uppsala, Sweden",ACM,English,0362-1340,
Inspec,PyFAI: a Python library for high performance azimuthal integration on GPU,PyFAI is an open-source Python library for Fast Azimuthal Integration which provides 1Dand 2D-azimuthal regrouping with a clean programming interface and tools for calibration. The library is suitable for interactive use in Python. In optimising the speed of the algorithms there has been no compromise on the accuracy compared to reference software. Fast integrations are obtained by the combination of an algorithm ensuring that each pixel from the detector provides a direct contribution to the final diffraction pattern and an OpenCL implementation that can use graphics cards for acceleration. This contribution describes how the algorithms were modified to work better in parallel.,azimuthal integration performance - GPU - open-source Python library - fast azimuthal integration - 1D-azimuthal regrouping - 2D-azimuthal regrouping - programming interface - calibration - reference software - diffraction pattern - OpenCL implementation - graphics card,"Kieffer, J.(1); Wright, J.P.(1)",2013.0,Journal,Powder Diffraction,,"(1) Eur. Synchrotron Radiat. Facility, Grenoble, France",Cambridge University Press,English,0885-7156,
Inspec,Automation of transmission planning analysis process using Python and GTK+,"To decrease the amount of time and effort needed to perform transmission planning analysis required by PJM reliability criteria, the open source Python language has been used to automate these processes. To make these programs easier to use, an open source graphical toolkit, the GIMP toolkit (GTK+), was also utilized along with Glade, a tool that can be used to easily create graphical user interfaces. All of these software development tools can be freely obtained and are easy to install. Our applications were developed for the Microsoft Windows operating system, although Python, GTK+, and Glade are also available for other platforms such as Linux. This paper presents the basic building blocks needed to create an application and summarizes the steps required for rapid software tool development with application to power systems analysis.",transmission planning analysis process - Python language - GIMP toolkit - open source graphical toolkit - graphical user interfaces - software development tools - Microsoft Windows operating system - Linux - Glade - power systems analysis,"Condren, J.; Seungwon An",2006.0,Conference,2006 IEEE Power Engineering Society General Meeting,,,IEEE,English,,1-4244-0493-2
Inspec,Geomstats: a python package for riemannian geometry in machine learning [arXiv],"We introduce Geomstats, an open-source Python toolbox for computations and statistics on nonlinear manifolds, such as hyperbolic spaces, spaces of symmetric positive definite matrices, Lie groups of transformations, and many more. We provide object-oriented and extensively unit-tested implementations. Among others, manifolds come equipped with families of Riemannian metrics, with associated exponential and logarithmic maps, geodesics and parallel transport. Statistics and learning algorithms provide methods for estimation, clustering and dimension reduction on manifolds. All associated operations are vectorized for batch computation and provide support for different execution backends, namely NumPy, PyTorch and TensorFlow, enabling GPU acceleration. This paper presents the package, compares it with related libraries and provides relevant code examples. We show that Geomstats provides reliable building blocks to foster research in differential geometry and statistics, and to democratize the use of Riemannian geometry in machine learning applications. The source code is freely available under the MIT license at \url{geomstats.ai}.",nonlinear manifolds - hyperbolic spaces - symmetric positive definite matrices - Riemannian metrics - exponential maps - logarithmic maps - learning algorithms - dimension reduction - batch computation - GPU acceleration - differential geometry - Riemannian geometry - machine learning applications - open-source Python toolbox,"Miolane, N.; Le Brigant, A.; Mathe, J.; Hou, B.; Guigui, N.; Thanwerdas, Y.; Heyder, S.; Peltre, O.; Koep, N.; Zaatiti, H.; Hajri, H.; Cabanes, Y.; Gerald, T.; Chauchat, P.; Shewmake, C.; Kainz, B.; Donnat, C.; Holmes, S.; Pennec, X.",2020.0,arXiv,arXiv,,,arXiv,English,,
Inspec,PyGOLD: a python based API for docking based virtual screening workflow generation,"Motivation: Molecular docking is one of the successful approaches in structure based discovery and development of bioactive molecules in chemical biology and medicinal chemistry. Due to the huge amount of computational time that is still required, docking is often the last step in a virtual screening approach. Such screenings are set as workflows spanned over many steps, each aiming at different filtering task. These workflows can be automatized in large parts using python based toolkits except for docking using the docking software GOLD. However, within an automated virtual screening workflow it is not feasible to use the GUI in between every step to change the GOLD configuration file. Thus, a python module called PyGOLD was developed, to parse, edit and write the GOLD configuration file and to automate docking based virtual screening workflows.",PyGOLD - docking based virtual screening workflow generation - structure based discovery - bioactive molecules - chemical biology - medicinal chemistry - virtual screening approach - docking software GOLD - automated virtual screening workflow - GOLD configuration file - docking based virtual screening workflows - molecular docking - Python based toolkits,"Patel, H.; Brinkjost, T.; Koch, O.",2017.0,Journal,Bioinformatics,10.1093/bioinformatics/btx197,,Oxford University Press,English,1367-4803,
Inspec,Pytrec_eval: An Extremely Fast Python Interface to trec_eval [arXiv],"We introduce pytrec_eval, a Python interface to the tree_eval information retrieval evaluation toolkit. pytrec_eval exposes the reference implementations of trec_eval within Python as a native extension. We show that pytrec_eval is around one order of magnitude faster than invoking trec_eval as a sub process from within Python. Compared to a native Python implementation of NDCG, pytrec_eval is twice as fast for practically-sized rankings. Finally, we demonstrate its effectiveness in an application where pytrec_eval is combined with Pyndri and the OpenAI Gym where query expansion is learned using Q-learning. [doi:10.1145/3209978.3210065].",pytrec_eval - tree_eval information retrieval evaluation toolkit - OpenAI Gym - Pyndri - Q-learning - query expansion - Python interface,"Van Gysel, C.(1); de Rijke, M.(1)",2018.0,arXiv,arXiv,,"(1) Univ. of Amsterdam Amsterdam, Amsterdam, Netherlands",arXiv,English,,
Inspec,A Python Instrument Control and Data Acquisition Suite for Reproducible Research,"Tools that standardize and automate experimental data collection are needed for greater confidence in research results. The National Synchrotron Light Source-II (NSLS-II) has generated an open-source Python data acquisition, management, and analysis software suite that automates X-ray experiments and collects an experimental record that facilitates complete reproducibility. Here, we show that the NSLS-II tools are not only useful for X-ray science at large-scale facilities by presenting an add-on package that adapts these tools for use in a small laboratory with common physics and electrical engineering instruments. The composite software suite eases and automates the execution of experiments, records extensive metadata, stores data in portable containers, and speeds up the analysis through tools for comprehensive searches. In total, this software suite increases the reproducibility of laboratory experiments. We demonstrate the software via the evaluation of two lock-in amplifiers-the miniature ADA2200 and the ubiquitous Stanford Research Systems (SRS) SR810. The frequency resolution, signal-to-noise ratio, and dynamic reserve of the lock-in amplifiers are measured and presented. The usage of the software suite is described throughout these measurements so that the reader can implement the tools in their lab.",composite software suite - experimental data collection automation - laboratory experiments reproducibility - electrical engineering instruments - common physics - large-scale facilities - X-ray science - NSLS-II tools - facilitates complete reproducibility - experimental record - X-ray experiments - National Synchrotron Light Source-II - standardize - reproducible research - data acquisition suite - Python instrument control - ubiquitous Stanford Research Systems SR810 - stores data - extensive metadata,"Koerner, L.J.(1); Caswell, T.A.(2); Allan, D.B.(2); Campbell, S.I.(2)",2020.0,Journal,IEEE Transactions on Instrumentation and Measurement,10.1109/TIM.2019.2914711,"(1) Dept. of Electr. & Comput. Eng., Univ. of St. Thomas, St. Paul, MN, United States; (2) Nat. Synchrotron Light Source II, Brookhaven Nat. Lab., Upton, NY, United States",IEEE,English,0018-9456,
Inspec,ConKit: a python interface to contact predictions,"Summary: Recent advances in protein residue contact prediction algorithms have led to the emergence of many new methods and a variety of file formats. We present ConKit, an open source, modular and extensible Python interface which allows facile conversion between formats and provides an interface to analyses of sequence alignments and sets of contact predictions.",ConKit - contact prediction algorithms - file formats - open source - modular Python interface - extensible Python interface - sequence alignments - facile conversion,"Simkovic, F.(1); Thomas, J.M.H.(1); Rigden, D.J.(1)",2017.0,Journal,Bioinformatics,10.1093/bioinformatics/btx148,"(1) Dept. of Biochem., Univ. of Liverpool, Liverpool, United Kingdom",Oxford University Press,English,1367-4803,
Inspec,Gumpy: a Python toolbox suitable for hybrid brain-computer interfaces,"Objective. The objective of this work is to present gumpy, a new free and open source Python toolbox designed for hybrid brain-computer interface (BCI). Approach. Gumpy provides state-of-the-art algorithms and includes a rich selection of signal processing methods that have been employed by the BCI community over the last 20 years. In addition, a wide range of classification methods that span from classical machine learning algorithms to deep neural network models are provided. Gumpy can be used for both EEG and EMG biosignal analysis, visualization, real-time streaming and decoding. Results. The usage of the toolbox was demonstrated through two different offline example studies, namely movement prediction from EEG motor imagery, and the decoding of natural grasp movements with the applied finger forces from surface EMG (sEMG) signals. Additionally, gumpy was used for real-time control of a robot arm using steady-state visually evoked potentials (SSVEP) as well as for real-time prosthetic hand control using sEMG. Overall, obtained results with the gumpy toolbox are comparable or better than previously reported results on the same datasets. Significance. Gumpy is a free and open source software, which allows end-users to perform online hybrid BCIs and provides different techniques for processing and decoding of EEG and EMG signals. More importantly, the achieved results reveal that gumpy's deep learning toolbox can match or outperform the state-of-the-art in terms of accuracy. This can therefore enable BCI researchers to develop more robust decoding algorithms using novel techniques and hence chart a route ahead for new BCI improvements.",free source Python toolbox - open source Python toolbox - deep neural network models - surface EMG signals - steady-state visually evoked potentials - real-time prosthetic hand control - gumpy toolbox - free source software - open source software - deep learning toolbox - robust decoding algorithms - Python toolbox - hybrid brain-computer interface - signal processing methods - BCI community - classification methods - classical machine learning algorithms - EMG biosignal analysis - EEG biosignal analysis - real-time streaming - movement prediction - EEG motor imagery - natural grasp movement decoding - finger forces - robot arm,"Tayeb, Z.(1); Waniek, N.(1); Fedjaev, J.(1); Ghaboosi, N.(2); Rychly, L.(1); Widderich, C.(1); Richter, C.(1); Braun, J.(1); Saveriano, M.(3); Cheng, G.(4); Conradt, J.(1)",2018.0,Journal,Journal of Neural Engineering,10.1088/1741-2552/aae186,"(1) Dept. of Electr. & Comput. Eng., Tech. Univ. of Munich, Munich, Germany; (2) Integrated Res., Sydney, NSW, Australia; (3) German Aerosp. Center, Inst. of Robot. & Mechatron., Munich, Germany; (4) Inst. for Cognitive Syst., Tech. Univ. of Munich, Munich, Germany",IOP Publishing,English,1741-2560,
Inspec,MABWiser: A Parallelizable Contextual Multi-Armed Bandit Library for Python,"Contextual multi-armed bandit algorithms serve as an effective technique to address online sequential decision-making problems. Despite their popularity, when it comes to off-the-shelf tools the library support remains limited, in particular for the Python technology stack. To fill this gap, in this paper we present a system that provides context-free, parametric and non-parametric contextual multi-armed bandit models. The available bandit policies accommodate both batch and online learning. The MABWISER system is implemented as an open-source Python library. Our design enables built-in parallelization to speed up training and test components for scalability while ensuring the reproducibility of results. We present a running example to highlight the user-friendly nature of the public interface and discuss the simulation capability of the library for hyper-parameter tuning and rapid experimentation.",off-the-shelf tools - library support - Python technology stack - nonparametric contextual multiarmed bandit models - available bandit policies - online learning - MABWISER system - open-source Python library - parallelizable contextual multiarmed bandit library - contextual multiarmed bandit algorithms - online sequential decision-making problems,"Strong, E.(1); Kleynhans, B.(1); Kadioglu, S.(1)",2019.0,Conference,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI). Proceedings,10.1109/ICTAI.2019.00129,"(1) Fidelity Investments, Boston, MA, United States",IEEE Computer Society,English,,
Inspec,QuCAT: quantum circuit analyzer tool in Python,"Quantum circuits constructed from Josephson junctions and superconducting electronics are key to many quantum computing and quantum optics applications. Designing these circuits involves calculating the Hamiltonian describing their quantum behavior. Here we present QuCAT, or `Quantum Circuit Analyzer Tool', an open-source framework to help in this task. This open-source Python library features an intuitive graphical or programmatical interface to create circuits, the ability to compute their Hamiltonian, and a set of complimentary functionalities such as calculating dissipation rates or visualizing current flow in the circuit.",current flow - programmatical interface - graphical interface - superconducting electronics - Josephson junctions - open-source Python library - open-source framework - QuCAT - quantum behavior - quantum optics applications - quantum computing - quantum circuit analyzer tool,"Gely, M.F.(1); Steele, G.A.(1)",2020.0,Journal,New Journal of Physics,10.1088/1367-2630/ab60f6,"(1) Kavli Inst. of Nanosci., Delft Univ. of Technol., Delft, Netherlands",IOP Publishing,English,1367-2630,
Inspec,"Diffprivlib: The IBM Differential Privacy Library: A general purpose, open source Python library for differential privacy [arXiv]","Since its conception in 2006, differential privacy has emerged as the de-facto standard in data privacy, owing to its robust mathematical guarantees, generalised applicability and rich body of literature. Over the years, researchers have studied differential privacy and its applicability to an ever-widening field of topics. Mechanisms have been created to optimise the process of achieving differential privacy, for various data types and scenarios. Until this work however, all previous work on differential privacy has been conducted on a ad-hoc basis, without a single, unifying codebase to implement results. In this work, we present the IBM Differential Privacy Library, a general purpose, open source library for investigating, experimenting and developing differential privacy applications in the Python programming language. The library includes a host of mechanisms, the building blocks of differential privacy, alongside a number of applications to machine learning and other data analytics tasks. Simplicity and accessibility has been prioritised in developing the library, making it suitable to a wide audience of users, from those using the library for their first investigations in data privacy, to the privacy experts looking to contribute their own models and mechanisms for others to use.",data privacy - Diffprivlib - IBM differential privacy library - open source Python library - Python programming language - machine learning,"Holohan, N.(1); Braghin, S.(1); Mac Aonghusa, P.(1); Levacher, K.(1)",2019.0,arXiv,arXiv,,"(1) IBM Res. - Ireland, Ireland",arXiv,English,,
Inspec,PyPerC: Python toolbox for perceptual computing,In this paper we present a new toolbox that is developed for perceptual computing (PerC). This toolbox provides all requirements to implement PerC applications on different platforms and hence will promote perceptual computers in various domains. We will demonstrate the effectiveness of the developed procedures and will also describe an example of implementing a perceptual computer with the proposed toolbox.,PyPerC - perceptual computer - PerC applications - perceptual computing - Python toolbox,"Ghanavati, Z.A.(1); Katebzadeh, M.(1); Tahayori, H.(1); Khunjush, F.(1)",2018.0,Conference,2018 6th Iranian Joint Congress on Fuzzy and Intelligent Systems (CFIS),10.1109/CFIS.2018.8336650,"(1) Dept. of Comput. Sci. & Eng. & IT, Shiraz Univ., Shiraz, Iran",IEEE,English,,
Inspec,Cloud segmentation property extraction from total sky image repositories using Python,"Acquiring the reflectance, radiance, and related structural cloud properties from repositories of historical sky images is a challenging and a computationally intensive task, especially when performed manually or by means of nonautomated approaches. In this article, a quick and efficient, self-adaptive Python tool for the acquisition, and analysis of cloud segmentation properties that is applicable to images from all-sky image repositories is presented and a case study demonstrating its usage and the overall efficacy of the technique is demonstrated. The proposed Python tool aims to build a new data extraction technique and to improve the accessibility of data to future researchers, utilizing the freely available libraries in the Python programing language with the ability to be translated into other programing languages. After development and testing of the Python tool in determining cloud and whole sky segmentation properties, over 42,000 sky images were analyzed in a relatively short time of just under 40 min, with an average execution time of about 0.06 s to complete each image analysis.",cloud segmentation property extraction - reflectance - historical sky images - computationally intensive task - self-adaptive Python tool - cloud segmentation properties - all-sky image repositories - data extraction technique - Python programing language - sky segmentation properties - image analysis - sky image repositories - structural cloud properties,"Igoe, D.P.(1); Parisi, A.V.(1); Downs, N.J.(1)",2019.0,Journal,Instrumentation Science & Technology,10.1080/10739149.2019.1603996,"(1) Sch. of Agric., Comput. & Environ. Sci., Univ. of Southern Queensland, Toowoomba, QLD, Australia",Taylor & Francis,English,1073-9149,
Inspec,Algorithms for Random Maps Generation and Their Implementation as a Python Library,"Random map generation has application in strategy computer games, terrain simulators, and other areas. In this paper basic assumptions of a library for random maps generation are presented. It uses both value noise and diamond square computer graphics algorithms, as well as newly invented algorithms for biomes creation and river generation. Complete library implementation with an example use in a separate application is explained in detail. Basic issues related to developing programming libraries and random map generations are also discussed.",Python Library - programming libraries - river generation - biomes creation - diamond square computer graphics algorithms - value noise - random map generation,"Rusek, M.(1); Jusiak, R.(1); Karwowski, W.(1)",2018.0,Conference,"Computer Vision and Graphics. International Conference, ICCVG 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11114)",10.1007/978-3-030-00692-1_6,"(1) Fac. of Appl. Inf. & Math., Warsaw Univ. of Life Sci., Warsaw, Poland",Springer International Publishing,English,,
Inspec,MiSTree: a Python package for constructing and analysing Minimum Spanning Trees [arXiv],"The minimum spanning tree (MST), a graph constructed from a distribution of points, draws lines between pairs of points so that all points are linked in a single skeletal structure that contains no loops and has minimal total edge length. The MST has been used in a broad range of scientific fields such as particle physics (to distinguish classes of events in collider collisions), in astronomy (to detect mass segregation in star clusters) and cosmology (to search for filaments in the cosmic web). Its success in these fields has been driven by its sensitivity to the spatial distribution of points and the patterns within. MiSTree, a public Python package, allows a user to construct the MST in a variety of coordinates systems, including Celestial coordinates used in astronomy. The package enables the MST to be constructed quickly by initially using a k-nearest neighbour graph (kNN, rather than a matrix of pairwise distances) which is then fed to Kruskal's algorithm to construct the MST. MiSTree enables a user to measure the statistics of the MST and provides classes for binning the MST statistics (into histograms) and plotting the distributions. Applying the MST will enable the inclusion of high-order statistics information from the cosmic web which can provide additional information to improve cosmological parameter constraints. This information has not been fully exploited due to the computational cost of calculating N-point statistics. MiSTree was designed to be used in cosmology but could be used in any field which requires extracting non-Gaussian information from point distributions. The source code for MiSTree is available on GitHub at https://github.com/knaidoo29/mistree. [Journal of Open Source Software, 4(42), 1721, 2019 doi:10.21105/joss.01721].",astronomy - high-order statistics information - Kruskal algorithm - k-nearest neighbour graph - source code - Python package - minimum spanning tree - point distributions - MiSTree - N-point statistics - cosmic web - MST statistics,"Naidoo, K.(1)",2019.0,arXiv,arXiv,,"(1) Dept. of Phys. & Astron., Univ. Coll. London, London, United Kingdom",arXiv,English,,
Inspec,Hearth Detection System Using Coherence Function on python for Tachycardia and Bradycardia,"When we see a heart problem the response time is crucial for a secure diagnostic. [1] In a previous work a functional prototype was made that allows to determine if a person has tachycardia or bradycardia as an existing pathology. The work was done using MATLAB software; however, this software is licensed and difficult to access since it is not free source. Under this limitation the prototype was reformulated in an open language known as PYTHON. The objective is to be able to achieve the same results as with the previous prototype without affecting the diagnosis. Based on this, a system was developed that diagnoses tachycardia and bradycardia with free software. Pathology detection is performed using a developed algorithm that mixes 3 comparison methods, such as cross spectrum. MSC and coherence. Upon capturing the ECG signal from the patient, the signal enters a DSP that uses these methods and will compare the entry ECG signal with a database created that contains all the possible existing signals according to the medical parameters corresponding to tachycardia and bradycardia. Resulting in a reliable diagnosis.",hearth detection system - coherence function - heart problem - response time - functional prototype - MATLAB software - free source - open language - PYTHON - bradycardia - free software - pathology detection - entry ECG signal - tachycardia diagnosis,"Alvarado, G.(1); Kukan, G.(1)",2019.0,Conference,"2019 4th International Conference on Electrical, Electronics, Communication, Computer Technologies and Optimization Techniques (ICEECCOT)",10.1109/ICEECCOT46775.2019.9114760,"(1) Dept. of GISTEL, Salesian Polytech. Univ., Guayaquil, Ecuador",IEEE,English,,
Inspec,mumpce_py: a Python implementation of the method of uncertainty minimization using polynomial chaos expansions,"The Method of Uncertainty Minimization using Polynomial Chaos Expansions (MUM-PCE) was developed as a software tool to constrain physical models against experimental measurements. These models contain parameters that cannot be easily determined from first principles and so must be measured, and some which cannot even be easily measured. In such cases, the models are validated and tuned against a set of global experiments which may depend on the underlying physical parameters in a complex way. The measurement uncertainty will affect the uncertainty in the parameter values. MUM-PCE was written to provide a streamlined workflow for computational uncertainty analysis. The software cannot be used out of the box. Users must create an interface to their own software, and that interface will be specific to the user's application. Two examples of how to write an interface are provided.",interface - Python implementation - mumpce_py - computational uncertainty analysis - streamlined workflow - measurement uncertainty - physical models - software tool - polynomial chaos expansions - method of uncertainty minimization,"Sheen, D.A.(1)",2017.0,Journal,Journal of Research of the National Institute of Standards and Technology,10.6028/jres.122.039,"(1) Nat. Inst. of Stand. & Technol., Gaithersburg, MD, United States",National Institute of Standards and Technology,English,1044-677X,
Inspec,Mango: A Python Library for Parallel Hyperparameter Tuning,"Tuning hyperparameters for machine learning algorithms is a tedious task, one that is typically done manually. To enable automated hyperparameter tuning, recent works have started to use techniques based on Bayesian optimization. However, to practically enable automated tuning for large scale machine learning training pipelines, significant gaps remain in existing libraries, including lack of abstractions, fault tolerance, and flexibility to support scheduling on any distributed computing framework. To address these challenges, we present Mango, a Python library for parallel hyperparameter tuning. Mango enables the use of any distributed scheduling framework, implements intelligent parallel search strategies, and provides rich abstractions for defining complex hyperparameter search spaces that are compatible with scikit-learn. Mango is comparable in performance to Hyperopt [1], another widely used library. Mango is available open-source [2] and is currently used in production at Arm Research to provide state-of-art hyperparameter tuning capabilities.",Mango - Python library - parallel hyperparameter tuning - automated hyperparameter tuning - machine learning - distributed computing - distributed scheduling - complex hyperparameter search spaces - scikit-learn - intelligent parallel search strategies - Bayesian optimization,"Sandha, S.S.; Aggarwal, M.; Fedorov, I.; Srivastava, M.",2020.0,Conference,"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). Proceedings",10.1109/ICASSP40776.2020.9054609,,IEEE,English,,
Inspec,The Python Sky Model: software for simulating the Galactic microwave sky,"We present a numerical code to simulate maps of Galactic emission in intensity and polarization at microwave frequencies, aiding in the design of cosmic microwave background experiments. This PYTHON code builds on existing efforts to simulate the sky by providing an easy-to-use interface and is based on publicly available data from the WMAP (Wilkinson Microwave Anisotropy Probe) and Planck satellite missions. We simulate synchrotron, thermal dust, free-free and anomalous microwave emission over the whole sky, in addition to the cosmic microwave background, and include a set of alternative prescriptions for the frequency dependence of each component, for example, polarized dust with multiple temperatures and a decorrelation of the signals with frequency, which introduce complexity that is consistent with current data. We also present a new prescription for adding small-scale realizations of these components at resolutions greater than current all-sky measurements. The usefulness of the code is demonstrated by forecasting the impact of varying foreground complexity on the recovered tensor-to-scalar ratio for the LiteBIRD satellite. The code is available at: https://github.com/bthorne93/PySM_public.",numerical code - Galactic emission - microwave frequencies - cosmic microwave background experiments - PYTHON code - WMAP satellite mission - Planck satellite mission - Wilkinson Microwave Anisotropy Probe - synchrotron emission - thermal dust emission - free-free emission - anomalous microwave emission - polarized dust - all-sky measurements - tensor-to-scalar ratio - LiteBIRD satellite - Python sky model - Galactic microwave sky,"Thorne, B.(1); Dunkley, J.(1); Alonso, D.(1); Næss, S.(1)",2017.0,Journal,Monthly Notices of the Royal Astronomical Society,10.1093/mnras/stx949,"(1) Dept. of Phys., Univ. of Oxford, Oxford, United Kingdom",Oxford University Press,English,0035-8711,
Inspec,FluidDyn: a Python open-source framework for research and teaching in fluid dynamics [arXiv],"FluidDyn is a project to foster open-science and open-source in the fluid dynamics community. It is thought of as a research project to channel open-source dynamics, methods and tools to do science. We propose a set of Python packages forming a framework to study fluid dynamics with different methods, in particular laboratory experiments (package fluidlab), simulations (packages fluidfft, fluidsim and fluidfoam) and data processing (package fluidimage). In the present article, we give an overview of the specialized packages of the project and then focus on the base package called fluiddyn, which contains common code used in the specialized packages. Packages fluidfft and fluidsim are described with greater detail in two companion papers, Mohanan et al. (2018a,b). With the project FluidDyn, we demonstrate that specialized scientific code can be written with methods and good practices of the open-source community. The Mercurial repositories are available in Bitbucket (https://bitbucket.org/fluiddyn/). All codes are documented using Sphinx and Read the Docs, and tested with continuous integration run on Bitbucket, Pipelines and Travis. To improve the reuse potential, the codes are as modular as possible, leveraging the simple object-oriented programming model of Python. All codes are also written to be highly efficient, using C++, Cython and Pythran to speedup the performance of critical functions.",Python open-source framework - open-science - Python packages - fluidsim - fluidfoam - specialized scientific code - open-source community - FluidDyn - fluid dynamics teaching - fluidlab - fluidfft - fluidimage - fluiddyn - Bitbucket - Sphinx - Read the Docs - Pipelines - Travis - object-oriented programming model - C++ - Cython - Pythran - fluid dynamics research,"Augier, P.(1); Mohanan, A.V.(2); Bonamy, C.(1)",2018.0,arXiv,arXiv,,"(1) LEGI, Univ. Grenoble Alpes, Grenoble, France; (2) Dept. of Mech., KTH, Stockholm, Sweden",arXiv,English,,
Inspec,Asynchronous Execution of Python Code on Task-based Runtime Systems,"Despite advancements in the areas of parallel and distributed computing, the complexity of programming on High Performance Computing (HPC) resources has deterred many domain experts, especially in the areas of machine learning and artificial intelligence (AI), from utilizing performance benefits of such systems. Researchers and scientists favor high-productivity languages to avoid the inconvenience of programming in low-level languages and costs of acquiring the necessary skills required for programming at this level. In recent years, Python, with the support of linear algebra libraries like NumPy, has gained popularity despite facing limitations which prevent this code from distributed runs. Here we present a solution which maintains both high level programming abstractions as well as parallel and distributed efficiency. Phylanx, is an asynchronous array processing toolkit which transforms Python and NumPy operations into code which can be executed in parallel on HPC resources by mapping Python and NumPy functions and variables into a dependency tree executed by HPX, a general purpose, parallel, task-based runtime system written in C++. Phylanx additionally provides introspection and visualization capabilities for debugging and performance analysis. We have tested the foundations of our approach by comparing our implementation of widely used machine learning algorithms to accepted NumPy standards.",asynchronous execution - task-based runtime system - machine learning - artificial intelligence - linear algebra libraries - high level programming abstractions - asynchronous array processing toolkit - NumPy operations - high performance computing resources - Phylanx - Python code execution - parallel computing - distributed computing - dependency tree - HPX system,"Tohid, R.(1); Wagle, B.(1); Shirzad, S.(1); Diehl, P.(1); Serio, A.(1); Kheirkhahan, A.(1); Amini, P.(1); Williams, K.(2); Isaacs, K.(2); Huck, K.(3); Brandt, S.(1); Kaiser, H.(1)",2018.0,Conference,2018 IEEE/ACM 4th International Workshop on Extreme Scale Programming Models and Middleware (ESPM2),10.1109/ESPM2.2018.00009,"(1) Louisiana State Univ., Baton Rouge, LA, United States; (2) Univ. of Arizona, Tucson, AZ, United States; (3) Univ. of Oregon, Eugene, OR, United States",IEEE Computer Society,English,,
Inspec,Using Python for Mapping Molecular Dynamics Simulation Openmm Onto the Xeon Phi Architecture,"In seeking to accelerate the mathematically intense engineering and scientific applications, parallel computing is used to bypass the physical limitations of traditional stand-alone CPU based systems. This has led to the creation of new hardware and software paradigms developed in tandem for future performance gains. The thrust of this paper is to investigate the performance of applications and code run in two distinct hardware configurations: standalone 16-Core 2.3 GHz Intel Xeon E5-2968 CPU and the Xeon E5 coupled with dual Xeon Phi 7120 61-Core 1.25GHz Intel Many Integrated Core (MIC) Architecture. The hardware configurations were implemented under different software environments: standard Python, Intel's distribution of Python and both Python versions with Automatic Offloading enabled. The results revealed a significant increase in application performance when implemented under Intel's distribution of Python combined with the offloading of computationally demanding portions of the code to the host co-processors.",software environments - molecular dynamics simulation - hardware configurations - standalone 16-Core 2.3 GHz Intel Xeon E5-2968 CPU - Openmm - parallel computing - Xeon Phi Architecture - application performance - Python versions - dual Xeon Phi 7120 61-Core 1.25GHz Intel,"Morris, O.A.(1); Abed, K.H.(1)",2018.0,Conference,SoutheastCon 2018,10.1109/SECON.2018.8478913,"(1) Dept. of Electr. & Comput. Eng., Jackson State Univ., Jackson, MS, United States",IEEE,English,,
Inspec,EvoCluster: An Open-Source Nature-Inspired Optimization Clustering Framework in Python,"EvoCluster is an open source and cross-platform framework implemented in Python which includes the most well-known and recent nature-inspired metaheuristic optimizers that are customized to perform partitional clustering tasks. The goal of this framework is to provide a user-friendly and customizable implementation of the metaheuristic based clustering algorithms which can be utilized by experienced and non-experienced users for different applications. The framework can also be used by researchers who can benefit from the implementation of the metaheuristic optimizers for their research studies. EvoCluster can be extended by designing other optimizers, including more objective functions, adding other evaluation measures, and using more data sets. The current implementation of the framework includes ten metaheristic optimizers, thirty datasets, five objective functions, and twelve evaluation measures. The source code of EvoCluster is publicly available at (http://evo-ml.com/2019/10/25/evocluster/).",open-source nature-inspired optimization - Python - cross-platform framework - partitional clustering tasks - objective functions - source code - EvoCluster,"Qaddoura, R.(1); Faris, H.(2); Aljarah, I.(2); Castillo, P.A.(3)",2020.0,Conference,"Applications of Evolutionary Computation. 23rd European Conference, EvoApplications 2020. Held as Part of EvoStar 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12104)",10.1007/978-3-030-43722-0_2,"(1) Inf. Technol., Philadelphia Univ., Amman, Jordan; (2) King Abdullah II Sch. for Inf. Technol., Univ. of Jordan, Amman, Jordan; (3) ETSIIT-CITIC, Univ. of Granada, Granada, Spain",Springer International Publishing,English,,
Inspec,New List Skeletons for the Python Skeleton Library,"Algorithmic skeletons are patterns of parallel computations. Skeletal parallel programming eases parallel programming: a program is merely a composition of such patterns. Data-parallel skeletons operate on parallel data-structures that have often sequential counterparts. In algorithmic skeleton approaches that offer a global view of programs, a parallel program has therefore a structure similar to a sequential program but operates on parallel data-structures. PySke is such an algorithmic skeleton library for Python to program shared or distributed memory parallel architectures in a simple way. This paper presents an extension to PySke: new algorithmic skeletons on parallel lists. This extension is evaluated on an application.",parallel lists - new list skeletons - Python skeleton library - parallel computations - skeletal parallel programming - data-parallel skeletons - parallel data-structures - sequential program - algorithmic skeleton library - distributed memory parallel architecture - shared memory parallel architecture - PySke,"Loulergue, F.(1); Philippe, J.(2)",2019.0,Conference,"2019 20th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)",10.1109/PDCAT46702.2019.00077,"(1) Sch. of Inf. Comput. & Cyber Syst., Northern Arizona Univ., Flagstaff, AZ, United States; (2) IMT Atlantique, Inria, Nantes, France",IEEE,English,,
Inspec,Py4JFML: A Python wrapper for using the IEEE Std 1855-2016 through JFML,"JFML is an open source Java library aimed at facilitating interoperability of fuzzy systems by implementing the IEEE Std 1855-2016 - the IEEE Standard for Fuzzy Markup Language (FML) that is sponsored by the IEEE Computational Intelligence Society. We developed a Python wrapper for JFML that enables to use all the functionalities of JFML through a Python 3.x module. The bridge between Python and Java is accomplished through the use of the Py4J framework. As a result, the possibility of using the IEEE standard for representing fuzzy systems is enlarged to a wider community of developers and knowledge engineers, with minimal code redundancy. Experiments show full interoperability between Python programs and JFML without any tangible overhead. We illustrate the use of Py4JFML in a beer style classification case study.",Py4JFML - Python wrapper - IEEE Std 1855-2016 - open source Java library - fuzzy systems - Fuzzy Markup Language - Python 3.x module - Py4J framework - IEEE standard - Python programs - minimal code redundancy - interoperability - beer style classification,"Alcala-Fdez, J.(1); Alonso, J.M.(2); Castiello, C.(3); Mencar, C.(3); Soto-Hidalgo, J.M.(4)",2019.0,Conference,2019 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),10.1109/FUZZ-IEEE.2019.8858811,"(1) Dept. of Comput. Sci. & Artificial Intell., Univ. of Granada, Granada, Spain; (2) Centro Singular de Investig. en Tecnoloxias da Informacion, Univ. of Santiago de Compostela, Santiago de Compostela, Spain; (3) Dept. of Inf., Univ. of Bari Aldo Moro, Bari, Italy; (4) Dept. of Electr. & Comput. Eng., Univ. of Cordoba, Cordoba, Spain",IEEE,English,,
Inspec,PySAT: A Python Toolkit for Prototyping with SAT Oracles,"Boolean satisfiability (SAT) solvers are at the core of efficient approaches for solving a vast multitude of practical problems. Moreover, albeit targeting an NP-complete problem, SAT solvers are increasingly used for tackling problems beyond NP. Despite the success of SAT in practice, modeling with SAT and more importantly implementing SAT-based problem solving solutions is often a difficult and error-prone task. This paper proposes the PySAT toolkit, which enables fast Python-based prototyping using SAT oracles and SAT-related technology. PySAT provides a simple API for working with a few state-of-the-art SAT oracles and also integrates a number of cardinality constraint encodings, all aiming at simplifying the prototyping process. Experimental results presented in the paper show that PySAT-based implementations can be as efficient as those written in a low-level language.",Python toolkit - boolean satisfiability solvers - NP-complete problem - PySAT toolkit - Python-based prototyping - error-prone task - SAT Oracles - cardinality constraint encoding - problem solving solution,"Ignatiev, A.(1); Morgado, A.(1); Marques-Silva, J.(1)",2018.0,Conference,"Theory and Applications of Satisfiability Testing - SAT 2018. 21st International Conference, SAT 2018 Held as Part of the Federated Logic Conference, FloC 2018. Proceedings: LNCS 10929",10.1007/978-3-319-94144-8_26,"(1) LASIGE, Univ. de Lisboa, Lisbon, Portugal",Springer International Publishing,English,,
Inspec,holpy: Interactive Theorem Proving in Python [arXiv],"The design of modern proof assistants is faced with several sometimes conflicting goals, including scalability, extensibility, and soundness of proof checking. In this paper, we propose a new design for proof assistants, in an attempt to address some of these difficulties. The new design is characterized by a pervasive use of macros in representing and checking proofs, and a foundational format for theory files based on JSON. We realize these ideas in a prototype proof assistant called holpy, implemented in Python. We also demonstrate how proof automation can be extended using Python under this framework. Finally, we present a case study about a simple imperative language.",JSON - prototype proof assistant - theory files - foundational format - proof checking - modern proof assistants - interactive theorem proving - holpy - proof automation - Python,Bohua Zhan(1),2019.0,arXiv,arXiv,,"(1) State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China",arXiv,English,,
Inspec,"Solcore: a multi-scale, Python-based library for modelling solar cells and semiconductor materials","Computational models can provide significant insight into the operation mechanisms and deficiencies of photovoltaic solar cells. Solcore is a modular set of computational tools, written in Python 3, for the design and simulation of photovoltaic solar cells. Calculations can be performed on ideal, thermodynamic limiting behaviour, through to fitting experimentally accessible parameters such as dark and light IV curves and luminescence. Uniquely, it combines a complete semiconductor solver capable of modelling the optical and electrical properties of a wide range of solar cells, from quantum well devices to multi-junction solar cells. The model is a multi-scale simulation accounting for nanoscale phenomena such as the quantum confinement effects of semiconductor nanostructures, to micron level propagation of light through to the overall performance of solar arrays, including the modelling of the spectral irradiance based on atmospheric conditions. In this article, we summarize the capabilities in addition to providing the physical insight and mathematical formulation behind the software with the purpose of serving as both a research and teaching tool.",luminescence - multijunction solar cells - semiconductor nanostructures - solar arrays - semiconductor materials - computational models - operation mechanisms - photovoltaic solar cells - computational tools - Python 3 - thermodynamic limiting behaviour - micron level light propagation - nanoscale phenomena - multiscale Python-based library - mathematical formulation - atmospheric conditions - spectral irradiance - quantum confinement effects - multiscale simulation - quantum well devices - optical properties - electrical properties - semiconductor solver - light IV curves - Solcore - solar cell modelling,"Alonso-A´lvarez, D.(1); Wilson, T.(1); Pearce, P.(1); Fu¨hrer, M.(1); Farrell, D.(1); Ekins-Daukes, N.(1)",2018.0,Journal,Journal of Computational Electronics,10.1007/s10825-018-1171-3,"(1) Dept. of Phys., Imperial Coll. London, London, United Kingdom",Springer,English,1569-8025,
Inspec,DeepDIVA: a highly-functional python framework for reproducible experiments,"We introduce DeepDIVA: an infrastructure designed to enable quick and intuitive setup of reproducible experiments with a large range of useful analysis functionality. Reproducing scientific results can be a frustrating experience, not only in document image analysis but in machine learning in general. Using DeepDIVA a researcher can either reproduce a given experiment or share their own experiments with others. Moreover, the framework offers a large range of functions, such as boilerplate code, keeping track of experiments, hyper-parameter optimization, and visualization of data and results. To demonstrate the effectiveness of this framework, this paper presents case studies in the area of handwritten document analysis where researchers benefit from the integrated functionality. DeepDIVA is implemented in Python and uses the deep learning framework PyTorch. It is completely open source, and accessible as Web Service through DIVAServices.",reproducible experiments - DeepDIVA - document image analysis - handwritten document analysis - deep learning - highly-functional Python - machine learning - PyTorch - Web Service - open source - DIVAServices,"Alberti, M.(1); Pondenkandath, V.(1); Wursch, M.(1); Ingold, R.(1); Liwicki, M.(1)",2018.0,Conference,2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR). Proceedings,10.1109/ICFHR-2018.2018.00080,"(1) Document Image & Voice Anal. Group, Univ. of Fribourg, Fribourg, Switzerland",IEEE Computer Society,English,,
Inspec,"Digging Into MUD With Python: mudpy, bdata, and bfit [arXiv]","Used to store the results of (muSR) measurements at TRIUMF, the Muon Data (MUD) file format serves as a useful and flexible scheme that is both lightweight and self-describing. The application programming interface (API) for these files is written in C and FORTRAN, languages not known for their ease of use. In contrast, Python is a language which emphasizes rapid prototyping and readability. This work describes three Python 3 packages to interface with MUD files and analyze their contents: mudpy, bdata, and bfit. The first enables easy access to the contents of any MUD file. The latter two are implemented specifically for the implanted-ion beta-detected NMR (beta-NMR) experiment at TRIUMF. These tools provide both an API and graphical user interface (GUI) to help users extract and fit beta-NMR data.",bdata - bfit - TRIUMF - application programming interface - API - rapid prototyping - Python 3 packages - MUD file - implanted-ion beta-detected NMR experiment - graphical user interface - beta-NMR data - mudpy - Muon Data file format - C language - FORTRAN,"Fujimoto, D.(1)",2020.0,arXiv,arXiv,,"(1) Stewart Blusson Quantum Matter Inst., Univ. of British Columbia, Vancouver, BC, Canada",arXiv,English,,
Inspec,Features of the solution of a problem of dynamics of a plate with use of the Python programming language,The article describes the features of the application of the modern general-purpose language Python for solving the dynamic problem of oscillations of a rectangular plate. The focus is often on libraries used for numerical computation and visualization of results.,Python programming language - general-purpose language Python - rectangular plate - oscillations - dynamic problem - libraries - numerical computation - visualization,"Mondrus, V.(1); Sizov, D.(1)",2017.0,Conference,MATEC Web of Conferences,10.1051/matecconf/201711700126,"(1) Moscow State Univ. of Civil Eng., Moscow, Russia",EDP Sciences,English,2261-236X,
Inspec,GetDist: a Python package for analysing Monte Carlo samples [arXiv],"Monte Carlo techniques, including MCMC and other methods, are widely used and generate sets of samples from a parameter space of interest that can be used to infer or plot quantities of interest. This note outlines methods used the Python GetDist package to calculate marginalized one and two dimensional densities using Kernel Density Estimation (KDE). Many Monte Carlo methods produce correlated and/or weighted samples, for example produced by MCMC, nested, or importance sampling, and there can be hard boundary priors. GetDist's baseline method consists of applying a linear boundary kernel, and then using multiplicative bias correction. The smoothing bandwidth is selected automatically following Botev et al., based on a mixture of heuristics and optimization results using the expected scaling with an effective number of samples (defined to account for MCMC correlations and weights). Two-dimensional KDE use an automatically-determined elliptical Gaussian kernel for correlated distributions. The package includes tools for producing a variety of publication-quality figures using a simple named-parameter interface, as well as a graphical user interface that can be used for interactive exploration. It can also calculate convergence diagnostics, produce tables of limits, and output in latex.",graphical user interface - named-parameter interface - elliptical Gaussian kernel - MCMC correlations - Monte Carlo methods - kernel density estimation - Python GetDist package - Monte Carlo techniques - Monte Carlo samples,"Lewis, A.(1)",2019.0,arXiv,arXiv,,"(1) Univ. of Sussex, Brighton, United Kingdom",arXiv,English,,
Inspec,GriSPy: a python package for fixed-radius nearest neighbors search [arXiv],"We present a new regular grid search algorithm for quick fixed-radius nearest-neighbor lookup developed in Python. This module indexes a set of k-dimensional points in a regular grid, with optional periodic conditions, providing a fast approach for nearest neighbors queries. In this first installment we provide three types of queries: bubble, shell and the nth-nearest; as well as three different metrics of interest in astronomy: the euclidean and two distance functions in spherical coordinates of varying precision, haversine and Vincenty; and the possibility of providing a custom distance function. This package results particularly useful for large datasets where a brute-force search turns impractical.",nth-nearest query - shell query - bubble query - GriSPy - brute-force search - custom distance function - nearest neighbors queries - k-dimensional points - nearest-neighbor lookup - regular grid search - fixed-radius nearest neighbors search - Python package,"Chalela, M.(1); Sillero, E.(1); Pereyra, L.(1); Garciacutea, M.A.(3); Cabral, J.B.(2); Lares, M.(1); Merchaacuten, M.(1)",2019.0,arXiv,arXiv,,"(1) Inst. de Astron. Teor. u Exp., Observatorio Astron. Cordoba, Cordoba, Argentina; (2) Centro Internacional Franco Argentino de Cienc. de la Informacion y de Sist., Rosario, Argentina; (3) Fac. Regional Cordoba, Univ. Tecnol. Nac., Cordoba, Argentina",arXiv,English,,
Inspec,Speeding simulation analysis up with yt and Intel Distribution for Python [arXiv],"As modern scientific simulations grow ever more in size and complexity, even their analysis and post-processing becomes increasingly demanding, calling for the use of HPC resources and methods. yt is a parallel, open source post-processing python package for numerical simulations in astrophysics, made popular by its cross-format compatibility, its active community of developers and its integration with several other professional Python instruments. The Intel Distribution for Python enhances yt's performance and parallel scalability, through the optimization of lower-level libraries Numpy and Scipy, which make use of the optimized Intel Math Kernel Library (Intel-MKL) and the Intel MPI library for distributed computing. The library package yt is used for several analysis tasks, including integration of derived quantities, volumetric rendering, 2D phase plots, cosmological halo analysis and production of synthetic X-ray observation. In this paper, we provide a brief tutorial for the installation of yt and the Intel Distribution for Python, and the execution of each analysis task. Compared to the Anaconda python distribution, using the provided solution one can achieve net speedups up to 4.6times on Intel Xeon Scalable processors (codename Skylake). [Issue 38, 2019, p. 27-32].",Anaconda Python distribution - Intel Xeon scalable processors - parallel source post-processing Python package - open source post-processing Python package - optimized Intel math kernel library - professional Python instruments - cross-format compatibility - numerical simulations - modern scientific simulations - simulation analysis - Intel distribution - cosmological halo analysis - library package yt - distributed computing - Intel MPI library - Intel-MKL,"Cielo, S.; Iapichino, L.; Baruffa, F.",2019.0,arXiv,arXiv,,,arXiv,English,,
Inspec,Asynchronous execution of python code on task based runtime systems [arXiv],"Despite advancements in the areas of parallel and distributed computing, the complexity of programming on High Performance Computing (HPC) resources has deterred many domain experts, especially in the areas of machine learning and artificial intelligence (AI), from utilizing performance benefits of such systems. Researchers and scientists favor high-productivity languages to avoid the inconvenience of programming in low-level languages and costs of acquiring the necessary skills required for programming at this level. In recent years, Python, with the support of linear algebra libraries like NumPy, has gained popularity despite facing limitations which prevent this code from distributed runs. Here we present a solution which maintains both high level programming abstractions as well as parallel and distributed efficiency. Phylanx, is an asynchronous array processing toolkit which transforms Python and NumPy operations into code which can be executed in parallel on HPC resources by mapping Python and NumPy functions and variables into a dependency tree executed by HPX, a general purpose, parallel, task-based runtime system written in C++. Phylanx additionally provides introspection and visualization capabilities for debugging and performance analysis. We have tested the foundations of our approach by comparing our implementation of widely used machine learning algorithms to accepted NumPy standards.",artificial intelligence - high-productivity languages - linear algebra libraries - high level programming abstractions - asynchronous array processing toolkit - NumPy operations - HPC resources - NumPy functions - task-based runtime system - debugging - performance analysis - machine learning - domain experts - task based runtime systems - asynchronous execution - Phylanx - high performance computing resources - Python code,"Tohid, R.; Wagle, B.; Shirzad, S.; Diehl, P.; Serio, A.; Kheirkhahan, A.; Amini, P.; Williams, K.; Isaacs, K.; Huck, K.; Brandt, S.; Kaiser, H.",2018.0,arXiv,arXiv,,,arXiv,English,,
Inspec,Tellurium: An extensible Python-based modeling environment for systems and synthetic biology,"Here we present Tellurium, a Python-based environment for model building, simulation, and analysis that facilitates reproducibility of models in systems and synthetic biology. Tellurium is a modular, cross-platform, and open-source simulation environment composed of multiple libraries, plugins, and specialized modules and methods. Tellurium is a self-contained modeling platform which comes with a fully configured Python distribution. Two interfaces are provided, one based on the Spyder IDE which has an accessible user interface akin to MATLAB and a second based on the Jupyter Notebook, which is a format that contains live code, equations, visualizations, and narrative text. Tellurium uses libRoadRunner as the default SBML simulation engine which supports deterministic simulations, stochastic simulations, and steady-state analyses. Tellurium also includes Antimony, a human-readable model definition language which can be converted to and from SBML. Other standard Python scientific libraries such as NumPy, SciPy, and matplotlib are included by default. Additionally, we include several user-friendly plugins and advanced modules for a wide-variety of applications, ranging from complex algorithms for bifurcation analysis to multidimensional parameter scanning. By combining multiple libraries, plugins, and modules into a single package, Tellurium provides a unified but extensible solution for biological modeling and analysis for both novices and experts. Availability: tellurium.analogmachine.org. [All rights reserved Elsevier].",synthetic biology - open-source simulation environment - multiple libraries - self-contained modeling platform - fully configured Python distribution - default SBML simulation engine - deterministic simulations - stochastic simulations - human-readable model definition language - standard Python scientific libraries - biological modeling - extensible Python-based modeling environment - cross-platform - specialized modules - user-friendly plugins - Spyder IDE - accessible user interface akin - Matlab - Jupyter Notebook - live code - equations - visualizations - narrative text - libRoadRunner - steady-state analyses - Tellurium - Antimony - NumPy - SciPy - matplotlib - bifurcation analysis - multidimensional parameter scanning - single package,"Choi, K.(1); Medley, J.K.(1); Ko¨nig, M.(2); Stocking, K.(1); Smith, L.(1); Gu, S.(1); Sauro, H.M.(1)",2018.0,Journal,BioSystems,10.1016/j.biosystems.2018.07.006,"(1) Dept. of Bioeng., Univ. of Washington, Seattle, WA, United States; (2) Inst. for Biol., Humboldt Univ., Berlin, Germany",Elsevier B.V.,English,0303-2647,
Inspec,PySeqLab: an open source Python package for sequence labeling and segmentation,"Motivation: Text and genomic data are composed of sequential tokens, such as words and nucleotides that give rise to higher order syntactic constructs. In this work, we aim at providing a comprehensive Python library implementing conditional random fields (CRFs), a class of probabilistic graphical models, for robust prediction of these constructs from sequential data. Results: Python Sequence Labeling (PySeqLab) is an open source package for performing supervised learning in structured prediction tasks. It implements CRFs models, that is discriminative models from (i) first-order to higher-order linear-chain CRFs, and from (ii) first-order to higher-order semi-Markov CRFs (semi-CRFs). Moreover, it provides multiple learning algorithms for estimating model parameters such as (i) stochastic gradient descent (SGD) and its multiple variations, (ii) structured perceptron with multiple averaging schemes supporting exact and inexact search using `violation-fixing' framework, (iii) search-based probabilistic online learning algorithm (SAPO) and (iv) an interface for Broyden-Fletcher-Goldfarb-Shanno (BFGS) and the limited-memory BFGS algorithms. Viterbi and Viterbi A* are used for inference and decoding of sequences. Using PySeqLab, we built models (classifiers) and evaluated their performance in three different domains: (i) biomedical Natural language processing (NLP), (ii) predictive DNA sequence analysis and (iii) Human activity recognition (HAR). State-of-the-art performance comparable to machine-learning based systems was achieved in the three domains without feature engineering or the use of knowledge sources.",structured prediction tasks - discriminative models - higher-order linear-chain CRFs - higher-order semiMarkov CRFs - semiCRFs - multiple learning algorithms - model parameters - stochastic gradient descent - supervised learning - open source package - Python Sequence Labeling - sequential data - robust prediction - probabilistic graphical models - conditional random fields - comprehensive Python library - higher order syntactic constructs - nucleotides - sequential tokens - genomic data - open source Python package - knowledge sources - machine-learning based systems - state-of-the-art performance - DNA sequence analysis - PySeqLab - limited-memory BFGS algorithms - Broyden-Fletcher-Goldfarb-Shanno - inexact search using violation-fixing framework - exact search using violation-fixing framework - multiple averaging schemes - structured perceptron,"Allam, A.(1); Krauthammer, M.(1)",2017.0,Journal,Bioinformatics,10.1093/bioinformatics/btx451,"(1) Dept. of Pathology, Sch. of Med., Yale Univ., New Haven, CT, United States",Oxford University Press,English,1367-4803,
Inspec,rstoolbox - a Python library for large-scale analysis of computational protein design data and structural bioinformatics,"Background: Large-scale datasets of protein structures and sequences are becoming ubiquitous in many domains of biological research. Experimental approaches and computational modelling methods are generating biological data at an unprecedented rate. The detailed analysis of structure-sequence relationships is critical to unveil governing principles of protein folding, stability and function. Computational protein design (CPD) has emerged as an important structure-based approach to engineer proteins for novel functions. Generally, CPD workflows rely on the generation of large numbers of structural models to search for the optimal structure-sequence configurations. As such, an important step of the CPD process is the selection of a small subset of sequences to be experimentally characterized. Given the limitations of current CPD scoring functions, multi-step design protocols and elaborated analysis of the decoy populations have become essential for the selection of sequences for experimental characterization and the success of CPD strategies. Results: Here, we present the rstoolbox, a Python library for the analysis of large-scale structural data tailored for CPD applications. rstoolbox is oriented towards both CPD software users and developers, being easily integrated in analysis workflows. For users, it offers the ability to profile and select decoy sets, which may guide multi-step design protocols or for follow-up experimental characterization. rstoolbox provides intuitive solutions for the visualization of large sequence/structure datasets (e.g. logo plots and heatmaps) and facilitates the analysis of experimental data obtained through traditional biochemical techniques (e.g. circular dichroism and surface plasmon resonance) and high-throughput sequencing. For CPD software developers, it provides a framework to easily benchmark and compare different CPD approaches. Here, we showcase the rstoolbox in both types of applications. Conclusions: rstoolbox is a library for the evaluation of protein structures datasets tailored for CPD data. It provides interactive access through seamless integration with IPython, while still being suitable for highperformance computing. In addition to its functionalities for data analysis and graphical representation, the inclusion of rstoolbox in protein design pipelines will allow to easily standardize the selection of design candidates, as well as, to improve the overall reproducibility and robustness of CPD selection processes.",rstoolbox - Python library - large-scale analysis - computational protein design data - structural bioinformatics - Large-scale datasets - biological research - computational modelling methods - biological data - structure-sequence relationships - protein folding - CPD workflows - structural models - optimal structure-sequence configurations - multistep design protocols - large-scale structural data - CPD applications - CPD software users - CPD software developers - protein structures datasets - CPD data - data analysis - protein design pipelines - CPD selection processes - structure-based approach - CPD scoring functions - high-performance computing - sequence/structure dataset visualization,"Bonet, J.(1); Harteveld, Z.(1); Sesterhenn, F.(1); Scheck, A.(1); Correia, B.E.(1)",2019.0,Journal,BMC Bioinformatics,10.1186/s12859-019-2796-3,"(1) Inst. of Bioeng., Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland",Springer,English,1471-2105,
Inspec,MagPySV: a python package for processing and denoising geomagnetic observatory data,"Measurements obtained at ground-based observatories are crucial to understanding the geomagnetic field and its secular variation (SV). However, current data processing methods rely on piecemeal closed-source codes or are performed on an ad hoc basis, hampering efforts to reproduce data sets underlying published results. We present MagPySV, an open-source Python package designed to provide a consistent and automated means of generating high-resolution SV data sets from hourly means distributed by the Edinburgh World Data Centre. It applies corrections for documented baseline changes, and optionally, data may be excluded using the ap index, which removes effects from documented high solar activity periods such as geomagnetic storms. Robust statistics are used to identify and remove outliers. Developing existing denoising methods, we use principal component analysis of the covariance matrix of residuals between observed SV and that predicted by a global field model to remove a proxy for external field contamination from observations. This method creates a single covariance matrix for all observatories of interest combined and applies the denoising to all locations simultaneously, resulting in cleaner time series of the internally generated SV. In our case studies, we present cleaned data in two geographic regions: monthly first differences are used to investigate geomagnetic jerk morphology in Europe, an area previously well-studied at lower resolution, and annual differences are investigated for northern high latitude regions, which are often neglected due to their high noise content. MagPySV may be run on the command line or within an interactive Jupyter notebook; two notebooks reproducing the case studies are supplied.",data processing - high solar activity periods - covariance matrix - geomagnetic observatory data denoising - time series - northern high latitude regions - geomagnetic jerk morphology - principal component analysis - Edinburgh World Data Centre - open-source Python package - secular variation - geomagnetic field - ground-based observatories - MagPySV,"Cox, G.A.(1); Brown, W.J.(2); Billingham, L.(2); Holme, R.(1)",2018.0,Journal,"Geochemistry, Geophysics, Geosystems",10.1029/2018GC007714,"(1) Dept. of Earth, Ocean & Ecological Sci., Univ. of Liverpool, Liverpool, United Kingdom; (2) Lyell Centre, British Geol. Survey, Edinburgh, United Kingdom",Wiley,English,1525-2027,
Inspec,It's like python but: towards supporting transfer of programming language knowledge,"Expertise in programming traditionally assumes a binary novice-expert divide. Learning resources typically target programmers who are learning programming for the first time, or expert programmers for that language. An underrepresented, yet important group of programmers are those that are experienced in one programming language, but desire to author code in a different language. For this scenario, we postulate that an effective form of feedback is presented as a transfer from concepts in the first language to the second. Current programming environments do not support this form of feedback. In this study, we apply the theory of learning transfer to teach a language that programmers are less familiar with-such as R-in terms of a programming language they already know-such as Python. We investigate learning transfer using a new tool called Transfer Tutor that presents explanations for R code in terms of the equivalent Python code. Our study found that participants leveraged learning transfer as a cognitive strategy, even when unprompted. Participants found Transfer Tutor to be useful across a number of affordances like stepping through and highlighting facts that may have been missed or misunderstood. However, participants were reluctant to accept facts without code execution or sometimes had difficulty reading explanations that are verbose or complex. These results provide guidance for future designs and research directions that can support learning transfer when learning new programming languages.",programming language knowledge - Transfer Tutor - Python code - learning transfer theory - R code - cognitive strategy,"Shrestha, N.(1); Barik, T.(2); Parnin, C.(1)",2018.0,Conference,2018 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC),10.1109/VLHCC.2018.8506508,"(1) NC State Univ., Raleigh, NC, United States; (2) Microsoft, Redmond, WA, United States",IEEE,English,,
Inspec,Cyber Security Tool Kit (CyberSecTK): A Python Library for Machine Learning and Cyber Security,"The cyber security toolkit, CyberSecTK, is a simple Python library for preprocessing and feature extraction of cyber-security-related data. As the digital universe expands, more and more data need to be processed using automated approaches. In recent years, cyber security professionals have seen opportunities to use machine learning approaches to help process and analyze their data. The challenge is that cyber security experts do not have necessary trainings to apply machine learning to their problems. The goal of this library is to help bridge this gap. In particular, we propose the development of a toolkit in Python that can process the most common types of cyber security data. This will help cyber experts to implement a basic machine learning pipeline from beginning to end. This proposed research work is our first attempt to achieve this goal. The proposed toolkit is a suite of program modules, data sets, and tutorials supporting research and teaching in cyber security and defense. An example of use cases is presented and discussed. Survey results of students using some of the modules in the library are also presented.",cyber security tool kit - CyberSecTK - Python library - machine learning - feature extraction - preprocessing - cyber security data - program modules - data sets - tutorials - teaching,"Calix, R.A.(1); Singh, S.B.(1); Tingyu Chen(1); Dingkai Zhang(1); Tu, M.(1)",2020.0,Journal,Information,10.3390/info11020100,"(1) Purdue Univ. Northwest, Hammond, IN, United States",MDPI,English,2078-2489,
Inspec,Creating CAD designs and performing their subsequent analysis using opensource solutions in Python,"The paper discusses the concept of a system that encapsulates the transition from geometry building to strength tests. The solution we propose views the engineer as a programmer who is capable of coding the procedure for working with the modeli.e., to outline the necessary transformations and create cases for boundary conditions. We propose a prototype of such system. In our work, we used: Python programming language to create the program; Jupyter framework to create a single workspace visualization; pythonOCC library to implement CAD; FeniCS library to implement FEM; GMSH and VTK utilities. The prototype is launched on a platform which is a dynamically expandable multi-tenant cloud service providing users with all computing resources on demand. However, the system may be deployed locally for prototyping or work that does not involve resource-intensive computing. To make it possible, we used containerization, isolating the system in a Docker container.",boundary conditions - Python programming language - Jupyter framework - single workspace visualization - pythonOCC library - FeniCS library - prototyping - resource-intensive computing - CAD designs - opensource solutions - geometry building - strength tests - programmer - modeli.e - working procedure coding - FEM - GMSH - VTK utilities - multitenant cloud service - containerization - Docker container,"Iakushkin, O.O.(1); Sedova, O.S.(1)",2018.0,Conference,AIP Conference Proceedings,10.1063/1.5019153,"(1) St.-Petersburg State Univ., St. Petersburg, Russia",AIP Publishing,English,0094-243X,
Inspec,ATP cards automatic generation from an electrical network elements database using Python,"The EMTP-ATP is a widely used program for the simulation of electromagnetic transients, however, the complexity associated with manual creation of the input file and the need for an operator intervention to model the network in the auxiliary graphics software makes it difficult to use such largescale simulations by utilities. In this work, a system of automatic generation of ATP cards from a database containing the elements of the electrical network to be simulated was developed. The software queries a relational and structured database and formats an ”.atp” extension entry file according to the fixed format of the ATP Rule Book and FORTRAN77 Standard. The results of the simulations obtained with the proposed system were compared to those obtained with ATPDraw and both are equivalent.",ATP cards automatic generation - electrical network elements database - EMTP-ATP - electromagnetic transients - auxiliary graphics software - largescale simulations - relational database - structured database - extension entry file - Python - ATP rule book - FORTRAN77 standard - ATPDraw,"Muniz, J.R.S.(1); Moraes, J.A.A.(1); Rocha, G.V.S.(1); Nunes, M.V.A.(1); Barradas, R.P.S.(1); Bezerra, U.H.(1); Brito, A.B.(2); Monteiro, F.P.(1); Carvalho, R.L.S.(1)",2018.0,Conference,2018 13th IEEE International Conference on Industry Applications (INDUSCON). Proceedings,10.1109/INDUSCON.2018.8627278,"(1) Dept. of Electr. Eng., Fed. Univ. of Para, Belem, Brazil; (2) Celpa Equatorial Group, Belem, Brazil",IEEE,English,,
Inspec,"CDLIB: a python library to extract, compare and evaluate communities from complex networks","Community Discovery is among the most studied problems in complex network analysis. During the last decade, many algorithms have been proposed to address such task; however, only a few of them have been integrated into a common framework, making it hard to use and compare different solutions. To support developers, researchers and practitioners, in this paper we introduce a python library - namely CDlib - designed to serve this need. The aim of CDlib is to allow easy and standardized access to a wide variety of network clustering algorithms, to evaluate and compare the results they provide, and to visualize them. It notably provides the largest available collection of community detection implementations, with a total of 39 algorithms.",CDLIB - Python library - complex networks - Community Discovery - complex network analysis - CDlib - standardized access - network clustering algorithms - community detection implementations,"Rossetti, G.(1); Milli, L.(1); Cazabet, R.(2)",2019.0,Journal,Applied Network Science,10.1007/s41109-019-0165-9,"(1) KDD Lab., ISTI, Pisa, Italy; (2) Univ. de Lyon, Lyon, France",Springer,English,2364-8228,
Inspec,Scripting a large Fortran code with Python,"As a software engineering experiment, FLASH, a 500,000 line high-performance parallel scientific code written mainly in Fortran, was instrumented with the scripting language Python. We give an overview of the process and describe the applications that resulted from Python's flexibility.",Fortran code - software engineering - FLASH - high-performance parallel scientific code - scripting language Python,"Calleja, A.C.(1)",2004.0,Conference,"""Software Engineering for High Performance Computing System (HPCS) Applications"" W3S Workshop - 26th International Conference on Software Engineering",10.1049/ic:20040419,"(1) ASCI Flash Center & Dept. of Phys., Chicago Univ., IL, United States",IEE,English,,0-86341-418-4
Inspec,"Converting 2D-medical image files ldquodicomrdquo into 3dmodels, based on image processing, and analysing their results with python programming","This paper presents the possibility of converting (2D) medical image data (Digital Imaging and Communications in Medicine (DICOM) files) to 3D model. Medical data and image processing software's, namely Seg3D2 and ImageVis3D, were used to analyze images, create 3D models of the liver and export them in OBJ images for performing a range of surgical procedures, and measure the accuracy of the size and weight of the liver, kidneys and arteries with their conformity to DICOM file. It is compared to the image processing before and after the conversion stage of medical image using the Python language program to ensure the integrity of the images after the conversion process is identical to the original pictures of DICOM without causing any distortions or changes to it. We reduce file size while maintaining the model's highest quality, while employing mixed reality techniques, applied on Liver Surgical Operation [living donor liver Transplantation (LDLT)].",Python programming - Digital Imaging - image processing software - Seg3D2 - ImageVis3D - OBJ images - kidneys - arteries - DICOM file - Liver Surgical Operation - 2D-medical image file conversion - 3D model - medical data software - image analysis - digital imaging and communications in medicine files - mixed reality,"Mamdouh, R.(1); El-Bakry, H.M.(2); Riad, A.(3); El-Khamisy, N.(3)",2020.0,Journal,WSEAS Transactions on Computers,10.37394/23205.2020.19.2,"(1) Fac. of Comp & Inf. Syst., Mansoura Univ., Mansoura, Egypt; (2) Inf. Syst. Dept., Mansoura Univ., Mansoura, Egypt; (3) Comput. & Inf. Syst. Dept., Sadat Acad., Cairo, Egypt",WSEAS,English,1109-2750,
Inspec,pyNBS: a Python implementation for network-based stratification of tumor mutations,"Summary: We present pyNBS: a modularized Python 2.7 implementation of the network-based stratification (NBS) algorithm for stratifying tumor somatic mutation profiles into molecularly and clinically relevant subtypes. In addition to release of the software, we benchmark its key parameters and provide a compact cancer reference network that increases the significance of tumor stratification using the NBS algorithm. The structure of the code exposes key steps of the algorithm to foster further collaborative development.",pyNBS - Python implementation - tumor mutations - modularized Python 2 - network-based stratification algorithm - tumor somatic mutation profiles - molecularly subtypes - clinically relevant subtypes - compact cancer reference network - tumor stratification - NBS algorithm,"Huang, J.K.(1); Tongqiu Jia(2); Carlin, D.E.(2); Ideker, T.(1)",2018.0,Journal,Bioinformatics,10.1093/bioinformatics/bty186,"(1) Bioeng. Dept., UC San Diego, La Jolla, CA, United States; (2) Dept. of Med., UC San Diego, La Jolla, CA, United States",Oxford University Press,English,1367-4803,
Inspec,Finding Errors in Python Programs Using Dynamic Symbolic Execution,"For statically typed languages, dynamic symbolic execution (also called concolic testing) is a mature approach to automated test generation. However, extending it to dynamic languages presents several challenges. Complex semantics, fragmented and incomplete type information, and calls to foreign functions lacking precise models make symbolic execution difficult. We propose a symbolic execution approach that mixes concrete and symbolic values and incrementally solves path constraints in search for alternate executions by lazily instantiating axiomatizations for called functions as needed. We present the symbolic execution model underlying this approach and illustrate the workings of our prototype concolic testing tool on an actual Python software package.",program errors - Python programs - statically typed languages - dynamic symbolic execution model - automated test generation - dynamic languages - symbolic execution approach - concrete values - symbolic values - path constraints - axiomatizations - functions - concolic testing tool - Python software package,"Sapra, S.(1); Minea, M.(2); Chaki, S.(1); Gurfinkel, A.(1); Clarke, E.M.(1)",2013.0,Conference,"Testing Software and Systems. 25th IFIP WG 6.1 International Conference, ICTSS 2013. Proceedings: LNCS 8254",10.1007/978-3-642-41707-8_20,"(1) Carnegie Mellon Univ., Pittsburgh, PA, United States; (2) Politeh. Univ. of Timisoara, Timisoara, Romania",Springer-Verlag,English,,
Inspec,AutoParallel: A Python module for automatic parallelization and distributed execution of affine loop nests [arXiv],"The last improvements in programming languages, programming models, and frameworks have focused on abstracting the users from many programming issues. Among others, recent programming frameworks include simpler syntax, automatic memory management and garbage collection, which simplifies code re-usage through library packages, and easily configurable tools for deployment. For instance, Python has risen to the top of the list of the programming languages due to the simplicity of its syntax, while still achieving a good performance even being an interpreted language. Moreover, the community has helped to develop a large number of libraries and modules, tuning them to obtain great performance. However, there is still room for improvement when preventing users from dealing directly with distributed and parallel computing issues. This paper proposes and evaluates AutoParallel, a Python module to automatically find an appropriate task-based parallelization of affine loop nests to execute them in parallel in a distributed computing infrastructure. This parallelization can also include the building of data blocks to increase task granularity in order to achieve a good execution performance. Moreover, AutoParallel is based on sequential programming and only contains a small annotation in the form of a Python decorator so that anyone with little programming skills can scale up an application to hundreds of cores.",AutoParallel - Python module - automatic parallelization - affine loop nests - programming languages - programming models - simpler syntax - automatic memory management - garbage collection - sequential programming - Python decorator - programming skills - distributed computing - parallel computing - distributed execution,"Ramon-Cortes, C.(1); Amela, R.(1); Ejarque, J.(1); Clauss, P.(2); Badia, R.M.(3)",2018.0,arXiv,arXiv,,"(1) Barcelona Supercomput. Center, Barcelona, Spain; (2) ICube Lab., Univ. de Strasbourg Strasbourg, Strasbourg, France; (3) Barcelona Supercomput. Center, Consejo Super. de Investig. Cientificas, Barcelona, Spain",arXiv,English,,
Inspec,SlideSeg: A Python Module for the Creation of Annotated Image Repositories from Whole Slide Images,"Machine learning methods are being widely used in medicine to aid cancer diagnosis and detection. In the area of digital pathology, prediction heat maps produced by convolutional neural networks (CNN) have already exceeded the performance of a trained pathologist with no time constraints. To train deep learning networks, large datasets of accurately labeled ground truth data are required; however, whole slide images are often on the scale of 10+ gigapixels when digitized at 40X magnification, contain multiple magnification levels, and have unstandardized formats. Due to these characteristics, traditional techniques for the production of training and validation data cannot be used, resulting in the limited availability of annotated datasets. This research presents a Python module and method to rapidly produce accurately annotated image patches from whole slide images. This module is built on OpenCV, an open source computer vision library, OpenSlide, an open source library for reading virtual slide images, and NumPy, a library for scientific computing with Python. These Python scripts successfully produce 'ground truth' image patches and will help transfer advances in research laboratories into clinical application by addressing many of the challenges associated with the development of annotated datasets for machine learning in histopathology.",Python module - open source computer vision library - open source library - virtual slide images - Python scripts - ground truth image patches - annotated image repositories - machine learning methods - cancer diagnosis - digital pathology - prediction heat maps - convolutional neural networks - deep learning networks - cancer detection - annotated image patches - OpenCV,"Crabb, B.(1); Olson, N.(2)",2018.0,Conference,Proceedings of the SPIE - Progress in Biomedical Optics and Imaging,10.1117/12.2300262,"(1) SSC Pacific, San Diego, CA, United States; (2) Naval Hosp. Camp Pendleton, Oceanside, CA, United States",SPIE,English,1605-7422,
Inspec,PyGB: GraphBLAS DSL in Python with Dynamic Compilation Into Efficient C++,"We present PyGB, a high-level Python domainspecific language (DSL) for GraphBLAS building blocks for graph algorithms. GraphBLAS is based on a small number of linear algebra operations, and it is described using mathematical notation and concepts. However, the concrete realizations of GraphBLAS concentrate on efficiency and widely usable programming interfaces. The GraphBLAS C language API standardized by the GraphBLAS Forum is the major example of such a realization, and our GraphBLAS Template Library (GBTL) implemented in the C++ language is another. PyGB exposes the \cpp interface of GBTL through a DSL that leverages Python's mature scientific computing ecosystem and high-level syntax. The syntax of PyGB more closely resembles the GraphBLAS mathematical notation than GBTL. The DSL dispatches to dynamically compiled templated classes to achieve comparable performance to the native GBTL code. We highlight the features of PyGB through code examples and discuss how Python's syntax and dynamic execution enable us to provide the high-level abstraction with minimal performance penalty. We demonstrate the stages of execution, from type inference to template compilation, to dynamic linking and invocation from the Python interpreter. Our experimental evaluation shows that for sufficiently large inputs, the overhead of PyGB is negligible and compilation times are not worse than for native GBTL implementation. Last, we outline concrete features we plan to implement in the future to extend PyGB.",PyGB - GraphBLAS DSL - dynamic compilation - linear algebra operations - GraphBLAS Template Library - GraphBLAS mathematical notation - high-level abstraction - Python interpreter - scientific computing ecosystem - GBTL code - GBTL code - C++ language - graph algorithms - GraphBLAS C language API - high-level Python domain specific language,"Chamberlin, J.(1); Zalewski, M.(2); McMillan, S.(3); Lumsdaine, A.(1)",2018.0,Conference,2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),10.1109/IPDPSW.2018.00059,"(1) Univ. of Washington, Seattle, WA, United States; (2) Pacific Northwest Nat. Lab., Northwest Inst. for Adv. Comput., Seattle, WA, United States; (3) Software Eng. Inst., Carnegie Mellon Univ., Pittsburgh, PA, United States",IEEE Computer Society,English,,
Inspec,Python 2.4 decorators: reducing code duplication and consolidating knowledge,"As software environments become more complex and programs get larger, it becomes more and more necessary to find ways to reduce code duplication and scattering of knowledge. While simple code duplication is easy to factor out into functions or methods, more complex code duplication is not. A second and related problem is scattering of knowledge. Duplication is not a good thing for both developer productivity and software reliability - which is why Python 2.4's new ""decorator"" feature lets one address both kinds of duplication. Decorators are Python objects that can register, annotate, and/or wrap a Python function or method. Python decorators are a simple, highly customizable way to wrap functions or methods, annotate them with metadata, or register them with a framework of some kind. But, as a relatively new feature, their full possibilities have not yet been explored, and perhaps the most exciting uses haven't even been invented yet. Each message uses different syntax for decorators, based on some C#-like alternatives being discussed at the time.",Python 2.4 - decorators - code duplication reduction - consolidating knowledge - software environments - knowledge scattering - productivity - software reliability - metadata,"Eby, P.",2005.0,Journal,Dr. Dobb's Journal,,,CMP Media LLC,English,1044-789X,
Inspec,Pyroomacoustics: A Python Package for Audio Room Simulation and Array Processing Algorithms,"We present pyroomacoustics, a software package aimed at the rapid development and testing of audio array processing algorithms. The content of the package can be divided into three main components: an intuitive Python object-oriented interface to quickly construct different simulation scenarios involving multiple sound sources and microphones in 2D and 3D rooms; a fast C implementation of the image source model for general polyhedral rooms to efficiently generate room impulse responses and simulate the propagation between sources and receivers; and finally, reference implementations of popular algorithms for beamforming, direction finding, and adaptive filtering. Together, they form a package with the potential to speed up the time to market of new algorithms by significantly reducing the implementation overhead in the performance evaluation step.",Python object-oriented interface - room impulse responses - general polyhedral rooms - image source model - fast C implementation - multiple sound sources - audio array processing algorithms - software package - pyroomacoustics - audio room simulation - Python package,"Scheibler, R.(1); Bezzam, E.(1); Dokmanic, I.(2)",2018.0,Conference,"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",10.1109/ICASSP.2018.8461310,"(1) Ecole Polytech. Fed. de Lausanne, Lausanne, Switzerland; (2) Univ. of Illinois Urbana-Champaign, Urbana, IL, United States",IEEE,English,,
Inspec,High-level Synthesis using Python Language,"This paper presents High-Level Synthesis compiler. The development of FPGA technology and the increasing complexity of applications in recent decades have forced compilers to move to higher abstraction levels. Compilers interprets an algorithmic description of a desired behavior written in High-Level Languages (HLLs) and translate it to Hardware Description Languages (HDLs). This paper presents a Python based High-Level synthesis (HLS) compiler. The compiler get the configuration parameters and map RPython program to VHDL code. Then, VHDL code can be used to program FPGA chips. FPGAs have the potential to achieve far greater performance than software exploiting a greater level of parallelism especially for fine grain algorithms. This can be achieved by reconfigurable internal FPGA connections and hardware primitives. Creating parallel programs implemented in FPGAs in pure HDL is difficult and time consuming. using higher level of abstraction and High-Level Synthesis compiler implementation time can be reduced. This article describes design methodologies and tools, implementation of created VHDL backend for Python compiler.",HLL - HDL - high-level synthesis compiler implementation time - RPython program - hardware description languages - high-level languages - Python compiler - reconfigurable internal FPGA connections - fine grain algorithms - FPGA chips - VHDL code - algorithmic description - higher abstraction levels - Python language,"Cieszewski, R.(1); Pozniak, K.(1)",2017.0,Journal,Elektronika,10.15199/13.2017.8.7,"(1) Inst. Syst. Elektronicznych, Politech. Warszawska, Warsaw, Poland",SIGMA-NOT,Polish,0033-2089,
Inspec,Design of King Glory's Game Query System Based on Python,"The King Glory is a multiplayer tower defense sports game. This paper is based on Python to implement a game hero information query system. First, the crawler technology is used to get the hero information from the webpage, then the layered architecture is used to develop the software system and experiment on two computers. The user selects the specified hero name in the client interface to get the hero's title and skill information. The experimental results show that the system can query the details of the hero skills in the game.",Python - multiplayer tower defense sports game - game hero information query system - crawler technology - King Glory's game query system,Xiaozhuo Li(1); Zhenyu Wang(1),2019.0,Conference,2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE). Proceedings,10.1109/EITCE47263.2019.9094996,"(1) Dept. of Comput. Sci. & Technol., Xi'an Univ. of Posts & Telecommun., Xi'an, China",IEEE,English,,
Inspec,PyCoTools: a Python toolbox for COPASI,"Motivation: COPASI is an open source software package for constructing, simulating and analyzing dynamic models of biochemical networks. COPASI is primarily intended to be used with a graphical user interface but often it is desirable to be able to access COPASI features programmatically, with a high level interface. Results: PyCoTools is a Python package aimed at providing a high level interface to COPASI tasks with an emphasis on model calibration. PyCoTools enables the construction of COPASI models and the execution of a subset of COPASI tasks including time courses, parameter scans and parameter estimations. Additional `composite' tasks which use COPASI tasks as building blocks are available for increasing parameter estimation throughput, performing identifiability analysis and performing model selection. PyCoTools supports exploratory data analysis on parameter estimation data to assist with troubleshooting model calibrations. We demonstrate PyCoTools by posing a model selection problem designed to show case PyCoTools within a realistic scenario. The aim of the model selection problem is to test the feasibility of three alternative hypotheses in explaining experimental data derived from neonatal dermal fibroblasts in response to TGF-szlig over time. PyCoTools is used to critically analyze the parameter estimations and propose strategies for model improvement.",neonatal dermal fibroblasts - troubleshooting model calibrations - exploratory data analysis - biochemical networks - PyCoTools - parameter estimation data - identifiability analysis - COPASI models - Python package - high level interface - graphical user interface - open source software package - Python toolbox - model selection problem,"Welsh, C.M.(1); Fullard, N.(3); Proctor, C.J.(2); Martinez-Guimera, A.(1); Isfort, R.J.(4); Bascom, C.C.(4); Tasseff, R.(4); Przyborski, S.A.(3); Shanley, D.P.(1)",2018.0,Journal,Bioinformatics,10.1093/bioinformatics/bty409,"(1) Inst. for Cell & Mol. Biosci., Newcastle Univ., Newcastle upon Tyne, United Kingdom; (2) Inst. of Cellular Med., Newcastle Univ., Newcastle upon Tyne, United Kingdom; (3) Dept. of Biosci., Durham Univ., Durham, United Kingdom; (4) Proctor & Gamble Co., Cincinnati, OH, United States",Oxford University Press,English,1367-4803,
Inspec,PYRO-NN: Python Reconstruction Operators in Neural Networks [arXiv],"Purpose: Recently, several attempts were conducted to transfer deep learning to medical image reconstruction. An increasingly number of publications follow the concept of embedding the CT reconstruction as a known operator into a neural network. However, most of the approaches presented lack an efficient CT reconstruction framework fully integrated into deep learning environments. As a result, many approaches are forced to use workarounds for mathematically unambiguously solvable problems. Methods: PYRO-NN is a generalized framework to embed known operators into the prevalent deep learning framework Tensorflow. The current status includes state-of-the-art parallel-, fanand cone-beam projectors and back-projectors accelerated with CUDA provided as Tensorflow layers. On top, the framework provides a high level Python API to conduct FBP and iterative reconstruction experiments with data from real CT systems. Results: The framework provides all necessary algorithms and tools to design end-to-end neural network pipelines with integrated CT reconstruction algorithms. The high level Python API allows a simple use of the layers as known from Tensorflow. To demonstrate the capabilities of the layers, the framework comes with three baseline experiments showing a cone-beam short scan FDK reconstruction, a CT reconstruction filter learning setup, and a TV regularized iterative reconstruction. All algorithms and tools are referenced to a scientific publication and are compared to existing non deep learning reconstruction frameworks. The framework is available as open-source software at https://github.com/csyben/PYRO-NN. Conclusions: PYRO-NN comes with the prevalent deep learning framework Tensorflow and allows to setup end-to-end trainable neural networks in the medical image reconstruction context. We believe that the framework will be a step towards reproducible research and give the medical physics community a toolkit to elevate medical image reconstruction with new deep learning techniques.",iterative reconstruction - end-to-end trainable neural networks - nondeep learning reconstruction frameworks - CT reconstruction filter learning - TV regularized iterative reconstruction - generalized framework - mathematically unambiguously solvable problems - efficient CT reconstruction framework - Python reconstruction operators - medical image reconstruction context - cone-beam short scan FDK reconstruction - integrated CT reconstruction algorithms - end-to-end neural network pipelines - CT systems - high level Python API - Tensorflow layers - fanand cone-beam projectors - prevalent deep learning framework Tensorflow,"Syben, C.(1); Michen, M.(1); Stimpel, B.(1); Seitz, S.(1); Ploner, S.(1); Maier, A.K.(1)",2019.0,arXiv,arXiv,,"(1) Pattern Recognition Lab., Friedich-Alexander Univ. Erlangen-Nurnberg, Erlangen, Germany",arXiv,English,,
Inspec,"Growing the ReConFig community through python, zynq and hardware overlays","In this talk, modern software trends will be explored with a focus on how we can grow the ReConFig community - specifically by learning-from and welcoming-in software developers who want FPGA benefits but do not have a background in programmable logic. Putting that emphasis into action, I'll also talk about an open source project I'm passionate about today - PYNQ: Python Productivity for Zynq. Applying the software trends that will first be presented, PYNQ software is freely available, requires no proprietary tools, includes Python libraries for FPGA communication, and leverages a Jupyter Notebook frontend for web based development. Following one final trend from software community keynotes, I will end the talk with a live demonstration of PYNQ on a newly released low-cost Zynq board.",ReConFig community - zynq board - hardware overlays - FPGA - programmable logic - open source project - software trends - PYNQ software - python libraries - Web based development,"Schelle, G.",2016.0,Conference,2016 International Conference on Reconfigurable Computing and FPGAs (ReConFig),10.1109/ReConFig.2016.7857138,,IEEE,English,,
Inspec,Glycosylator: a Python framework for the rapid modeling of glycans,"Background: Carbohydrates are a class of large and diverse biomolecules, ranging from a simple monosaccharide to large multi-branching glycan structures. The covalent linkage of a carbohydrate to the nitrogen atom of an asparagine, a process referred to as N-linked glycosylation, plays an important role in the physiology of many living organisms. Most software for glycan modeling on a personal desktop computer requires knowledge of molecular dynamics to interface with specialized programs such as CHARMM or AMBER. There are a number of popular web-based tools that are available for modeling glycans (e.g., GLYCAM-WEB (http://https://dev.glycam.org/gp/) or Glycosciences.db (http://www. glycosciences.de/)). However, these web-based tools are generally limited to a few canonical glycan conformations and do not allow the user to incorporate glycan modeling into their protein structure modeling workflow. Results: Here, we present Glycosylator, a Python framework for the identification, modeling and modification of glycans in protein structure that can be used directly in a Python script through its application programming interface (API) or through its graphical user interface (GUI). The GUI provides a straightforward two-dimensional (2D) rendering of a glycoprotein that allows for a quick visual inspection of the glycosylation state of all the sequons on a protein structure. Modeled glycans can be further refined by a genetic algorithm for removing clashes and sampling alternative conformations. Glycosylator can also identify specific three-dimensional (3D) glycans on a protein structure using a library of predefined templates. Conclusions: Glycosylator was used to generate models of glycosylated protein without steric clashes. Since the molecular topology is based on the CHARMM force field, new complex sugar moieties can be generated without modifying the internals of the code. Glycosylator provides more functionality for analyzing and modeling glycans than any other available software or webserver at present. Glycosylator will be a valuable tool for the glycoinformatics and biomolecular modeling communities.",biomolecular modeling communities - Glycosylator - Python framework - multibranching glycan structures - carbohydrate - N-linked glycosylation - glycan modeling - web-based tools - GLYCAM-WEB - canonical glycan conformations - protein structure modeling workflow - Python script - application programming interface - graphical user interface - glycosylation state - three-dimensional glycans - glycosylated protein - two-dimensional rendering - CHARMM force field - complex sugar moieties - GUI - genetic algorithm - glycoinformatics - molecular dynamics,"Lemmin, T.(1); Soto, C.(2)",2019.0,Journal,BMC Bioinformatics,10.1186/s12859-019-3097-6,"(1) Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; (2) Vanderbilt Vaccine Center, Med. Center, Vanderbilt Univ., Nashville, TN, United States",Springer,English,1471-2105,
Inspec,refnx: neutron and X-ray reflectometry analysis in Python,"refnx is a model-based neutron and X-ray reflectometry data analysis package written in Python. It is cross platform and has been tested on Linux, macOS and Windows. Its graphical user interface is browser based, through a Jupyter notebook. Model construction is modular, being composed from a series of components that each describe a subset of the interface, parameterized in terms of physically relevant parameters (volume fraction of a polymer, lipid area per molecule etc.). The model and data are used to create an objective, which is used to calculate the residuals, log-likelihood and log-prior probabilities of the system. Objectives are combined to perform co-refinement of multiple data sets and mixed-area models. Prior knowledge of parameter values is encoded as probability distribution functions or bounds on all parameters in the system. Additional prior probability terms can be defined for sets of components, over and above those available from the parameters alone. Algebraic parameter constraints are available. The software offers a choice of fitting approaches, including least-squares (global and gradient-based optimizers) and a Bayesian approach using a Markov-chain Monte Carlo algorithm to investigate the posterior distribution of the model parameters. The Bayesian approach is useful for examining parameter covariances, model selection and variability in the resulting scattering length density profiles. The package is designed to facilitate reproducible research; its use in Jupyter notebooks, and subsequent distribution of those notebooks as supporting information, permits straightforward reproduction of analyses.",refnx - Python - model-based neutron - X-ray reflectometry data analysis package - graphical user interface - Jupyter notebook - model construction - volume fraction - lipid area - log-likelihood - log-prior probabilities - multiple data sets - mixed-area models - probability distribution functions - algebraic parameter constraints - Bayesian approach - Markov-chain Monte Carlo algorithm - posterior distribution - model parameters - parameter covariances - model selection - variability - notebooks,"Nelson, A.R.J.(1); Prescott, S.W.(2)",2019.0,Journal,Journal of Applied Crystallography,10.1107/S1600576718017296,"(1) ANSTO, Kirrawee DC, NSW, Australia; (2) Sch. of Chem. Eng., Univ. of New South Wales, Sydney, NSW, Australia",IUCr - International Union of Crystallography,English,1600-5767,
Inspec,Mocking the weak lensing universe: the LensTools Python computing package,"We present a newly developed software package which implements a wide range of routines frequently used in Weak Gravitational Lensing (WL). With the continuously increasing size of the WL scientific community we feel that easy to use Application Program Interfaces (APIs) for common calculations are a necessity to ensure efficiency and coordination across different working groups. Coupled with existing open source codes, such as CAMB (Lewis et al., 2000) and Gadget2 (Springel, 2005), LensTools brings together a cosmic shear simulation pipeline which, complemented with a variety of WL feature measurement tools and parameter sampling routines, provides easy access to the numerics for theoretical studies of WL as well as for experiment forecasts. Being implemented in python (Rossum, 1995), LensTools takes full advantage of a range of state-of-the art techniques developed by the large and growing open-source software community (Jones et al., 2001; McKinney, 2010; Astrophy Collaboration, 2013; Pedregosa et al., 2011; Foreman-Mackey et al., 2013). We made the LensTools code available on the Python Package Index and published its documentation on http://lenstools.readthedocs.io. [All rights reserved Elsevier].",weak gravitational lensing universe - LensTools Python computing package - software package - WL scientific community - application program interfaces - working groups - open source code CAME - open source code Gadget2 - cosmic shear simulation pipeline - WL feature measurement tools - parameter sampling routines - experiment forecasts - open-source software community - Python Package Index,"Petri, A.(1)",2016.0,Journal,Astronomy and Computing,10.1016/j.ascom.2016.06.001,"(1) Dept. of Phys., Columbia Univ., New York, NY, United States",Elsevier B.V.,English,2213-1337,
Inspec,Mocking the weak lensing universe: the LensTools python computing package [arXiv],"We present a newly developed software package which implements a wide range of routines frequently used in Weak Gravitational Lensing (WL). With the continuously increasing size of the WL scientific community we feel that easy to use Application Program Interfaces (APIs) for common calculations are a necessity to ensure efficiency and coordination across different working groups. Coupled with existing open source codes, such as CAMB[1] and Gadget2[2], LensTools brings together a cosmic shear simulation pipeline which, complemented with a variety of WL feature measurement tools and parameter sampling routines, provides easy access to the numerics for theoretical studies of WL as well as for experiment forecasts. Being implemented in PYTHON[3], LensTools takes full advantage of a range of state-of-the art techniques developed by the large and growing open-source software community [4, 5, 6, 7, 8]. We made the LensTools code available on the Python Package Index and published its documentation on http://lenstools.readthedocs.io [Astronomy & Computing, Volume 17, Pages 73-79, October 2016 doi:10.1016/j.ascom.2016.06.001].",LensTools python computing package - Python Package Index - open-source software community - experiment forecasts - parameter sampling routines - WL feature measurement tools - cosmic shear simulation pipeline - open source code LensTools - open source code Gadget - open source code CAMB - working groups - application program interfaces - WL scientific community - weak gravitational lensing universe - software package,"Petri, A.(1)",2016.0,arXiv,arXiv,,"(1) Dept. of Phys., Columbia Univ., New York, NY, United States",arXiv,English,,
Inspec,Python based framework for HDSLs with an underlying formal semantics,"Although Moore's law is slowing down, design productivity is still a big issue in semiconductor industry. Drivers are the trend to 3D integration, the addition of design goals such as ultra-low power and safety, and an increasing number of designs in IoT and automotive areas. EDA tools such as high-level synthesis cover a small design area only. Also, the impact of IP reuse is overestimated since IP integration often requires complex configuration and additional software to be developed. To continuously increase design productivity, Infineon heavily relies on an in-house automation framework that utilizes Python as language for automation and synthesis. It supports (and makes use of) classical HDSLs to describe specific design aspects. Mostly structured specification formalisms such as tables, requirements or diagrams (e.g. SysML subsets) are used. These formalisms can be seen as HDSLs with the additional benefit that they exist as a result of a specification process, i.e. need not be coded explicitly. To be able to deal with several formalisms, Infineon's automation framework follows OMG's MDA vision and utilizes meta-models e.g. for generation of infrastructure code. This work focuses on the aspect of combining DSLs, defining a formal semantic for HDSLs and using this definition to validate the correctness of the mapping of HDSLs to HDLs, an essential pillar to connect HDSLs to today's design flows.",Python based framework - HDSLs - Moore's law - design productivity - semiconductor industry - design goals - EDA tools - high-level synthesis - IP reuse - IP integration - in-house automation framework - specific design aspects - specification formalisms - specification process - Infineon's automation framework - formal semantics - ultra-low power design - safety design - OMG MDA vision - automation language,"Devarajegowda, K.(1); Schreiner, J.(1); Findenig, R.(1); Ecker, W.(1)",2017.0,Conference,2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),10.1109/ICCAD.2017.8203893,"(1) Infineon Technol. AG, Munich, Germany",IEEE,English,,
Inspec,Practical experiences with Python and Linux RT at the SUPSI Laboratory,"This paper presents a Computer Aided Control System Design (CACSD) environment completely based on the programming language Python. Students can perform all the control design tasks (modeling, identification, controller design, simulation) in this environment, and at the end, they can automatically generate RT code for targets like a PC or a Raspberry PI with a Linux RT OS. A Python package for control purposes have been developed at the Caltech by Richard Murray, with the aim of integrating the most used functions and methods available in other commercial and non commercial software. Using this package it is possible to design different kinds of controllers for laboratory plants (PID, state-feedback, LQR, including full and reduced order observers). An additional package developed at SUPSI allows representing the full system in a graphical block diagram, similar to xCos or Simulink, and automatically generating code for RT targets. This application offers the most used blocks required for the design of a control system. New blocks can be easily integrated into this SW. This environment has been validated at the SUPSI laboratory on different electromechanical plants: the classical InvertedPendulum, the DisksandSpring system, the BallonPlate and the BallonWheel plants. [All rights reserved Elsevier].",SUPSI laboratory - Python programming language - controller design - Python package - laboratory plants - state-feedback - graphical block diagram - Computer Aided Control System Design - PID controller - LQR - reduced order observers - full order observers,"Bucher, R.(1)",2019.0,Journal,IFAC - Papers Online,10.1016/j.ifacol.2019.08.137,"(1) Inst. for Syst. & Appl. Electron., Univ. of Appl. Sci. of Southern Switzerland, Lugano-Manno, Switzerland",Elsevier B.V.,English,2405-8963,
Inspec,Python unleashed on systems biology,"Researchers at Cornell University have built an open source software system to model biomolecular reaction networks. SloppyCell is written in Python and uses third-party libraries extensively, but it also does some fun things with on-the-fly code generation and parallel programming.",Python - systems biology - open source software system - biomolecular reaction network modeling - SloppyCell - third-party libraries - on-the-fly code generation - parallel programming,"Myers, C.R.(1); Gutenkunst, R.N.(1); Sethna, J.P.(1)",2007.0,Journal,Computing in Science & Engineering,,"(1) Cornell Univ., Ithaca, NY, United States",IEEE,English,1521-9615,
Inspec,Case study on the process of teachers transitioning to teaching programming in Python,"The aim of our research was to investigate the process of teachers transitioning to teaching programming in Python, with respect to the challenges they face and support they require. Through the methods of qualitative research, we analysed a number of cases where computer science teachers transitioned from teaching in Pascal to Python. Based on the analysis of these cases, we propose a categorization for the transformation process. We identified influencing factors and present recommendations to support teachers transitioning to teaching a new language. We believe our research will contribute to improved support for teachers transitioning to teaching programming basics in new programming languages.",teaching programming basics - programming languages - computer science teachers - transformation process - Python - teachers transitioning - Pascal,"Klimekova´, E.(1); Tomcsa´nyiova´, M.(1)",2018.0,Conference,"Informatics in Schools Fundamentals of Computer Science and Software Engineering. 11th International Conference on Informatics in Schools: Situation, Evolution, and Perspectives, ISSEP 2018 Proceedings: Lecture Notes in Computer Science (LNCS 11169)",10.1007/978-3-030-02750-6_17,"(1) Dept. of Inf. Educ., Comenius Univ. in Bratislava, Bratislava, Slovakia",Springer International Publishing,English,,
Inspec,Python Source Code De-anonymization Using Nested Bigrams,"An important issue in cybersecurity is the insertion or modification of code by individuals other than the original authors of the code. This motivates research on authorship attribution of unknown source code. We have addressed the deficiencies of previously used feature extraction methods and propose a novel approach: Nested Bigrams. Such features are easy to extract and carry substantial information about the interconnections between the nodes of the abstract syntax tree. We also show that for large number of authors, a Strongly Regularized Feed-forward Neural Network outperforms the Random Forest Classifier used in many code stylometric studies. A new ranking system for reducing the number of features is also proposed, and experiments show that this approach can reduce the feature set to 98 nested bigrams while maintaining a classification accuracy above 90 percent.",authorship attribution - abstract syntax tree - feature extraction - feedforward neural network - code stylometric - nested bigrams - random forest classifier - Python source code deanonymization - cybersecurity,"Hozhabrierdi, P.(1); Fuentes Hitos, D.(2); Mohan, C.K.(1)",2018.0,Conference,2018 IEEE International Conference on Data Mining Workshops (ICDMW). Proceedings,10.1109/ICDMW.2018.00011,"(1) EECS Dept., Syracuse Univ., Syracuse, NY, United States; (2) Matilock, Inc., Huelva, Spain",IEEE Computer Society,English,,
Inspec,PySAP: python sparse data analysis package for multidisciplinary image processing [arXiv],"We present the open-source image processing software package PySAP (Python Sparse data Analysis Package) developed for the COmpressed Sensing for Magnetic resonance Imaging and Cosmology (COSMIC) project. This package provides a set of flexible tools that can be applied to a variety of compressed sensing and image reconstruction problems in various research domains. In particular, PySAP offers fast wavelet transforms and a range of integrated optimisation algorithms. In this paper we present the features available in PySAP and provide practical demonstrations on astrophysical and magnetic resonance imaging data.",python sparse data analysis package - multidisciplinary image processing - image reconstruction problems - astrophysical resonance imaging data - open-source image processing software package - PySAP - COmpressed Sensing for Magnetic resonance Imaging and Cosmology - COSMIC project,"Farrens, S.(1); Grigis, A.(2); El Gueddari, L.(2); Ramzi, Z.(1); Chaithya, G.R.(2); Starck, S.(3); Sarthou, B.(4); Cherkaoui, H.(2); Ciuciu, P.(2); Starck, J.-L.(1)",2019.0,arXiv,arXiv,,"(1) CEA, Univ. Paris Diderot, Gif-sur-Yvette, France; (2) DRF, Univ. Paris-Saclay, Gif-sur-Yvette, France; (3) EPITA, Le Kremlin-Bicetre, France; (4) ENSTA ParisTech, Palaiseau, France",arXiv,English,,
Inspec,A Python Based InSAR Processing Tool For ISRO SAR Missions,"Interferometric Synthetic Aperture Radar (InSAR) is a remote sensing technique widely used to generate elevation maps, commonly known as interferograms, that depicts surface deformations and topographic trends. Changes in topography and deformations can be measured over span of days to years and are recorded in the form of fringes. Taking into consideration the upcoming NASA-ISRO Synthetic Aperture Radar (NISAR) mission, which is designed to support wide-swath interferometry, it is high time to develop a InSAR processing tool dedicated to ISRO missions. Due to its versatile features, popularity, flexibility and the huge library support, the tool development was chosen to be in Python3 programming language. In this paper the first results obtained from the in-house developed, python 3 based, software tool for InSAR processing are presented. The tool is slated to become part of the Microwave Data Analysis Software (MIDAS) of SAC, which is a generic SAR processing software suite. Currently, the tool accepts ERS 1/2, ENVISAT, RADARSAT-2 and ALOS-2 data. For verification purpose, the outputs generated by the tool are compared with those generated by the freely available Delft Object-oriented Radar Interferometric Software (DORIS) developed by the Delft Institute of Earth Observation and Space Systems (DEOS), Delft University of Technology.",Python3 programming language - software tool - ISRO SAR missions - Python based InSAR processing tool - interferometric synthetic aperture radar - SAR processing software suite - Delft Object-oriented Radar Interferometric Software,"Panchal, R.(1); Chirakkal, S.(2); Putrevu, D.(2); Misra, A.(2)",2019.0,Conference,2019 URSI Asia-Pacific Radio Science Conference (AP-RASC),10.23919/URSIAP-RASC.2019.8738729,"(1) Chhotubhai Gopalbhai Inst. of Technol., Bardoli, India; (2) Adv. Microwave & Hyperspectral Tech. Dev. Group, Space Applic. Center, Ahmedabad, India",IEEE,English,,
Inspec,SkyLLH - a generalized python-based tool for log-likelihood analyses in multi-messenger astronomy [arXiv],"Common analysis techniques in multi-messenger astronomy involve hypothesis tests with unbinned log-likelihood (LLH) functions using data recorded in celestial coordinates to identify sources of high-energy cosmic particles in the Universe. We present the new Python-based tool ""SkyLLH"" to develop such analyses in a telescope-independent framework. The main goal of the software is to provide an easy-to-use and modularized concept to implement and to execute such LLH functions efficiently on the computer with high-performance. SkyLLH can be applied on different multi-messenger data like neutrino and gamma-ray events from experiments such as the IceCube Neutrino Observatory and the Fermi-LAT. In this contribution we highlight SkyLLH's various design goals, current development status, and prospects for its wider application in multi-messenger astronomy.",Fermi-LAT - IceCube Neutrino Observatory - telescope-independent framework - unbinned log-likelihood functions - SkyLLH tool - LLH functions - high-energy cosmic particles - multimessenger astronomy - python-based tool,"Wolf, M.(1)",2019.0,arXiv,arXiv,,"(1) Phys.-Dept., Tech. Univ. Munchen, Garching, Germany",arXiv,English,,
Inspec,Biopython: Python tools for computational biology,"The Biopython project was formed in August 1999 as a collaboration to collect and produce open source bioinformatics tools written in Python, an object-oriented scripting language. It is modeled on the highly successful Bioperl project, but has the goal of making libraries available for people doing computations in Python. The philosophy of all the Bio* projects is that part of bioinformaticists' work involves software development. In order to prevent repeated efforts we believe that the field can be advanced more quickly if libraries that perform common programming functions are available. Thus, we hope to create a central source for high-quality bioinformatics tools that researchers can use. As an open source project, Biopython can be downloaded for free from the Web site at http://www.biopython.org. Biopython libraries are currently under heavy development. This paper describes the current state of available Biopython tools, shows examples of their use in common bioinformatics problems, and describes plans for future development.",Biopython project - computational biology - python tools - open source bioinformatics tools - object-oriented scripting language - Bioperl project - libraries - Bio* projects - software development,"Chapman, B.(1); Chang, J.",2000.0,Journal,SIGBIO Newsletter,10.1145/360262.360268,"(1) Georgia Univ., Athens, GA, United States",ACM,English,0163-5697,
Inspec,"PyBoolNet: a python package for the generation, analysis and visualization of boolean networks","Motivation: The goal of this project is to provide a simple interface to working with Boolean networks. Emphasis is put on easy access to a large number of common tasks including the generation and manipulation of networks, attractor and basin computation, model checking and trap space computation, execution of established graph algorithms as well as graph drawing and layouts. Results: PYBOOLNET is a Python package for working with Boolean networks that supports simple access to model checking via NUSMV, standard graph algorithms via NETWORKX and visualization via DOT. In addition, state of the art attractor computation exploiting POTASSCO ASP is implemented. The package is function-based and uses only native Python and NETWORKX data types.",basin computation - model checking - trap space computation - graph drawing - layouts - PYBOOLNET - python package - boolean networks - standard graph algorithms - visualization - graph algorithms - NUSMV - DOT - POTASSCO ASP - NETWORKX datatype,"Klarner, H.(1); Streck, A.(1); Siebert, H.(1)",2017.0,Journal,Bioinformatics,10.1093/bioinformatics/btw682,"(1) Inst. fur Math., Freie Univ. Berlin, Berlin, Germany",Oxford University Press,English,1367-4803,
Inspec,Translation of Image Edge Detection Based on Python,"Matlab software is often used in image processing, with the development of science and technology, a lot of data to be efficient and real-time processing is valued. Python as a new interpretation scripting language, the program is simple, easy tounderstand, and maintain real-time processing. Using python in image processing, can well keep the requirements of the designer, because of the open and free program, reduce the difficulty of programming, and enhance the interest of programmers. In this paper, through the comparison between canny operators, Sobel operator, lapla operator in image processing, the simulation results verify that the canny operator has good detection effect. The simulation results show the advantages of python, is suitable for the use in image processing.",image edge detection - python - image processing - open program - canny operator - Matlab software - scripting language - Sobel operator - lapla operator,Chuanwei Zhang(1); Yu Zhengyang(1),2019.0,Conference,IOP Conference Series: Earth and Environmental Science,10.1088/1755-1315/252/5/052121,"(1) Coll. of Mech. Eng., Xi'an Univ. of Sci. & Technol., Xi'an, China",IOP Publishing,English,1755-1307,
Inspec,GraKeL: A Graph Kernel Library in Python [arXiv],"The problem of accurately measuring the similarity between graphs is at the core of many applications in a variety of disciplines. Graph kernels have recently emerged as a promising approach to this problem. There are now many kernels, each focusing on different structural aspects of graphs. Here, we present GraKeL, a library that unifies several graph kernels into a common framework. The library is written in Python and is build on top of scikit-learn. It is simple to use and can be naturally combined with scikit-learn's modules to build a complete machine learning pipeline for tasks such as graph classification and clustering. The code is BSD licensed and is available at: https://github.com/ysig/GraKeL.",graph kernel library - Python - graph kernels - scikit-learn - complete machine learning pipeline - graph classification - GraKeL,"Siglidis, G.; Nikolentzos, G.; Limnios, S.; Giatsidis, C.; Skianis, K.; Vazirgianis, M.",2018.0,arXiv,arXiv,,,arXiv,English,,
Inspec,PyPUT: Python-based Placement Utilities Toolset,"In the placement stage of a standard-cell design flow, a set of cells must be placed within a specified rectangular region, that may contain obstacles, in such a way that overlaps and overflows are non-existent and a target function is optimized. An efficient placement algorithm combined with an appropriate routing algorithm can attain a design without manufacturability issues. Although placement is in the forefront of Physical Design research, there is a distinct lack of libraries and/or toolsets that can be used to develop the aforementioned algorithms. In this paper we present an open-source Python-based toolset for the development of placement algorithms.",PyPUT - placement stage - standard-cell design flow - specified rectangular region - efficient placement algorithm - open-source Python-based toolset - placement algorithms - physical design research - routing algorithm - open-source Python-based placement utilities,"Kranas, G.(1); Tsalamagkakis, G.-C.(1); Oikonomou, P.(1); Dadaliaris, A.N.(1)",2018.0,Conference,"2018 South-Eastern European Design Automation, Computer Engineering, Computer Networks and Society Media Conference (SEEDA_CECNSM)",10.23919/SEEDA-CECNSM.2018.8544926,"(1) Comput. Sci. Dept., Univ. of Thessaly, Lamia, Greece",IEEE,English,,
Inspec,VyPR2: a framework for runtime verification of python web services,"Runtime Verification (RV) is the process of checking whether a run of a system holds a given property. In order to perform such a check online, the algorithm used to monitor the property must induce minimal overhead. This paper focuses on two areas that have received little attention from the RV community: Python programs and web services. Our first contribution is the VyPR runtime verification tool for single-threaded Python programs. The tool handles specifications in our, previously introduced, Control-Flow Temporal Logic (CFTL), which supports the specification of state and time constraints over runs of functions. VyPR minimally (in terms of reachability) instruments the input program with respect to a CFTL specification and then uses instrumentation information to optimise the monitoring algorithm. Our second contribution is the lifting of VyPR to the web service setting, resulting in the VyPR2 tool. We first describe the necessary modifications to the architecture of VyPR, and then describe our experience applying VyPR2 to a service that is critical to the physics reconstruction pipeline on the CMS Experiment at CERN.",RV community - VyPR runtime verification tool - single-threaded Python programs - Control-Flow Temporal Logic - input program - CFTL specification - monitoring algorithm - VyPR2 tool - Python Web services - instrumentation information - physics reconstruction pipeline - time constraints - reachability instruments,"Dawes, J.H.(1); Reger, G.(1); Franzoni, G.(2); Pfeiffer, A.(2); Govi, G.(3)",2019.0,Conference,"Tools and Algorithms for the Construction and Analysis of Systems. 25th International Conference, TACAS 2019. Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2019. Proceedings: Lecture Notes in Computer Science (11428)",10.1007/978-3-030-17465-1_6,"(1) Univ. of Manchester, Manchester, United Kingdom; (2) CERN, Geneva, Switzerland; (3) Fermi Nat. Accel. Lab., Batavia, IL, United States",Springer International Publishing,English,,
Inspec,GfaPy: a flexible and extensible software library for handling sequence graphs in Python,"GFA 1 and GFA 2 are recently defined formats for representing sequence graphs, such as assembly, variation or splicing graphs. The formats are adopted by several software tools. Here, we present GfaPy, a software package for creating, parsing and editing GFA graphs using the programming language Python. GfaPy supports GFA 1 and GFA 2, using the same interface and allows for interconversion between both formats. The software package provides a simple interface for custom record types, which is an important new feature of GFA 2 (compared to GFA 1). This enables new applications of the format.",GfaPy - GFA 1 - GFA 2 - software tools - software package - software library - variation graphs - GFA graphs - sequence graphs representation - splicing graphs - programming language Python - custom record types,"Gonnella, G.(1); Kurtz, S.(1)",2017.0,Journal,Bioinformatics,10.1093/bioinformatics/btx398,"(1) Center for Bioinf., Univ. Hamburg, Hamburg, Germany",Oxford University Press,English,1367-4803,
Inspec,"ImagePy: an open-source, Python-based and platform-independent software package for bioimage analysis","This note presents the design of a scalable software package named ImagePy for analysing biological images. Our contribution is concentrated on facilitating extensibility and interoperability of the software through decoupling the data model from the user interface. Especially with assistance from the Python ecosystem, this software framework makes modern computer algorithms easier to be applied in bioimage analysis.",open-source software package - Python-based software package - biological images - software framework - Python ecosystem - user interface - data model - bioimage analysis - platform-independent software package - ImagePy,Anliang Wang(1); Xiaolong Yan(1); Zhijun Wei(2),2018.0,Journal,Bioinformatics,10.1093/bioinformatics/bty313,"(1) Div. of Marine Disaster Forecasting & Warning, Nat. Marine Environ. Forecasting Center, Beijing, China; (2) State Key Lab. of Coastal & Offshore Eng., Dalian Univ. of Technol., Dalian, China",Oxford University Press,English,1367-4803,
Inspec,A statistical comparison of java and python software metric properties,"This paper presents a statistical analysis of 20 opensource object-oriented systems with the purpose of detecting differences in metrics distribution between Java and Python projects. We selected ten Java projects from the Java Qualitas Corpus and ten projects written in Python. For each system, we considered 10 class-level software metrics.We performed a best fit procedure on the empirical distributions through the log-normal distribution and the double Pareto distribution to identify differences between the two languages. Even though the statistical distributions for projects written in Java and Python may appear the same for lower values of the metric, performing the procedure with the double Pareto distribution for the Number of Local Methods metric reveals that major differences can be noticed along the queue of the distributions. On the contrary, the same analysis performed with the Number of Statements metric reveals that only the initial portion of the double Pareto distribution shows differences between the two languages. In addition, the dispersion parameter associated to the log-normal distribution fit for the total Number Of Methods can be used for distinguishing Java projects from Python projects.",Java projects - Python projects - software metric properties - statistical analysis - opensource object-oriented systems - metrics distribution - Java Qualitas Corpus - log-normal distribution - double Pareto distribution - number of local methods metrics - distribution queues - number of statements metric - dispersion parameter,"Destefanis, G.(1); Ortu, M.(1); Porru, S.(1); Swift, S.(1); Marchesi, M.(1)",2016.0,Conference,2016 IEEE/ACM 7th International Workshop on Emerging Trends in Software Metrics (WETSoM),10.1109/WETSoM.2016.012,"(1) Brunel Univ., Uxbridge, United Kingdom",IEEE,English,,
Inspec,Gistable: Evaluating the Executability of Python Code Snippets on GitHub,"Software developers create and share code online to demonstrate programming language concepts and programming tasks. Code snippets can be a useful way to explain and demonstrate a programming concept, but may not always be directly executable. A code snippet can contain parse errors, or fail to execute if the environment contains unmet dependencies. This paper presents an empirical analysis of the executable status of Python code snippets shared through the GitHub gist system, and the ability of developers familiar with software configuration to correctly configure and run them. We find that 75.6% of gists require non-trivial configuration to overcome missing dependencies, configuration files, reliance on a specific operating system, or some other environment configuration. Our study also suggests the natural assumption developers make about resource names when resolving configuration errors is correct less than half the time. We also present Gistable, a database and extensible framework built on GitHub's gist system, which provides executable code snippets to enable reproducible studies in software engineering. Gistable contains 10,259 code snippets, approximately 5,000 with a Dockerfile to configure and execute them without import error. Gistable is publicly available at https://github.com/gistable/gistable.",programming concept - Python code snippets - GitHub gist system - software configuration - configuration files - environment configuration - executable code snippets - programming language concepts - programming tasks - configuration errors - Gistable - software engineering,"Horton, E.(1); Parnin, C.(1)",2018.0,Conference,2018 IEEE International Conference on Software Maintenance and Evolution (ICSME). Proceedings,10.1109/ICSME.2018.00031,"(1) NC State Univ., Raleigh, NC, United States",IEEE Computer Society,English,,
Inspec,PsychoPy-Psychophysics software in Python,"The vast majority of studies into visual processing are conducted using computer display technology. The current paper describes a new free suite of software tools designed to make this task easier, using the latest advances in hardware and software. PsychoPy is a platform-independent experimental control system written in the Python interpreted language using entirely free libraries. PsychoPy scripts are designed to be extremely easy to read and write, while retaining complete power for the user to customize the stimuli and environment. Tools are provided within the package to allow everything from stimulus presentation and response collection (from a wide range of devices) to simple data analysis such as psychometric function fitting. Most importantly, PsychoPy is highly extensible and the whole system can evolve via user contributions. If a user wants to add support for a particular stimulus, analysis or hardware device they can look at the code for existing examples, modify them and submit the modifications back into the package so that the whole community benefits. [All rights reserved Elsevier].",PsychoPy scripts - psychophysics software - software package - Python - software tools - platform-independent experimental control system - data analysis - psychometric function fitting - visual processing - computer display technology - free libraries - stimulus presentation,"Peirce, J.W.(1)",2007.0,Journal,Journal of Neuroscience Methods,10.1016/j.jneumeth.2006.11.017,"(1) Nottingham Visual Neurosci., Univ. of Nottingham, United Kingdom",Elsevier,English,0165-0270,
Inspec,A Software Metric for Python Language,"There are many metrics for evaluating the quality of codes written in different programming languages. However, no efforts have been done to propose metrics for Python, which is an important and useful language especially for the software development for the embedded systems. In this present work, we are trying to investigate all the factors, which are responsible for increasing the complexity of code written in Python language. Accordingly, we have proposed a unified metric for this language. Practical applicability of the metric is demonstrated on a case study.",software metric - python language - programming languages - software development - embedded systems - Python language,"Misra, S.(1); Cafer, F.(1)",2010.0,Conference,Computational Science and Its Applications - ICCSA 2010. Proceedings International Conference,10.1007/978-3-642-12165-4_24,"(1) Dept. of Comput. Eng., Fed. Univ. of Technol., Minna, Nigeria",Springer Verlag,English,,
Inspec,Towards More Sophisticated Static Analysis Methods of Python Programs,"Static analysis is a software verification method which is analyzing the source code without executing it for detecting code smells and possible software bugs. Various analysis methods have been successfully applied for languages with static type system, such as C, C++ and Java. Python is an important programming language with dynamic type system, used in many emerging areas, including data science, machine learning and web applications. The dynamic behavior of the Python language requires different static analysis approaches compared to the ones with static type system. In this paper we overview these methods and investigate their advantages and shortages. We compare the symbolic execution with the generally used Abstract Syntax Tree based approach and show its advantages based on concrete examples. We also highlight the restrictions of current tools and suggest further research directions to tackle these problems.",Python language - static analysis - static type system - static analysis methods - software verification method - source code - software bugs - programming language - dynamic behavior - abstract syntax tree based approach,"Gulabovska, H.(1); Porkolab, Z.(1)",2019.0,Conference,2019 IEEE 15th International Scientific Conference on Informatics (INFORMATICS 2019). Proceedings,10.1109/Informatics47936.2019.9119307,"(1) Dept. of Program. Languages & Compilers, Eotvos Lorand Univ., Budapest, Hungary",IEEE,English,,
Inspec,Gistable: Evaluating the Executability of Python Code Snippets on GitHub [arXiv],"Software developers create and share code online to demonstrate programming language concepts and programming tasks. Code snippets can be a useful way to explain and demonstrate a programming concept, but may not always be directly executable. A code snippet can contain parse errors, or fail to execute if the environment contains unmet dependencies. This paper presents an empirical analysis of the executable status of Python code snippets shared through the GitHub gist system, and the ability of developers familiar with software configuration to correctly configure and run them. We find that 75.6% of gists require non-trivial configuration to overcome missing dependencies, configuration files, reliance on a specific operating system, or some other environment configuration. Our study also suggests the natural assumption developers make about resource names when resolving configuration errors is correct less than half the time. We also present Gistable, a database and extensible framework built on GitHub's gist system, which provides executable code snippets to enable reproducible studies in software engineering. Gistable contains 10,259 code snippets, approximately 5,000 with a Dockerfile to configure and execute them without import error. Gistable is publicly available at https://github.com/gistable/gistable.",Python code snippets - programming language concepts - software configuration - GitHub's gist system - software developers - share code online - software engineering - Gistable - parse errors,"Horton, E.(1); Parnin, C.(1)",2018.0,arXiv,arXiv,,"(1) NC State Univ. Raleigh, Raleigh, NC, United States",arXiv,English,,
Inspec,On parallel software engineering education using python,"Python is gaining popularity in academia as the preferred language to teach novices serial programming. The syntax of Python is clean, easy, and simple to understand. At the same time, it is a high-level programming language that supports multi programming paradigms such as imperative, functional, and object-oriented. Therefore, by default, it is almost obvious to believe that Python is also the appropriate language for teaching parallel programming paradigms. This paper presents an in-depth study that examines to what extent Python language is suitable for teaching parallel programming to inexperienced students. The findings show that Python has stumbling blocks that prevent it from preserving its advantages when shifting from serial programming to parallel programming. Therefore, choosing Python as the first language for teaching parallel programming calls for strong justifications, especially when better solutions exist in the community.",high-level programming language - multiprogramming paradigms - appropriate language - parallel programming paradigms - parallel software engineering education - serial programming teaching - Python syntax,"Marowka, A.(1)",2018.0,Journal,Education and Information Technologies,10.1007/s10639-017-9607-0,"(1) Parallel Res. Lab., Petach-Tikva, Israel",Springer,English,1360-2357,
Inspec,SOLVCON: A Python-Based CFD Software Framework for Hybrid Parallelization,"SOLVCON is a new, open-sourced software framework for high-fidelity solutions of linear and non-linear hyperbolic partial differential equations. SOLVCON emphasizes scalability, portability, and maintainability for supercomputing by using emerging multi-core architectures. The code development effort follows Extreme Programming practices, including version control, documentation, issue tracking, user support, and frequent code releases. In SOLVCON, the Python framework includes all supportive functionalities for the work How. For pre-processing operations, the Python framework provides parallelized mesh data input and automatically sets up domain decomposition. In calculations, the Python framework provides light-weight memory management through extensive use of pointers. Computation-intensive operations are implemented by using C and FORTRAN for high performance. The default numerical algorithm employed is the space-time Conservation Element and Solution Element (CESE) method. The code uses general unstructured meshes with mixed elements, including tetrahedra, hexahedra, prisms, and pyramids for three-dimensional calculations. Hybrid parallelism includes shared- and distributed-memory parallelization. The temporal loop and the spatial loop in modern finite-volume methods are implemented in a two-layered structure in SOLVCON. Distributed-memory parallelization by domain decomposition and MPI is performed in the temporal loop. Shared-memory parallel computing by using accelerator technologies, e.g., General-Purpose Graphic Processor Unit (GPGPU), is performed in the spatial loop. More than 99% of the execution time of SOLVCON is used for number-crunching in the solver as a part of the space loop. Written in C or FORTRAN, a typical solver contains only 10% of the code statements in SOLVCON. To demonstrate the capabilities of newly developed SOLVCON, we performed CFD calculations by using 23 million elements. The code was run on a 512-core cluster. SOLVCON delivers calculations of How variables in 11.29 million elements per second. The parallel efficiency is 70%. In the open-sourced SOLVCON, two solvers are available: (i) the Euler equations solver for compressible Hows, and (ii) the velocity-stress equations solver for waves in anisotropic elastic solids. SOLVCON can be easily extended for other applications, including viscous Hows, aero-acoustics, nonlinear solid mechanics, and electromagnetism. The Python framework allows fast adaption to new heterogeneous, multi-core hardware as well as further development of the code for peta-scale supercomputing.",Python-based CFD software framework - hybrid parallelization - SOLVCON - open-sourced software framework - high-fidelity solutions - linear hyperbolic partial differential equations - nonlinear hyperbolic partial differential equations - scalability - portability - maintainability - supercomputing - multicore architecture - code development - version control - issue tracking - user support - frequent code releases - supportive functionalities - parallelized mesh data input - domain decomposition - light-weight memory management - C language - FORTRAN - numerical algorithm - space-time conservation element and solution element method - CESE method - general unstructured meshes - tetrahedra element - hexahedra element - prism element - pyramid element - three-dimensional calculations - temporal loop - spatial loop - finite volume method - two-layered structure - distributed memory parallelization - MPI - shared memory parallelization - shared memory parallel computing - accelerator technologies - number crunching - CFD calculations - velocity-stress equation solver - anisotropic elastic solids - viscous flow - aeroacoustics - nonlinear solid mechanics - electromagnetism - heterogeneous multicore hardware - peta-scale supercomputing,"Yung-Yu Chen(1); Bilyeu, D.L.(1); Lixiang Yang(1); Yu, S.-T.J.(1)",2011.0,Conference,49th AIAA Aerospace Sciences Meeting including the New Horizons Forum and Aerospace Exposition,,"(1) Dept. of Mech. & Aerosp. Eng., Ohio State Univ., Columbus, OH, United States",American Institute of Aeronautics & Astronautics,English,,
Inspec,A variable selection package driving Netica with Python,"Bayesian Networks (BNs) are useful methods of probabilistically modelling environmental systems. BN performance is sensitive to the number of variables included in the model framework. The selection of the optimum set of variables to include in a BN (ldquovariable selectionrdquo) is therefore a key part of the BN modelling process. While variable selection is an issue dealt with in the wider BN and machine learning literature, it remains largely absent from environmental BN applications to date, due in large part to a lack of software designed to work with available BN packages. CVNetica_VS is an open-source Python module that extends the functionality of Netica, a commonly used commercial BN software package, to perform variable selection. CVNetica_VS uses wrapper-based variable selection and cross-validation to search for the optimum variable set to use in a BN. The software will aid in objectifying and automating the development of BNs in environmental applications. [All rights reserved Elsevier].",variable selection package - Netica - probabilistically modelling environmental systems - BN performance - model framework - BN modelling process - environmental BN applications - Bayesian networks - machine learning - CVNetica_VS - commercial BN software package - optimum variable set - wrapper-based variable selection - open-source Python module,"Beuzen, T.(1); Simmons, J.(1)",2019.0,Journal,Environmental Modelling & Software,10.1016/j.envsoft.2019.01.018,"(1) Sch. of Civil & Environ. Eng., Water Res. Lab., Sydney, NSW, Australia",Elsevier B.V.,English,1364-8152,
Inspec,NL4Py: Agent-Based Modeling in Python with Parallelizable NetLogo Workspaces [arXiv],"NL4Py is a NetLogo controller software for Python, for the rapid, parallel execution of NetLogo models. NL4Py provides both headless (no graphical user interface) and GUI NetLogo workspace control through Python. Spurred on by the increasing availability of open-source computation and machine learning libraries on the Python package index, there is an increasing demand for such rapid, parallel execution of agent-based models through Python. NetLogo, being the language of choice for a majority of agent-based modeling driven research projects, requires an integration to Python for researchers looking to perform statistical analyses of agent-based model output using these libraries. Unfortunately, until the recent introduction of PyNetLogo, and now NL4Py, such a controller was unavailable. This article provides a detailed introduction into the usage of NL4Py and explains its client-server software architecture, highlighting architectural differences to PyNetLogo. A step-by-step demonstration of global sensitivity analysis and parameter calibration of the Wolf Sheep Predation model is then performed through NL4Py. Finally, NL4Py's performance is benchmarked against PyNetLogo and its combination with IPyParallel, and shown to provide significant savings in execution time over both configurations.",Python - rapid execution - parallel execution - agent-based model output - agent-based modeling - parallelizable NetLogo workspaces - NetLogo controller software - NetLogo models - GUI NetLogo workspace control - NL4Py performance,"Gunaratne, C.(1); Garibay, I.(1)",2018.0,arXiv,arXiv,,"(1) Complex Adaptive Syst. Lab., Univ. of Central Florida, Orlando, FL, United States",arXiv,English,,
Inspec,How Do Contributors Impact Code Naturalness? An Exploratory Study of 50 Python Projects,"Recent studies have shown how software is comparable to natural languages, meaning that source code is highly repetitive and predictable. Other studies have shown the naturalness as indicators for code quality (i.e., buggy code). With the rise of social coding and the popularity of open source projects, the software is now being built with contributions that come from contributors from diverse backgrounds. From this social contribution perspective, we explore how contributors impact code naturalness. In detail, our exploratory study investigators whether the developers' history of programming language experience affects the code naturalness. Calculating the code naturalness of 678 contributors from 50 open-source python projects, we analyze how two aspects of contributor activities impact the code naturalness: (a) the number of contributors in a software project, (b) diversity of programming language contributions. The results show that the code naturalness is affected by the diversity of contributors and that more collaborative software tends to be less predictable. This exploratory study serves as evidence into the relationship between code naturalness and the programming diversity of contributors.",buggy code - social coding - code naturalness - contributor activities impact - natural languages - source code - code quality - open-source Python projects - programming language contributions - collaborative software,"Bunkerd, T.(1); Dong Wang(2); Kula, R.G.(2); Chaiyong Ragkhitwetsagul(1); Choetkiertikul, M.(1); Sunetnanta, T.(1); Ishio, T.(2); Matsumoto, K.(2)",2019.0,Conference,2019 10th International Workshop on Empirical Software Engineering in Practice (IWESEP),10.1109/IWESEP49350.2019.00010,"(1) Fac. of Inf. & Commun. Technol., Mahidol Univ., Bangkok, Thailand; (2) Nara Inst. of Sci. & Technol., Nara, Japan",IEEE,English,,
Inspec,Real-time embedded software test script based on python,"A real-time test script is designed based on Python, and relevant extended module is developed achieving the interface between ESSTE and interpreter. The test script possesses portability and quickly, it has advantages of strong ability to describe and good reusability and it has applied in ESSTE successfully. A number of real-time embedded systems are tested by this script technology, both the correctness and the real-time performance are validated.",real-time embedded software test script - Python - ESSTE - automatic software test - simulation test environment,Jiang Chong-wu(1); Liu Bin(1); Wang Yi-chen(1); Hu Xuan(1),2009.0,Journal,Computer Engineering,,"(1) Dept. of Syst. Eng. of Eng. Technol., Beihang Univ., Beijing, China",Editorial Board of Computer Engineering,Chinese,1000-3428,
Inspec,A Python Library for Deep Linguistic Resources,"This paper describes PyDelphin: an open-source software library, coded in Python, for working with the resources and results of Deep Linguistic Processing with HPSG (DELPH-IN). These resources and processing results offer rich syntactic and semantic information from linguistically-informed grammars but the original software stack for working with them presents significant technical hurdles for installation and use, particularly for new users and for single experiments. PyDelphin is quick to install and its thorough documentation makes it easy for newcomers to get started. It contains packages that implement a number of DELPH-IN technologies for working with semantic representations, grammar descriptions, tokenization, and corpus databases. It also has client interfaces for related external processors which make it straightforward to integrate these tools into a single workflow. The library has been successfully used in several research projects in topics such as abstractive summarization, machine translation, and natural language generation.",Python library - PyDelphin - open-source software library - HPSG - semantic information - linguistically-informed grammars - software stack - DELPH-IN technologies - semantic representations - grammar descriptions - external processors - deep linguistic processing,"Goodman, M.W.(1)",2019.0,Conference,2019 Pacific Neighborhood Consortium Annual Conference and Joint Meetings (PNC). Proceedings,,"(1) Sch. of Humanities, Nanyang Technol. Univ., Singapore, Singapore",IEEE,English,,
Inspec,An Empirical Analysis of the Python Package Index (PyPI) [arXiv],"In this research, we provide a comprehensive empirical summary of the Python Package Repository, PyPI, including both package metadata and source code covering 178,592 packages, 1,745,744 releases, 76,997 contributors, and 156,816,750 import statements. We provide counts and trends for packages, releases, dependencies, category classifications, licenses, and package imports, as well as authors, maintainers, and organizations. As one of the largest and oldest software repositories as of publication, PyPI provides insight not just into the Python ecosystem today, but also trends in software development and licensing more broadly over time. Within PyPI, we find that the growth of the repository has been robust under all measures, with a compound annual growth rate of 47% for active packages, 39% for new authors, and 61% for new import statements over the last 15 years. As with many similar social systems, we find a number of highly right-skewed distributions, including the distribution of releases per package, packages and releases per author, imports per package, and size per package and release. However, we also find that most packages are contributed by single individuals, not multiple individuals or organizations. The data, methods, and calculations herein provide an anchor for public discourse on PyPI and serve as a foundation for future research on the Python software ecosystem.",comprehensive empirical summary - PyPI - package metadata - import statements - package imports - largest software repositories - oldest software repositories - Python ecosystem today - software development - licensing - compound annual growth rate - active packages - Python software ecosystem - empirical analysis - Python package index - Python package repository,"Bommarito, E.(1); Bommarito, M.J., II(1)",2019.0,arXiv,arXiv,,"(1) Univ. of Michigan, Ann Arbor, MI, United States",arXiv,English,,
Inspec,Midi miner - a python library for tonal tension and track classification [arXiv],"We present a Python library, called Midi Miner, that can calculate tonal tension and classify different tracks. MIDI (Music Instrument Digital Interface) is a hardware and software standard for communicating musical events between digital music devices. It is often used for tasks such as music representation, communication between devices, and even music generation [5]. Tension is an essential element of the music listening experience, which can come from a number of musical features including timbre, loudness and harmony [3]. Midi Miner provides a Python implementation for the tonal tension model based on the spiral array [1] as presented by Herremans and Chew [4]. Midi Miner also performs key estimation and includes a track classifier that can disentangle melody, bass, and harmony tracks. Even though tracks are often separated in MIDI files, the musical function of each track is not always clear. The track classifier keeps the identified tracks and discards messy tracks, which can enable further analysis and training tasks.",harmony tracks - MIDI files - musical function - track classifier - discards messy tracks - python library - track classification - Music Instrument Digital Interface - software standard - communicating musical events - digital music devices - music representation - music generation - loudness - Python implementation - tonal tension model - Midi Miner,"Rui Guo(1); Herremans, D.(2); Magnusson, T.(1)",2019.0,arXiv,arXiv,,"(1) Univ. of Sussex, Brighton, United Kingdom; (2) Singapore Univ. of Technol. & Design, Singapore, Singapore",arXiv,English,,
Inspec,"An Analysis of Python's Topics, Trends, and Technologies Through Mining Stack Overflow Discussions [arXiv]","Python is a popular, widely used, and general-purpose programming language. In spite of its ever-growing community, researchers have not performed much analysis on Python's topics, trends, and technologies which provides insights for developers about Python community trends and main issues. In this article, we examine the main topics related to this language being discussed by developers on one of the most popular Q\&A websites, Stack Overflow, as well as temporal trends through mining 2461876 posts. To be more useful for the software engineers, we study what Python provides as the alternative to popular technologies offered by common programming languages like Java. Our results indicate that discussions about Python standard features, web programming, and scientific programming. Programming in areas such as mathematics, data science, statistics, machine learning, natural language processing (NLP), and so forth. are the most popular areas in the Python community. At the same time, areas related to scientific programming are steadily receiving more attention from the Python developers.",Web programming - natural language processing - Python developers - general-purpose programming language - Python community trends - Stack Overflow discussion mining - Python topics - Q&A Websites - software engineers - topic modeling,"Tahmooresi, H.(1); Heydarnoori, A.(1); Aghamohammadi, A.(1)",2020.0,arXiv,arXiv,,"(1) Dept. of Comput. Eng., Sharif Univ. of Technol., Tehran, Iran",arXiv,English,,
Inspec,Pykg2vec: A Python Library for Knowledge Graph Embedding [arXiv],"Pykg2vec is an open-source Python library for learning the representations of the entities and relations in knowledge graphs. Pykg2vec's flexible and modular software architecture currently implements 16 state-of-the-art knowledge graph embedding algorithms, and is designed to easily incorporate new algorithms. The goal of pykg2vec is to provide a practical and educational platform to accelerate research in knowledge graph representation learning. Pykg2vec is built on top of TensorFlow and Python's multiprocessing framework and provides modules for batch generation, Bayesian hyperparameter optimization, mean rank evaluation, embedding, and result visualization. Pykg2vec is released under the MIT License and is also available in the Python Package Index (PyPI). The source code of pykg2vec is available at https://github.com/Sujit-O/pykg2vec.",open-source Python library - knowledge graph representation learning - result visualization - mean rank evaluation - Bayesian hyperparameter optimization - batch generation - Python multiprocessing framework - TensorFlow multiprocessing framework - modular software architecture - knowledge graph embedding - Pykg2vec,"Shih Yuan Yu; Chhetri, S.R.; Canedo, A.; Goyal, P.; Al Faruque, M.A.",2019.0,arXiv,arXiv,,,arXiv,English,,
Inspec,Suggesting Comment Completions for Python using Neural Language Models,"Source-code comments are an important communication medium between developers to better understand and maintain software. Current research focuses on auto-generating comments by summarizing the code. However, good comments contain additional details, like important design decisions or required trade-offs, and only developers can decide on the proper comment content. Automated summarization techniques cannot include information that does not exist in the code, therefore fully-automated approaches while helpful, will be of limited use. In our work, we propose to empower developers through a semi-automated system instead. We investigate the feasibility of using neural language models trained on a large corpus of Python documentation strings to generate completion suggestions and obtain promising results. By focusing on confident predictions, we can obtain a top-3 accuracy of over 70%, although this comes at the cost of lower suggestion frequency. Our models can be improved by leveraging context information like the signature and the full body of the method. Additionally, we are able to return good accuracy completions even for new projects, suggesting the generalizability of our approach.",completion suggestions - comment completions - neural language - source-code comments - automated summarization - Python documentation strings - software maintenance,"Ciurumelea, A.(1); Proksch, S.(1); Gall, H.C.(1)",2020.0,Conference,"2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). Proceedings",10.1109/SANER48275.2020.9054866,"(1) Univ. of Zurich, Zurich, Switzerland",IEEE,English,,
Inspec,"Cyanure: an open-source toolbox for empirical risk minimization for python, C++, and soon more [arXiv]","Cyanure is an open-source C++ software package with a Python interface. The goal of Cyanure is to provide state-of-the-art solvers for learning linear models, based on stochastic variance-reduced stochastic optimization with acceleration mechanisms. Cyanure can handle a large variety of loss functions (logistic, square, squared hinge, multinomial logistic) and regularization functions (lscr2, lscr1, elastic-net, fused Lasso, multi-task group Lasso). It provides a simple Python API, which is very close to that of scikit-learn, which should be extended to other languages such as R or Matlab in a near future.",open-source toolbox - empirical risk minimization - Cyanure - open-source C++ software package - Python interface - stochastic variance-reduced stochastic optimization - Python API - loss functions - regularization functions - scikit-learn,"Mairal, J.(1)",2019.0,arXiv,arXiv,,"(1) Grenoble INP, Univ. Grenoble Alpes, Grenoble, France",arXiv,English,,
Inspec,PyRPL (Python Red Pitaya Lockbox) - an open-source software package for FPGA-controlled quantum optics experiments,"The Red Pitaya [1] is an affordable (< 250 Euros) field-programmable gate array (FPGA) board with fast analog inputs and outputs (sampled at 125 MHz). This makes it useful for quantum optics experiments, in particular as a digital feedback controller for analog systems. Based on the open source software provided by the board manufacturer, we have created the software package PyRPL [2] (Python RedPitaya Lockbox) which implements many devices that are needed for optics experiments with the Red Pitaya. The user interface and all high-level functionalities are written in Python, but an essential part of the software is contained in a custom FPGA design written in the hardware description language (HDL) Verilog. The HDL part of PyRPL implements various digital signal processing (DSP) modules: a two-channel oscilloscope for measurement and diagnostics; two arbitrary function generators for waveform synthesis and noise generation; four proportional-integral-derivative (PID) controllers with up to fourth-order filters for feedback control; three demodulation modules for the generation of Pound-Drever-Hall-like error signals and the realization of narrow, phase-tunable band-pass filters; an infinite impulse response (IIR) filter able to realize transfer functions with up to 24 poles and 24 zeros; a network analyzer for the characterization of analog and digital systems and in-loop tuning of feedback parameters; a spectrum analyzer for the measurement and minimization of noise in closed-loop systems.",closed-loop systems - noise minimization - IIR filter - infinite impulse response filter - phase-tunable band-pass filters - Pound-Drever-Hall-like error signals - PID controllers - proportional-integral-derivative controllers - DSP - digital signal processing - Verilog - HDL - hardware description language - digital feedback controller - FPGA-controlled quantum optics experiments - open-source software package - PyRPL - python red pitaya lockbox,"Neuhaus, L.(1); Metzdorff, R.(1); Chua, S.(1); Jacqmin, T.(1); Briant, T.(1); Heidmann, A.(1); Cohadon, P.-F.(1); Deleglise, S.(1)",2017.0,Conference,2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC),10.1109/CLEOE-EQEC.2017.8087380,"(1) Lab. Kastler Brossel, UPMC, Paris, France",IEEE,English,,
Inspec,Pypvcell: an open-source solar cell modeling library in python,"We announced a open source solar cell modeling and analysis toolkit written in Python. The standard off-the-shelf solar cell simulation software is often difficult to modify or reuse some of its functionality into new solar cell models. In this software package, we wrap the solar cell simulations into individual modules and application programming interfaces to make them very user-friendly. This library contains a wide range of functions to do the heavy-lifting, error-prone jobs of modeling solar cells, such as unit conversions and arithmetic operations of spectrum data, absorption-emission reciprocity or solving the IVs of multi-junction cells. This allows the users to rapidly adapt and build their own models with these modularized and verified components. Source codes, detailed documentation and examples can be found in https://kanhua.github.io/pypvcell.",analysis toolkit - standard off-the-shelf solar cell simulation software - software package - solar cell simulations - individual modules - application programming interfaces - multijunction cells - source codes - open-source solar cell modeling library - Python - Pypvcell - unit conversions - arithmetic operations - spectrum data - absorption-emission reciprocity,"Kan-Hua Lee(1); Araki, K.(1); Elleuch, O.(1); Kojima, N.(1); Yamaguchi, M.(1)",2017.0,Conference,2017 IEEE 44th Photovoltaic Specialist Conference (PVSC),10.1109/PVSC.2017.8366371,"(1) Texas A&M Univ., College Station, TX, United States",IEEE,English,,
Inspec,Porting the LSST Data Management Pipeline Software to Python 3 [arXiv],"The LSST data management science pipelines software consists of more than 100,000 lines of Python 2 code. LSST operations will begin after support for Python 2 has been dropped by the Python community in 2020, and we must therefore plan to migrate the codebase to Python 3. During the transition period we must also support our community of active Python 2 users and this complicates the porting significantly. We have decided to use the Python future package as the basis for our port to enable support for Python 2 and Python 3 simultaneously, whilst developing with a mindset more suited to Python 3. In this paper we report on the current status of the port and the difficulties that have been encountered.",LSST data management pipeline software - Python 3 - Python 2 code - LSST operations - Python community - active Python 2 users - Python future package,"Jenness, T.(1)",2016.0,arXiv,arXiv,,"(1) Large Synoptic Survey Telescope, Tucson, AZ, United States",arXiv,English,,
Inspec,Conception of a program for prevention of the dangers related to wind turbines using PYTHON,"This article is a study of the danger of installations of sites of renewable energies, more exactly, wind farms. After we had shown the dangers that could alter a wind turbine and minimize the most commons accidents worldwide, we noticed that the high speed of the wind always returns as the main or secondary cause in the incident. It is in this context that a program with the PYTHON software was established to warn (prevent) about accidents involving such wind turbines. This allows us to view the feasibility and to choose the suitable territory or an appropriate wind turbine to preserve the durability of the device by getting it to perform continuously in complete safety.",renewable energies - wind turbines - PYTHON software - wind farms,"Hadjij, M.(1); Abderrahim, B.(1); Lounis, Z.(1)",2018.0,Journal,Wind Engineering,10.1177/0309524X18779341,"(1) Lab. d'Ing. en Securite Ind. et Dev. Durable, Univ. d'Oran 2 Mohamed Ben Ahmed, Oran, Algeria",SAGE Publications,English,0309-524X,
Inspec,NFDMLab: Simulating Nonlinear Frequency Division Multiplexing in Python,"Fiber-optic transmission based on nonlinear frequency division multiplexing (NFDM) has received much attention in recent years. We introduce NFDMLab, an open source software package for simulating NFDM transmissions written in the Python language.",NFDMLab - fiber-optic transmission - open source software package - NFDM transmissions - Python language - nonlinear frequency division multiplexing,"Brehler, M.(1); Mahnke, C.(1); Chimmalgi, S.(2); Wahls, S.(2)",2019.0,Conference,2019 Optical Fiber Communications Conference and Exhibition (OFC). Proceedings,,"(1) High Freq. Technol., Tech. Univ. Dortmund, Dortmund, Germany; (2) Delft Center for Syst. & Control, Tech. Univ. Delft, Delft, Netherlands",IEEE,English,,
Inspec,Design an MVC Model using Python for Flask Framework Development,"The Model-View-Controller (MVC) framework has become the standard in modern software development, with the model layer, display layer, and controller layer making it easier and faster. The Flask is a framework that uses Python language with easy to understand code writing. But the Flask framework still doesn't use the MVC method, so files and codes are not regular. The purpose of this study was to design a MVC for a framework that uses the Python programming language. This system has a generator that can make MVC folder structure easily and quickly, this system is also equipped with the Bootstrap framework, and this system is open source. The results showed that the presence of MVC on the flask framework could make users easier in creating new projects and have faster fully load time.",MVC Model - Flask framework development - Model-View-Controller framework - modern software development - model layer - display layer - controller layer - Python language - code writing - MVC method - Python programming language - MVC folder structure - Bootstrap framework,"Mufid, M.R.(1); Basofi, A.(1); Al Rasyid, M.U.H.(1); Rochimansyah, I.F.(2); Rokhim, A.(2)",2019.0,Conference,2019 International Electronics Symposium (IES). Proceedings,10.1109/ELECSYM.2019.8901656,"(1) Politek. Elektronika Negeri Surabaya, Surabaya, Indonesia; (2) Akademi Komunitas Negeri Lamongan, Lamongan, Indonesia",IEEE,English,,
Inspec,differint: A Python Package for Numerical Fractional Calculus [arXiv],"Fractional calculus has become widely studied and applied to physical problems in recent years [2,3]. As a result, many methods for the numerical computation of fractional derivatives and integrals have been defined. However, these algorithms are often programmed in an ad hoc manner, requiring researchers to implement and debug their own code. This work introduces the differint software package, which offers a single repository for multiple numerical algorithms for the computation of fractional derivatives and integrals. This package is coded in the open-source Python programming language [1]. The Grunwald-Letnikov, improved Grunwald-Letnikov, and Riemann-Liouville algorithms from the fractional calculus are included in this package. The algorithms presented are computed from their descriptions found in [2]. This work concludes with suggestions for the application of the differint software package.",Python package - numerical fractional calculus - physical problems - numerical computation - fractional derivatives - software package - multiple numerical algorithms - open-source Python - Riemann-Liouville algorithms - improved Grunwald-Letnikov algorithms,"Adams, M.(1)",2019.0,arXiv,arXiv,,"(1) Dept. of Math. & Stat., Univ. of Calgary, Calgary, AB, Canada",arXiv,English,,
Inspec,OpenML-Python: an extensible Python API for OpenML [arXiv],"OpenML is an online platform for open science collaboration in machine learning, used to share datasets and results of machine learning experiments. In this paper we introduce \emph{OpenML-Python}, a client API for Python, opening up the OpenML platform for a wide range of Python-based tools. It provides easy access to all datasets, tasks and experiments on OpenML from within Python. It also provides functionality to conduct machine learning experiments, upload the results to OpenML, and reproduce results which are stored on OpenML. Furthermore, it comes with a scikit-learn plugin and a plugin mechanism to easily integrate other machine learning libraries written in Python into the OpenML ecosystem. Source code and documentation is available at https://github.com/openml/openml-python/.",extensible Python API - open science collaboration - machine learning experiments - OpenML platform - Python-based tools - scikit-learn plugin - OpenML ecosystem - OpenML-Python - online platform - plugin mechanism,"Feurer, M.(1); van Rijn, J.N.(2); Kadra, A.(1); Gijsbers, P.(3); Mallik, N.(1); Ravi, S.(3); Muumlller, A.(4); Vanschoren, J.(3); Hutter, F.(5)",2019.0,arXiv,arXiv,,"(1) Univ. of Freiburg, Freiburg, Germany; (2) Leiden Univ., Leiden, Netherlands; (3) Eindhoven Univ. of Technol., Eindhoven, Netherlands; (4) Columbia Univ., Columbia, NY, United States; (5) Freiburg & Bosch Center for Artificial Intell., Univ. of Freiburg, Freiburg, Germany",arXiv,English,,
Inspec,PyISOLVER-A Fast Python OOP Implementation of LRDFIT Model,"An inductance-resistance (L-R) 2-D axisymmetric circuit model of a tokamak is constrained to fit combinations of diagnostic data. This model is widely used not only to reconstruct magnetohydrodynamics (MHD) equilibrium but also to predict time-dependent vacuum field evolution as part of TRANSP. However, the computational model was procedurally programmed with a commercial software platform which limits the reuse and distribution of this computational model and requires extra expense on the commercial software license. In this article, the original procedural program was ported from its commercial platform to an open-source Python platform and refactored into the object-oriented programming (OOP) style so that computational models could run independently on computers without calling any commercial software libraries. The new classes of the tokamak model contain the most frequently used methods and data structures from equilibrium fitting (EFIT) and LRDFIT. Currently, the model and diagnostic data are derived from national spherical torus experiment (NSTX)-U, however, a customized model could be easily developed for another tokamak. With Numba just-in-time (JIT) compiler, the speed of Python code is accelerated. The original deployment would take ~56 s to converge on a commercial software platform. The open-source Python version would take ~19 s with the same hardware to fit the same set of diagnostic data. Enabled by the OOP design pattern, the numerical algorithm could be further optimized without modification of any other part of code.",LRDFIT model - diagnostic data - magnetohydrodynamics equilibrium - time-dependent vacuum field evolution - commercial software license - procedural program - open-source Python platform - object-oriented programming style - software libraries - tokamak model - PyISOLVER - Python OOP Implementation - inductance-resistance 2-D axisymmetric circuit model - data structures - equilibrium fitting - Numba just-in-time compiler - computational plasma physics,"Fanghao Yang(1); Menard, J.E.(1)",2020.0,Journal,IEEE Transactions on Plasma Science,10.1109/TPS.2019.2958001,"(1) Princeton Plasma Phys. Lab., Princeton, NJ, United States",IEEE,English,0093-3813,
Inspec,The Simulation of Queuing Model for Bangkok Rapid Transit Train Ticket System Using Python,"This paper proposes the simulation model for ticket system of Bangkok rapid transit train. The proposed analysis model is applied by using queuing theory to analyze main queuing delay problem rapid transit train ticket machines. This analysis model has been developed by using python programming language to create software tool for analyzing the existing ticket system comparing with the desire variable condition or redesign the ticket system. Since, proposed software tool use for analyze the effect of existing ticket system by modification to visualize the queuing, delay time, waiting time and etc. The software tool with the simulation model can visualize the 2D animation results and graph for analyzation. The proposed analysis model could be used to any rapid transit train ticket system for impact analysis own existing ticket system.",Python programming language - software tool - queuing delay problem rapid transit train ticket machines - 2D animation visualization - graph - Bangkok rapid transit train ticket system,"Poomrittigul, S.(1); Koomsubsiri, A.(1); Sasithong, P.(2); Deenuch, D.(2); Wuttisittikulkij, L.(2)",2019.0,Conference,"2019 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)",10.1109/ITC-CSCC.2019.8793309,"(1) Dept. of Software Eng. & Inf. Syst., Pathumwan Inst. of Technol., Bangkok, Thailand; (2) Smart Wireless Commun. Ecosyst. Res. Group, Bangkok, Thailand",IEEE,English,,
Inspec,SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python [arXiv],"SciPy is an open source scientific computing library for the Python programming language. SciPy 1.0 was released in late 2017, about 16 years after the original version 0.1 release. SciPy has become a de facto standard for leveraging scientific algorithms in the Python programming language, with more than 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories, and millions of downloads per year. This includes usage of SciPy in almost half of all machine learning projects on GitHub, and usage by high profile projects including LIGO gravitational wave analysis and creation of the first-ever image of a black hole (M87). The library includes functionality spanning clustering, Fourier transforms, integration, interpolation, file I/O, linear algebra, image processing, orthogonal distance regression, minimization algorithms, signal processing, sparse matrix handling, computational geometry, and statistics. In this work, we provide an overview of the capabilities and development practices of the SciPy library and highlight some recent technical developments.",SciPy 1.0 - unique code contributors - SciPy library - computational geometry - minimization algorithms - leveraging scientific algorithms - Python programming language - open source scientific computing library,"Virtanen, P.(1); Gommers, R.(2); Oliphant, T.E.(3); Haberland, M.(5); Reddy, T.(6); Cournapeau, D.; Burovski, E.(7); Peterson, P.; Weckesser, W.; Bright, J.; van der Walt, S.J.(8); Brett, M.(9); Wilson, J.; Millman, K.J.(8); Mayorov, N.(10); Nelson, A.R.J.(11); Jones, E.(4); Kern, R.(4); Larson, E.(12); Carey, C.(13); Polat, I.; Yu Feng(14); Moore, E.W.(15); VanderPlas, J.(16); Laxalde, D.; Perktold, J.; Cimrman, R.(17); Henriksen, I.(18); Quintero, E.A.; Harris, C.R.; Archibald, A.M.(19); Ribeiro, A.H.(20); Pedregosa, F.(21); van Mulbregt, P.(22)",2019.0,arXiv,arXiv,,"(1) Univ. of Jyvaskyla, Jyvaskyla, Finland; (2) Quansight LLC, Austin, TX, United States; (3) Ultrasound Imaging, Mayo Clinic, Rochester, MN, United States; (4) Enthought, Inc., Austin, TX, United States; (5) BioResource & Agric. Eng. Dept., California Polytech. State Univ., San Luis Obispo, CA, United States; (6) Los Alamos Nat. Lab., Los Alamos, NM, United States; (7) Higher Sch. of Econ., Moscow, Russia; (8) Berkeley Inst. for Data Sci., Univ. of California, Berkeley, Berkeley, CA, United States; (9) Sch. of Psychol., Univ. of Birmingham, Birmingham, United Kingdom; (10) Skolkovo Innovation Center, WayRay LL, Moscow, Russia; (11) Australian Nucl. Sci. & Technol. Organ., Kirrawee, NSW, Australia; (12) Inst. for Learning & Brain Sci., Univ. of Washington, Seattle, WA, United States; (13) Coll. of Inf. & Comput. Sci., Univ. of Massachusetts Amherst, Amherst, MA, United States; (14) Berkeley Center for Cosmol. Phys., Univ. of California, Berkeley, Berkeley, CA, United States; (15) Bruker Biospin Corp., Billerica, MA, United States; (16) Univ. of Washington, Seattle, WA, United States; (17) New Technol. - Res. Centre, Univ. of West Bohemia, Plzentilde, Czech Republic; (18) Oden Inst. for Comput. Eng. & Sci., Univ. of Texas at Austin, Austin, TX, United States; (19) Anton Pannekoek Inst., Amsterdam, Netherlands; (20) Grad. Program in Electr. Eng., Univ. Fed. de Minas Gerais, Belo Horizonte, Brazil; (21) Google LLC, Montreal, QC, Canada; (22) Google LLC, Cambridge, MA, United States",arXiv,English,,
Inspec,"A Comparative Study on the Effect of Multiple Inheritance Mechanism in Java, C++, and Python on Complexity and Reusability of Code","Two of the fundamental uses of generalization in object-oriented software development are the reusability of code and better structuring of the description of objects. Multiple inheritance is one of the important features of object-oriented methodologies which enables developers to combine concepts and increase the reusability of the resulting software. However, multiple inheritance is implemented differently in commonly used programming languages. In this paper, we use Chidamber and Kemerer (CK) metrics to study the complexity and reusability of multiple inheritance as implemented in Python, Java, and C++. The analysis of results suggests that out of the three languages investigated Python and C++ offer better reusability of software when using multiple inheritance, whereas Java has major deficiencies when implementing multiple inheritance resulting in poor structure of objects.",Java - Python - object-oriented software development - multiple inheritance mechanism - C++ - code reusability - code complexity - programming languages - Chidamber and Kemerer metrics - CK metrics,"Albalooshi, F.(1); Mahmood, A.(1)",2017.0,Journal,International Journal of Advanced Computer Science and Applications,,"(1) Dept. of Comput. Sci., Univ. of Bahrain, Bahrain, Bahrain",SAI - The Science and Information Organization,English,2156-5570,
Inspec,PySINDy: A Python package for the Sparse Identification of Nonlinear Dynamics from Data [arXiv],"PySINDy is a Python package for the discovery of governing dynamical systems models from data. In particular, PySINDy provides tools for applying the sparse identification of nonlinear dynamics (SINDy) (Brunton et al. 2016) approach to model discovery. In this work we provide a brief description of the mathematical underpinnings of SINDy, an overview and demonstration of the features implemented in PySINDy (with code examples), practical advice for users, and a list of potential extensions to PySINDy. Software is available at https://github.com/dynamicslab/pysindy.",dynamical systems models - sparse identification - nonlinear dynamics - Python package - PySINDy,"de Silva, B.M.(1); Champion, K.(1); Quade, M.(2); Loiseau, J.-C.(3); Kutz, J.N.(1); Brunton, S.L.(4)",2020.0,arXiv,arXiv,,"(1) Dept. of Appl. Math., Univ. of Washington, Seattle, WA, United States; (2) Ambrosys GmbH, Potsdam, Germany; (3) ParisTech, Paris, France; (4) Dept. of Mech. Eng., Univ. of Washington, Seattle, WA, United States",arXiv,English,,
Inspec,Executability of Python snippets in Stack Overflow [arXiv],"Online resources today contain an abundant amount of code snippets for documentation, collaboration, learning, and problem-solving purposes. Their executability in a ""plug and play"" manner enables us to confirm their quality and use them directly in projects. But, in practice that is often not the case due to several requirements violations or incompleteness. However, it is a difficult task to investigate the executability on a large scale due to different possible errors during the execution. We have developed a scalable framework to investigate this for SOTorrent Python snippets. We found that with minor adjustments, 27.92% of snippets are executable. The executability has not changed significantly over time. The code snippets referenced in GitHub are more likely to be directly executable. But executability does not affect the chances of the answer to be selected as the accepted answer significantly. These properties help us understand and improve the interaction of users with online resources that include code snippets.",executability - code snippets - problem-solving purposes - SOTorrent Python snippets - plug and play - Stack Overflow - GitHub,"Hossain, M.M.(1); Mahmoudi, N.(1); Changyuan Lin(1); Khazaei, H.(1); Hindle, A.(2)",2019.0,arXiv,arXiv,,"(1) Dept. of Electr. & Comput. Eng., Univ. of Alberta, Edmonton, AB, Canada; (2) Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada",arXiv,English,,
Inspec,Stanza: a Python Natural Language Processing Toolkit for Many Human Languages [arXiv],"We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Stanza on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Stanza includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https://stanfordnlp.github.io/stanza.",source code - relation extraction - coreference resolution - neural architecture - multilingual corpora - named entity recognition - dependency parsing - lemmatization - tokenization - text analysis - Stanza features - Java Stanford CoreNLP software - native Python interface - universal dependencies treebanks - morphological feature tagging - multiword token expansion - language-agnostic fully neural pipeline - human languages - open-source Python natural language processing toolkit,"Peng Qi(1); Yuhao Zhang(1); Yuhui Zhang(1); Bolton, J.(1); Manning, C.D.(1)",2020.0,arXiv,arXiv,,"(1) Stanford Univ., Stanford, CA, United States",arXiv,English,,
Inspec,PyLops -- A Linear-Operator Python Library for large scale optimization [arXiv],"Linear operators and optimisation are at the core of many algorithms used in signal and image processing, remote sensing, and inverse problems. For small to medium-scale problems, existing software packages (e.g., MATLAB, Python numpy and scipy) allow for explicitly building dense (or sparse) matrices and performing algebraic operations (e.g., computation of matrix-vector products and manipulation of matrices) with syntax that closely represents their corresponding analytical forms. However, many real application, large-scale operators do not lend themselves to explicit matrix representations, usually forcing practitioners to forego of the convenient linear-algebra syntax available for their explicit-matrix counterparts. PyLops is an open-source Python library providing a flexible and scalable framework for the creation and combination of so-called linear operators, class-based entities that represent matrices and inherit their associated syntax convenience, but do not rely on the creation of explicit matrices. We show that PyLops operators can dramatically reduce the memory load and CPU computations compared to explicit-matrix calculations, while still allowing users to seamlessly use their existing knowledge of compact matrix-based syntax that scales to any problem size because no explicit matrices are required.",linear-operator Python library - optimisation - image processing - remote sensing - inverse problems - software packages - matrix-vector products - matrix representations - open-source Python library - PyLops operators - linear-algebra syntax - signal processing,"Ravasi, M.(1); Vasconcelos, I.(2)",2019.0,arXiv,arXiv,,"(1) Equinor ASA, Bergen, Norway; (2) Dept. of Earth Sci., Utrecht Univ., Utrecht, Netherlands",arXiv,English,,
Inspec,Process mining for Python (PM4Py): bridging the gap between process- and data science [arXiv],"Process mining, i.e., a sub-field of data science focusing on the analysis of event data generated during the execution of (business) processes, has seen a tremendous change over the past two decades. Starting off in the early 2000's, with limited to no tool support, nowadays, several software tools, i.e., both open-source, e.g., ProM and Apromore, and commercial, e.g., Disco, Celonis, ProcessGold, etc., exist. The commercial process mining tools provide limited support for implementing custom algorithms. Moreover, both commercial and open-source process mining tools are often only accessible through a graphical user interface, which hampers their usage in large-scale experimental settings. Initiatives such as RapidProM provide process mining support in the scientific workflow-based data science suite RapidMiner. However, these offer limited to no support for algorithmic customization. In the light of the aforementioned, in this paper, we present a novel process mining library, i.e. Process Mining for Python (PM4Py) that aims to bridge this gap, providing integration with state-of-the-art data science libraries, e.g., pandas, numpy, scipy and scikit-learn. We provide a global overview of the architecture and functionality of PM4Py, accompanied by some representative examples of its usage.",tool support - software tools - commercial process mining tools - open-source process mining tools - process mining support - scientific workflow-based data science suite RapidMiner - process mining library - PM4Py - event data analysis - graphical user interface - process mining for Python - data science libraries,"Berti, A.(1); van Zelst, S.J.(1); van der Aalst, W.(1)",2019.0,arXiv,arXiv,,"(1) Process & Data Sci. Group, RWTH Aachen Univ., Aachen, Germany",arXiv,English,,
Inspec,Learning polar codes using python program with graphical user interface,"Polar codes are an emerging class of powerful capacity-achieving channel codes for binary-input memoryless channels. Very recently, polar codes have been adopted as an official channel coding technology for control channels of 5G communications systems. In this paper, we aim to develop a self-learning software tool to help electrical engineering students understand polar codes in the most effective manner. The software tool developed in Python provides a graphical display for detailed and step-by-step encoding and decoding processes for polar codes of various different block lengths. We have applied this tool in our lecture class of the fourth year undergraduate students. It is found that students are able to gain insight the basic concept of polar codes quickly through the interactive and friendly graphical user interface.",capacity-achieving channel codes - polar code learning - Python program - graphical user interface - channel coding technology - control channels - 5G communications systems - self-learning software tool - electrical engineering students - fourth year undergraduate students - binary-input memoryless channels,"Aung, H.L.(1); Maung, T.Z.B.(1); Sasithong, P.(1); Sreprasurt, T.(1); Wijayasekara, S.(1); Pengnoo, M.(1); Wuttisittikulkij, L.(1); Phakphisut, W.(2); Phongphanphanee, C.(3); Bajpai, A.(4); Saadi, M.(5); Vanichchanunt, P.(6)",2019.0,Conference,"2019 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)",10.1109/ITC-CSCC.2019.8793295,"(1) Smart Wireless Commun. Ecosyst. Res. Group, Chulalongkorn Univ., Bangkok, Thailand; (2) King Mongkut's Inst. of Technol. Ladkrabang, Bangkok, Thailand; (3) Dept. of Comput. Eng., Chulalongkorn Univ., Bangkok, Thailand; (4) Dept. of Electron. & Commun., Indore Inst. of Sci. & Technol., Indore, India; (5) Dept. of Electr. Eng., Univ. of Central Punjab Lahore, Lahore, Pakistan; (6) Dept. of Electr. & Comput. Eng., King Mongkut's Univ. of Technol. North, Bangkok, Thailand",IEEE,English,,
Inspec,Python-Based Data Analysis Tool for a 6-DoF Industrial Robot,"A newly developed tool for analysing and visualizing data based on python. The main aim of this tool is saving the data analysis time by automating the data analysis process and creating a Graphical User Interface (GUI) to facilitate the usage of this tool regardless how much they experience programming with Python. This paper describes the architecture of the developed software tool and provides a variety of examples to show the developed tool's advanced features and functionalities. Moreover, in this paper, an industrial problem related to data analysis is discussed, and then a solution of this problem is presented. This tool is developed using open source libraries (Pandas, Matplotlib, Tkinter, and SciPy) to manage multi data files at once using one tool, as well as visualizing and storing these data in one file in a clean and organized way.",6-DoF industrial robot - data analysis time - data analysis process - Graphical User Interface - Python - data visualization - software development tool - data analysis tool - open source libraries - Pandas - Matplotlib - Tkinter - SciPy - GUI,"Alsabbagh, A.(1); Nasser, A.N.(1); Husi, G.(1)",2019.0,Conference,IOP Conference Series: Materials Science and Engineering,10.1088/1757-899X/568/1/012098,"(1) Dept. of Mechatron., Univ. of Debrecen, Debrecen, Hungary",IOP Publishing,English,1757-8981,
Inspec,Pymc-learn: Practical Probabilistic Machine Learning in Python [arXiv],"Pymc-learn is a Python package providing a variety of state-of-the-art probabilistic models for supervised and unsupervised machine learning. It is inspired by scikit-learn and focuses on bringing probabilistic machine learning to non-specialists. It uses a general-purpose high-level language that mimics scikit-learn. Emphasis is put on ease of use, productivity, flexibility, performance, documentation, and an API consistent with scikit-learn. It depends on scikit-learn and pymc3 and is distributed under the new BSD-3 license, encouraging its use in both academia and industry. Source code, binaries, and documentation are available on http://github.com/pymc-learn/pymc-learn.",practical probabilistic machine learning - Python package - supervised machine learning - unsupervised machine learning - scikit-learn - general-purpose high-level language - pymc-learn - BSD-3 license,"Emaasit, D.(1)",2018.0,arXiv,arXiv,,"(1) Data Sci. Team, Haystax Technol., McLean, VA, United States",arXiv,English,,
Inspec,metric-learn: Metric Learning Algorithms in Python [arXiv],"metric-learn is an open source Python package implementing supervised and weakly-supervised distance metric learning algorithms. As part of scikit-learn-contrib, it provides a unified interface compatible with scikit-learn which allows to easily perform cross-validation, model selection, and pipelining with other machine learning estimators. metric-learn is thoroughly tested and available on PyPi under the MIT licence.",machine learning estimators - open source Python package - scikit-learn-contrib - metric-learn - distance metric learning algorithms - model selection - pipelining - PyPi - MIT licence,"de Vazelhes, W.(1); Carey, C.J.(2); Yuan Tang(3); Vauquier, N.(1); Bellet, A.(1)",2019.0,arXiv,arXiv,,"(1) INRIA, France; (2) Google LLC, Mountain View, CA, United States; (3) Ant Financial, United States",arXiv,English,,
Inspec,Recommended Practices for Python Pedagogy in Graduate Data Science Courses,"This Research to Practice Full Paper discusses experiences and recommendations highlighting best practices for teaching Python1 in data science at higher education institutions. Python has become the language of choice for teaching data science at both graduate and undergraduate programs. From data preprocessing, pattern extraction, predictive modeling, to visualization, the language has important libraries and tools to achieve this seamlessly. In this paper, the pedagogical approaches and learning objectives achieved by a cohort of graduate students specific to using Python at all stages of the KDD (Knowledge Discovery in Databases) life cycle are highlighted. The need to do this is motivated by describing an undergraduate data mining course taught at a STEM program in Computer Science. Teaching and research experiences to build projects are also elaborated across these groups. The paper then proposes recommended practices for teaching Python at the graduate level in similar data science programs.1Python Software Foundation, [Online]. Available: https://www.python.org/",computer science - Python pedagogy - higher education institutions - undergraduate programs - pattern extraction - predictive modeling - learning objectives - graduate students - undergraduate data mining course - STEM program - <sup>1</sup>Python software foundation - data science programs - Python teaching - graduate data science courses - data preprocessing,"Yadav, N.(1); DeBello, J.E.(1)",2019.0,Conference,2019 IEEE Frontiers in Education Conference (FIE),10.1109/FIE43999.2019.9028449,"(1) Div. of Comput. Sci., Math. & Sci., St. John's Univ., Queens, NY, United States",IEEE,English,,
Inspec,Sonar: Writing Testbenches through Python,"Design verification is an important though time-consumingaspect of hardware design. A good testbench should supportperforming functional coverage of a design by making it easy to implement tests and determine which tests are being performed. However, for complex designs, creating and main-taining effective testbenches can take increasing amounts of time away from actual design. A further complication is there may be two development flows: conventional hardware written in a hardware description language (HDL) such as Verilog orVHDL and high-level synthesis (HLS). In the HLS approach, the hardware is specified in a higher-level language (HLL) and then converted to an HDL through HLS tools. In this flow, testbenches for the design are written in the same HLLand cosimulation is used to verify the generated HDL. Due totool restrictions, cosimulation may not always work. In VivadoHLS [1] for example, the design must contain control signals to define when to start and stop the module or the initiation interval for new data must be one cycle. Without cosimulation, the user must write an HDL testbench manually in addition to a testbench in the HLL for preliminary verification. To simplify writing testbenches, we present Sonar: an open-source Python library to write cross-language testbenches. From a common source script, Sonar can generate testbenches written in SystemVerilog (SV) and C++. These files can then be imported into standard simulation tools such as ModelSim[2] or Vivado HLS and run. The use of Python makes it easy to extend Sonar with higher layers of abstraction for testbenches and integrate it with other software platforms.Sonar is available at https://github.com/UofT-HPRC/sonar.",Sonar - design verification - hardware design - conventional hardware - hardware description language - high-level synthesis - higher-level language - HDL testbench - cross-language testbenches - VivadoHLS - HLL - taining effective testbenches - open-source Python library - SystemVerilog - C++,"Sharma, V.(1); Tarafdar, N.(1); Chow, P.(1)",2019.0,Conference,2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),10.1109/FCCM.2019.00052,"(1) Dept. of Electr. & Comput. Eng., Univ. of Toronto, Toronto, ON, Canada",IEEE Computer Society,English,,
Inspec,Software development and application of dynamic optimization in blasting parameters based on Python,"This paper based on the language programming technology of Python develops a software of blasting parameters, which can calculate explosive quantity, attenuation coefficient and vibration velocity. In order to test the function of the software, it makes a careful analysis of the data taken from monitoring data on Wansongling Tunnel Engineering in Hangzhou. The test result is very good.",software development - software application - dynamic optimization - Python - language programming - blasting parameter software - vibration velocity - explosive quantity - attenuation coefficient - Wansongling Tunnel Engineering - Hangzhou,Chen Qiao-ben(1); Luo Yi-xi(1),2016.0,Journal,Journal of Qingdao University of Technology,,"(1) Forces 92303, PLA, Qingdao, China",Editorial Office of Journal of Qingdao University of Technology,Chinese,1673-4602,
Inspec,Workflow for Data Analysis in Experimental and Computational Systems Biology: Using Python as `Glue',"Bottom-up systems biology entails the construction of kinetic models of cellular pathways by collecting kinetic information on the pathway components (e.g., enzymes) and collating this into a kinetic model, based for example on ordinary differential equations. This requires integration and data transfer between a variety of tools, ranging from data acquisition in kinetics experiments, to fitting and parameter estimation, to model construction, evaluation and validation. Here, we present a workflow that uses the Python programming language, specifically the modules from the SciPy stack, to facilitate this task. Starting from raw kinetics data, acquired either from spectrophotometric assays with microtitre plates or from Nuclear Magnetic Resonance (NMR) spectroscopy time-courses, we demonstrate the fitting and construction of a kinetic model using scientific Python tools. The analysis takes place in a Jupyter notebook, which keeps all information related to a particular experiment together in one place and thus serves as an e-labbook, enhancing reproducibility and traceability. The Python programming language serves as an ideal foundation for this framework because it is powerful yet relatively easy to learn for the non-programmer, has a large library of scientific routines and active user community, is open-source and extensible, and many computational systems biology software tools are written in Python or have a Python Application Programming Interface (API). Our workflow thus enables investigators to focus on the scientific problem at hand rather than worrying about data integration between disparate platforms.",data analysis - kinetic model - cellular pathways - kinetic information - pathway components - ordinary differential equations - data transfer - data acquisition - kinetics experiments - fitting parameter estimation - Python programming language - raw kinetics data - scientific Python tools - computational systems biology software tools - Python application programming interface - data integration - nuclear magnetic resonance spectroscopy time-courses,"Badenhorst, M.(1); Barry, C.J.(1); Swanepoel, C.J.(1); van Staden, C.T.(1); Wissing, J.(1); Rohwer, J.M.(1)",2019.0,Journal,Processes,10.3390/pr7070460,"(1) Dept. of Biochem., Stellenbosch Univ., Stellenbosch, South Africa",MDPI,English,2227-9717,
Inspec,Validating pyBSM: a Python package for modeling imaging systems,"The Python Based Sensor Model (pyBSM) provides open source functions for modeling electro-optical and infrared imaging systems. In this paper, we validate pyBSM predictions against laboratory measurements. Compared quantities include modulation transfer function, photoelectron count, and signal-to-noise ratio. Experiments are explained and code is provided with the details required to recreate this study for additional camera and lens combinations.",Python package - Python Based Sensor Model - open source functions - pyBSM predictions - laboratory measurements - electrooptical system modeling - infrared imaging systems modeling,"LeMaster, D.A.(1); Plummer, P.J.(1); Howard, M.D.(1); Rucci, M.A.(1)",2018.0,Conference,Proceedings of the SPIE,10.1117/12.2305228,"(1) Air Force Res. Lab., Wright-Patterson AFB, OH, United States",SPIE,English,0277-786X,
Inspec,An empirical analysis of vulnerabilities in python packages for web applications,"This paper examines software vulnerabilities in common Python packages used particularly for web development. The empirical dataset is based on the PyPI package repository and the so-called Safety DB used to track vulnerabilities in selected packages within the repository. The methodological approach builds on a release-based time series analysis of the conditional probabilities for the releases of the packages to be vulnerable. According to the results, many of the Python vulnerabilities observed seem to be only modestly severe; input validation and cross-site scripting have been the most typical vulnerabilities. In terms of the time series analysis based on the release histories, only the recent past is observed to be relevant for statistical predictions; the classical Markov property holds.",web applications - software vulnerabilities - web development - PyPI package repository - Safety DB - release-based time series analysis - conditional probabilities - Python vulnerabilities - cross-site scripting - Python packages - Markov property,"Ruohonen, J.(1)",2018.0,Conference,2018 9th International Workshop on Empirical Software Engineering in Practice (IWESEP),10.1109/IWESEP.2018.00013,"(1) Univ. of Turku, Turku, Finland",IEEE Computer Society,English,,
Inspec,A simulation tool for vertical transportation systems using python,"This paper presents a software development tool which is capable of simulating the vertical transportation systems within buildings using elevators. The simulation tool is composed of a passenger arrival model for a single or group of elevators, their control system, and a graphical user interface (GUI). The developed GUI can display statistical information of the passengers traffic pattern and also the animation of elevator cars with the number of passengers inside. The current version allows both individual and batch Poisson arrival processes which could represent up-peak traffic in the morning and after lunch of office buildings respectively. The motion of elevator cars has been precisely modeled with real parameters of velocity, acceleration, distance, and jerk. However, only the basic nearest car algorithm is implemented for elevator group control systems. We believe, the developed simulator not only has its utility for educational purpose but also can serve as a software platform for future research on more advanced elevator group control systems.",up-peak traffic - basic nearest car algorithm - simulation tool - vertical transportation systems - software development tool - passenger arrival model - graphical user interface - statistical information - passengers traffic pattern - GUI - python - batch Poisson arrival processes - elevator motion - elevator group control systems - software platform - elevator cars animation - individual Poisson arrival processes - educational purpose,"Chaosangket, N.(1); Sasithong, P.(1); Wijayasekara, S.K.(1); Asdornwised, W.(1); Wuttisittikulkij, L.(1); Vanichchanunt, P.(2); Saadi, M.(3)",2018.0,Conference,2018 5th International Conference on Business and Industrial Research (ICBIR). Proceedings,10.1109/ICBIR.2018.8391205,"(1) Fac. of Electr. Eng., Chulalongkorn Univ., Bangkok, Thailand; (2) Fac. of Eng., King Mongkut's Univ. of Technol., Bangkok, Thailand; (3) Dept. of Electr. Eng., Univ. of Central Punjab, Lahore, Pakistan",IEEE,English,,
Inspec,Turbulucid: a python package for post-processing of fluid flow simulations [arXiv],"A Python package for post-processing of plane two-dimensional data from computational fluid dynamics simulations is presented. The package, called turbulucid, provides means for scripted, reproducible analysis of large simulation campaigns and includes routines for both data extraction and visualization. For the former, the Visualization Toolkit (VTK) is used, allowing for post-processing of simulations performed on unstructured meshes. For visualization, several matplotlib-based functions for creating highly customizable, publication-quality plots are provided. To demonstrate turbulucid's functionality it is here applied to post-processing a simulation of a flow over a backward-facing step. The implementation and architecture of the package are also discussed, as well as its reuse potential.",python package - fluid flow simulations - computational fluid dynamics simulations - data extraction - visualization toolkit - turbulucid - VTK - matplotlib-based functions,"Mukha, T.",2018.0,arXiv,arXiv,,,arXiv,English,,
Inspec,"Some remarks on the performance of Matlab, Python and Octave in simulating dynamical systems [arXiv]","Matlab has been considered as a leader computational platform for many engineering fields. Well documented and reliable, Matlab presents as a great advantage its ability to increase the user productivity. However, Python and Octave are among some of the languages that have challenged Matlab. Octave and Python are well known examples of high-level scripting languages, with a great advantage of being open source software. The novelty of this paper is devoted to offer a comparison among these tree languages in the simulation of dynamical systems. We have applied the lower bound error to estimate the error of simulation. The comparison was performed with the chaotic systems Duffing-Ueda oscillator and the Chua's circuit, both identified with polynomial NARMAX. Octave presents the best reliable outcome. Nevertheless, Matlab needs the lowest time to undertake the same activity. Python has presented the worse result for the stop simulation criterion.",polynomial NARMAX - Duffing-Ueda oscillator - Chua's circuit - Matlab - chaotic systems - tree languages - open source software - high-level scripting languages - Python - dynamical system simulation - Octave,"Guedes, P.F.S.(1); Nepomuceno, E.G.(2)",2019.0,arXiv,arXiv,,"(1) Grad. Program in Electr. Eng., Univ. Fed. de Minas Gerais, Belo Horizonte, Brazil; (2) Dept. of Electr. Eng., Fed. Univ. of Sao Joao del-Rei, Sao Joao del-Rei, Brazil",arXiv,English,,
Inspec,"JAX, M.D.: end-to-end differentiable, hardware accelerated, molecular dynamics in pure python [arXiv]","A large fraction of computational science involves simulating the dynamics of particles that interact via pairwise or many-body interactions. These simulations, called Molecular Dynamics (MD), span a vast range of subjects from physics and materials science to biochemistry and drug discovery. Most MD software involves significant use of handwritten derivatives and code reuse across C++, FORTRAN, and CUDA. This is reminiscent of the state of machine learning before automatic differentiation became popular. In this work we bring the substantial advances in software that have taken place in machine learning to MD with JAX, M.D. (JAX MD). JAX MD is an end-to-end differentiable MD package written entirely in Python that can be just-in-time compiled to CPU, GPU, or TPU. JAX MD allows researchers to iterate extremely quickly and lets researchers easily incorporate machine learning models into their workflows. Finally, since all of the simulation code is written in Python, researchers can have unprecedented flexibility in setting up experiments without having to edit any low-level C++ or CUDA code. In addition to making existing workloads easier, JAX MD allows researchers to take derivatives through whole-simulations as well as seamlessly incorporate neural networks into simulations. This paper explores the architecture of JAX MD and its capabilities through several vignettes. Code is available at www.github.com/google/jax-md. We also provide an interactive Colab notebook that goes through all of the experiments discussed in the paper.",interactive Colab notebook - neural networks - low-level C++ - TPU - GPU - CPU - just-in-time compilation - Python - CUDA - FORTRAN - drug discovery - biochemistry - materials science - many-body interactions - computational science - hardware accelerated molecular dynamics - machine learning models - end-to-end differentiable MD package - JAX MD - MD software,"Schoenholz, S.S.; Cubuk, E.D.",2019.0,arXiv,arXiv,,,arXiv,English,,
Inspec,Python Programming Language for Power System Analysis Education and Research,"Due to its complexity and high dimensionality, power system analysis has always relied on numerical computation for real-time operation and planning. It is therefore of great importance that power systems engineering students have a robust understanding of computing and learn how to code. This paper discusses how Python can be an adequate programming language for education and research on power system analysis. This is accomplished by the analysis of a power transmission system from the perspectives of: (i) formation of bus admittance matrix, (ii) state estimation and (iii) fault studies. For each example, a simple vectorized Python 3 code, along with its basic concepts and functions highlighted, is presented. Additionally, the main results of interest are plotted to show the ability of Python in producing publication quality 2D and 3D plots.",Python programming language - power system analysis - power systems engineering students - adequate programming language - power transmission system - simple vectorized Python 3 code,"Fernandes, T.R.(1); Fernandes, L.R.(1); Ricciardi, T.R.(1); Ugarte, L.F.(1); de Almeida, M.C.(1)",2018.0,Conference,2018 IEEE PES Transmission & Distribution Conference and Exhibition - Latin America (T&D-LA),10.1109/TDC-LA.2018.8511780,"(1) Dept. of Syst. & Energy, Univ. of Campinas, Campinas, Brazil",IEEE,English,,
Inspec,High-performance Python for crystallographic computing,"The Python programming language, combined with the numerical computing library NumPy and the scientific computing library SciPy, has become the de facto standard for scientific computing in a variety of fields. This popularity is mainly due to the ease with which a Python program can be written and executed (easy syntax, dynamical typing, no compilation etc.), coupled with the existence of a large number of specialized third-party libraries that aim to lift all the limitations of the raw Python language. NumPy introduces vector programming, improving execution speeds, whereas SciPy brings a wealth of highly optimized and reliable scientific functions. There are cases, however, where vector programming alone is not sufficient to reach optimal performance. This issue is addressed with dedicated compilers that aim to translate Python code into native and statically typed code with support for the multi-core architectures of modern processors. In the present article it is shown how these approaches can be efficiently used to tackle different problems, with increasing complexity, that are relevant to crystallography: the 2D Laue function, scattering from a strained 2D crystal, scattering from 3D nanocrystals and, finally, diffraction from films and multilayers. For each case, detailed implementations and explanations of the functioning of the algorithms are provided. Different Python compilers (namely NumExpr, Numba, Pythran and Cython) are used to improve performance and are benchmarked against state-of-the-art NumPy implementations. All examples are also provided as commented and didactic Python (Jupyter) notebooks that can be used as starting points for crystallographers curious to enter the Python ecosystem or wishing to accelerate their existing codes.",native typed code - Python compilers - 3D nanocrystals - didactic Python - strained 2D crystal - 2D Laue function - multicore architectures - statically typed code - vector programming - third-party libraries - scientific computing library SciPy - numerical computing library NumPy - Python programming language - crystallographic computing - high-performance Python,"Boulle, A.(1); Kieffer, J.(2)",2019.0,Journal,Journal of Applied Crystallography,10.1107/S1600576719008471,"(1) Inst. de Rech. sur les Ceramiques, Centre Eur. de la Ceramique, Limoges, France; (2) Eur. Synchrotron Radiat. Facility, Grenoble, France",IUCr - International Union of Crystallography,English,1600-5767,
Inspec,A platform for human-chatbot interaction using python,"Over recent years, we've seen various customs for conversational agents. Chatbot is a conventional agent which is capable to communicate with operators by using natural languages. As numerous chatbot platforms already exist, there are still some problems in building data-driven system because a huge amount of data is required for its development. Thus, this paper describes various such agents which depend upon natural expressions implemented in Python. Moreover, to provide a better platform, web connectivity is also provided to evaluate the chatbot on a web-based platform which will help in analysing Human-Chatbot interactions.",conversational agents - natural languages - natural expressions - human chatbot interaction - chatbot platforms - Web based platform - data driven system - Python,"Kohli, B.(1); Choudhury, T.(2); Sharma, S.(1); Kumar, P.(1)",2018.0,Conference,2018 Second International Conference on Green Computing and Internet of Things (ICGCIoT). Proceedings,10.1109/ICGCIoT.2018.8753031,"(1) Amity Univ. Uttar Pradesh, Noida, India; (2) Univ. of Pet. & Energy Studies, Dehradun, India",IEEE,English,,
Inspec,The Development of Lexer and Parser as Parts of Compiler for GAMA32 Processor's Instruction-set using Python,"At this time, there are many products based on embedded systems, each of these products requires an embedded processor. This results in high demand for embedded processors. Therefore, we need a tool that is able to design an embedded processor completely with its software development tool. One of the embedded processor that is developed is GAMA32 processor. GAMA32 processor is a 32-bit embedded processor designed using System C Model. Its processor architecture is General Purpose Processor (GPP). GAMA32 processor has its own software development tool, but it has no compiler. The most common used compiler is open source compiler like GNU Compiler Collection (GCC) and Low Level Virtual Machine (LLVM). However, this two open source compilers are not compatible with GAMA32 processor because their complexity. In this research, a simple and flexible compiler will be developed, especially the Abstract Syntax Tree (AST) generator part using Python library rPLY and the AST's output is in the format of JavaScript Object Notation (JSON). For testing the result of AST generator, 5 statement patterns are used namely if, if-else, while, do-while, and for patterns with initial value, and data type declaration as well. The test results show that the correct AST can be produced from the patterns used.",open source compiler - embedded systems - software development tool - processor architecture - general purpose processor - GAMA32 processor instruction-set - System C Model - GPP - GNU compiler collection - GCC - low level virtual machine - LLVM - abstract syntax tree generator - AST - JavaScript Object Notation - JSON - Python library rPLY - parser - lexer,"Jordan, W.(1); Bejo, A.(1); Persada, A.G.(1)",2019.0,Conference,2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI),10.1109/ISRITI48646.2019.9034617,"(1) Dept. of Electr. & Inf. Eng., Univ. Gadjah Mada, Yogyakarta, Indonesia",IEEE,English,,
Inspec,Design of VMware vSphere Automatic Operation and Maintenance System Based on Python,"A kind of automatic operation and maintenance system established on the basis of facing to objective programming language Python is proposed by analyzing the requirements during the operation and maintenance of VMware vSphere. It can complete VMware vSphere automatic operation and maintenance work correctly by utilizing high-efficient, smart, simple and so on feature of Python language, combining with powerful function provided by extension modules such as pysphere, pyVmomi and MySQLdb, and with API support provided by VMware. The result indicates that this system has high-efficiency, universality and expansibility. Because of its simple code, clear layer and short period, it also has wide application prospect by using VMware vSphere automatic operation and maintenance system developed by Python.",objective programming language Python - VMware vSphere automatic operation - maintenance work - Python language - maintenance system,Fangtao Liu(1); Zhiyong Yang(1),2018.0,Conference,2018 International Conference on Advanced Mechatronic Systems (ICAMechS). Proceedings,10.1109/ICAMechS.2018.8506789,"(1) Dept. of Inf. Eng., Chongqing Vocational Inst. of Eng., Chongqing, China",IEEE,English,,
Inspec,jMetalPy: a python framework for multi-objective optimization with metaheuristics [arXiv],"This paper describes jMetalPy, an object-oriented Python-based framework for multi-objective optimization with metaheuristic techniques. Building upon our experiences with the well-known jMetal framework, we have developed a new multi-objective optimization software platform aiming not only at replicating the former one in a different programming language, but also at taking advantage of the full feature set of Python, including its facilities for fast prototyping and the large amount of available libraries for data processing, data analysis, data visualization, and high-performance computing. As a result, jMetalPy provides an environment for solving multi-objective optimization problems focused not only on traditional metaheuristics, but also on techniques supporting preference articulation and dynamic problems, along with a rich set of features related to the automatic generation of statistical data from the results generated, as well as the real-time and interactive visualization of the Pareto front approximations produced by the algorithms. jMetalPy offers additionally support for parallel computing in multicore and cluster systems. We include some use cases to explore the main features of jMetalPy and to illustrate how to work with it.",Pareto front approximations - high-performance computing - parallel computing - programming language - Python framework - statistical data - data visualization - data analysis - data processing - multiobjective optimization software platform - jMetal framework - metaheuristic techniques - object-oriented Python-based framework - jMetalPy,"Benitez-Hidalgo, A.(1); Nebro, A.J.(1); Garcia-Nieto, J.(1); Oregi, I.(2); Del Ser, J.(2)",2019.0,arXiv,arXiv,,"(1) Dept. de Lenguajes y Cienc. de la Comput., Univ. of Malaga, Malaga, Spain; (2) TECNALIA, Derio, Spain",arXiv,English,,
Inspec,Pykaldi: A Python Wrapper for Kaldi,"We present PyKaldi, a free and open-source Python wrapper for the widely-used Kaldi speech recognition toolkit. PyKaldi is more than a collection of Python bindings into Kaldi libraries. It is an extensible scripting layer that allows users to work with Kaldi and OpenFst types interactively in Python. It tightly integrates Kaldi vector and matrix types with NumPy arrays. We believe Py Kaldi will significantly improve the user experience and simplify the integration of Kaldi into Python workflows. PyKaldi comes with extensive documentation and tests. It is released under the Apache License v2.0 with support for both Python 2.7 and 3.5+.",extensible scripting layer - matrix types - Python workflows - Python 2 - free source Python wrapper - open-source Python wrapper - Kaldi speech recognition toolkit - Kaldi libraries - Pykaldi - OpenFst types - Kaldi vector - NumPy arrays - Apache License v2.0,"Dogan Can(1); Martinez, V.R.(1); Papadopoulos, P.(1); Narayanan, S.S.(1)",2018.0,Conference,"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",10.1109/ICASSP.2018.8462463,"(1) Signal Anal. & Interpretation Lab., Univ. of Southern California, Los Angeles, CA, United States",IEEE,English,,
Inspec,CASA 6: Modular Integration in Python [arXiv],"CASA, the Common Astronomy Software Applications, is the primary data processing software for the Atacama Large Millimeter/submillimeter Array (ALMA) and the Karl G. Jansky Very Large Array (VLA), and is often used also for other radio telescopes. CASA has always been distributed as a single, integrated application, including a Python interpreter and all the libraries, packages and modules. As part of the ongoing development of CASA 6, and the switch from Python 2 to 3, CASA will provide greater flexibility for users to integrate CASA into existing Python workflows by using a modular architecture and standard pip wheel installation. These proceedings of the 2019 Astronomical Data Analysis Software & Systems (ADASS) conference will give an overview of the CASA 6 project.",radio telescopes - Karl G. Jansky VLA - ALMA - Atacama Large Millimeter/submillimeter Array - Karl G. Jansky Very Large Array - data processing software - Common Astronomy Software Applications - modular integration - CASA 6 project - 2019 Astronomical Data Analysis Software & Systems conference - Python workflows - Python 2 - Python interpreter,"Raba, R.(1); Schiebel, D.(1); Emonts, B.(1); Garwood, R.(1); Pouzols, F.M.(2); Castro, S.(2); Garcia-Dabo, C.E.(2); Mehringer, D.(1); Suoranta, V.(1)",2019.0,arXiv,arXiv,,"(1) Nat. Radio Astron. Obs., Charlottesville, VA, United States; (2) Eur. Southern Obs., Garching, Germany",arXiv,English,,
Inspec,V2: Fast Detection of Configuration Drift in Python [arXiv],"Code snippets are prevalent, but are hard to reuse because they often lack an accompanying environment configuration. Most are not actively maintained, allowing for drift between the most recent possible configuration and the code snippet as the snippet becomes out-of-date over time. Recent work has identified the problem of validating and detecting out-of-date code snippets as the most important consideration for code reuse. However, determining if a snippet is correct, but simply out-of-date, is a non-trivial task. In the best case, breaking changes are well documented, allowing developers to manually determine when a code snippet contains an out-of-date API usage. In the worst case, determining if and when a breaking change was made requires an exhaustive search through previous dependency versions. We present V2, a strategy for determining if a code snippet is out-of-date by detecting discrete instances of configuration drift, where the snippet uses an API which has since undergone a breaking change. Each instance of configuration drift is classified by a failure encountered during validation and a configuration patch, consisting of dependency version changes, which fixes the underlying fault. V2 uses feedback-directed search to explore the possible configuration space for a code snippet, reducing the number of potential environment configurations that need to be validated. When run on a corpus of public Python snippets from prior research, V2 identifies 248 instances of configuration drift.",code reuse - code snippet - V2 - public Python snippets - out-of-date code snippets - configuration drift detection - out-of-date API usage,"Horton, E.(1); Parnin, C.(1)",2019.0,arXiv,arXiv,,"(1) North Carolina State Univ., Raleigh, NC, United States",arXiv,English,,
Inspec,"The Python/C API: Evolution, Usage Statistics, and Bug Patterns","Python has become one of the most popular programming languages in the era of data science and machine learning, especially for its diverse libraries and extension modules. Python front-end with C/C++ native implementation achieves both productivity and performance, almost becoming the standard structure for many mainstream software systems. However, feature discrepancies between two languages can pose many security hazards in the interface layer using the Python/C API. In this paper, we applied static analysis to reveal the evolution and usage statistics of the Python/C API, and provided a summary and classification of its 10 bug patterns with empirical bug instances from Pillow, a widely used Python imaging library. Our toolchain can be easily extended to access different types of syntactic bug-finding checkers. And our systematical taxonomy to classify bugs can guide the construction of more highly automated and high-precision bug-finding tools.",usage statistics - data science - programming language - machine learning - syntactic bug-finding checkers - bug-finding tools - Python/C API - interface layer security - static analysis - bug pattern classification - Pillow - Python imaging library,Mingzhe Hu(1); Yu Zhang(1),2020.0,Conference,"2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). Proceedings",10.1109/SANER48275.2020.9054835,"(1) Lab. for Intell. Networking & Knowledge Eng., Univ. of Sci. & Technol. of China, Hefei, China",IEEE,English,,
Inspec,AQUAMI: An open source Python package and GUI for the automatic quantitative analysis of morphologically complex multiphase materials,"Micrographs of materials contain microstructural information that is quantifiable in principle, but difficult to extract in practice. We present Automatic QUantitative Analysis of Microscopy Images (AQUAMI): a Python package which can automatically analyze micrographs and extract quantitative information to characterize microstructure features. This software package utilizes digital image analysis methods to perform many thousands of measurements on an image and reports information such as the mean feature dimensions, size distribution, and phase area fraction. Results are repeatable and can be directly compared between research groups. The results are robust against large changes in magnification, focus, illumination, and noise. We describe the working principle of the software and demonstrate it on micrographs of nanoporous and nanocomposite metals. [All rights reserved Elsevier].",AQUAMI - nanoporous metals - nanocomposite metals - digital image analysis methods - software package - Automatic Quantitative Analysis of Microscopy Images - morphologically complex multiphase materials - automatic quantitative analysis - GUI - open source Python package,"Stuckner, J.(1); Frei, K.(1); McCue, I.(2); Demkowicz, M.J.(2); Murayama, M.(1)",2017.0,Journal,Computational Materials Science,10.1016/j.commatsci.2017.08.012,"(1) Mater. Sci. & Eng. Dept., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, United States; (2) Mater. Sci. & Eng., Texas A&M Univ., College Station, TX, United States",Elsevier B.V.,English,0927-0256,
Inspec,emcee v3: a Python ensemble sampling toolkit for affine-invariant MCMC [arXiv],"emcee is a Python library implementing a class of affine-invariant ensemble samplers for Markov chain Monte Carlo (MCMC). This package has been widely applied to probabilistic modeling problems in astrophysics where it was originally published, with some applications in other fields. When it was first released in 2012, the interface implemented in emcee was fundamentally different from the MCMC libraries that were popular at the time, such as PyMC, because it was specifically designed to work with ""black box"" models instead of structured graphical models. This has been a popular interface for applications in astrophysics because it is often non-trivial to implement realistic physics within the modeling frameworks required by other libraries. Since emcee's release, other libraries have been developed with similar interfaces, such as dynesty (Speagle 2019). The version 3.0 release of emcee is the first major release of the library in about 6 years and it includes a full re-write of the computational backend, several commonly requested features, and a set of new ""move"" implementations. [Journal of Open Source Software, 2 4(43), 1864 (2019) doi:10.21105/joss.01864].",Python ensemble sampling toolkit - affine-invariant MCMC - emcee - Python library - affine-invariant ensemble samplers - Markov chain Monte Carlo - probabilistic modeling problems - astrophysics - MCMC libraries - black box models - structured graphical models - popular interface - modeling frameworks,"Foreman-Mackey, D.(1); Farr, W.M.(1); Sinha, M.(2); Archibald, A.M.(3); Hogg, D.W.(1); Sanders, J.S.(4); Zuntz, J.(5); Williams, P.K.G.(6); Nelson, A.R.J.(7); de Val-Borro, M.(8); Erhardt, T.(9); Pashchenko, I.(10); Pla, O.A.(11)",2019.0,arXiv,arXiv,,"(1) Center for Comput. Astrophys., Flatiron Inst., New York, NY, United States; (2) Dept. of Phys. & Astron., Stony Brook Univ., Stony Brook, NY, United States; (3) Univ. of Newcastle, Newcastle, NSW, Australia; (4) Max Planck Inst. for Extraterrestrial Phys., Garching, Germany; (5) Inst. for Astron., Univ. of Edinburgh, Edinburgh, United Kingdom; (6) Center for Astrophys., Harvard & Smithsonian, Cambridge, MA, United States; (7) Australian Nucl. Sci. & Technol. Organ., Lucas Heights, NSW, Australia; (8) Planetary Sci. Inst., Tucson, AZ, United States; (9) Climate & Environ. Phys., Univ. of Bern, Bern, Switzerland; (10) P.N. Lebedev Phys. Inst., Moscow, Russia; (11) Univ. Pompeu Fabra, Barcelona, Spain",arXiv,English,,
Inspec,GPdoemd: a python package for design of experiments for model discrimination using Gaussian process surrogates [arXiv],GPdoemd is an open-source python package for design of experiments for model discrimination that uses Gaussian process surrogate models to approximate and maximise the divergence between marginal predictive distributions of rival mechanistic models. GPdoemd uses the divergence prediction to suggest a maximally informative next experiment.,GPdoemd - design of experiments - model discrimination - open-source python package - Gaussian process surrogate models - divergence prediction,"Olofsson, S.(1); Misener, R.(1)",2018.0,arXiv,arXiv,,"(1) Dept. of Comput., Imperial Coll. London, London, United Kingdom",arXiv,English,,
Inspec,TurbuStat: Turbulence Statistics in Python,"We present TurbuStat (v1.0): a python package for computing turbulence statistics in spectral-line data cubes. TurbuStat includes implementations of 14 methods for recovering turbulent properties from observational data. Additional features of the software include: distance metrics for comparing two data sets; a segmented linear model for fitting lines with a break point; a two-dimensional elliptical power-law model; multicore fast-Fourier-transform support; a suite for producing simulated observations of fractional Brownian Motion fields, including two-dimensional images and optically thin H i data cubes; and functions for creating realistic world coordinate system information for synthetic observations. This paper summarizes the TurbuStat package and provides representative examples using several different methods. TurbuStat is an open-source package and we welcome community feedback and contributions.",turbulence statistics - spectral-line data cubes - turbulent properties - observational data - distance metrics - data sets - segmented linear model - fitting lines - two-dimensional elliptical power-law model - simulated observations - fractional Brownian Motion fields - two-dimensional images - synthetic observations - Python package - open source package - turbustat package - multicore fast Fourier transform support,"Koch, E.W.(1); Rosolowsky, E.W.(1); Boyden, R.D.(2); Burkhart, B.(3); Ginsburg, A.(4); Loeppky, J.L.(5); Offner, S.S.R.(6)",2019.0,Journal,Astronomical Journal,10.3847/1538-3881/ab1cc0,"(1) Dept. of Phys., Univ. of Alberta, Edmonton, AB, Canada; (2) Dept. of Astron. & Steward Obs., Univ. of Arizona, Tucson, AZ, United States; (3) Center for Comput. Astrophys., Flatiron Inst., New York, NY, United States; (4) Nat. Radio Astron. Obs., Socorro, TX, United States; (5) Dept. of Phys., Univ. of British Columbia, Kelowna, BC, Canada; (6) Dept. of Astron., Univ. of Texas at Austin, Austin, TX, United States",IOP Publishing,English,1538-3881,
Inspec,libconform v0.1.0: a Python library for conformal prediction [arXiv],"This paper introduces libconform v0.1.0, a Python library for the conformal prediction framework, licensed under the MIT-license. libconform is not yet stable. This paper describes the main algorithms implemented and documents the API of libconform. Also some details about the implementation and changes in future versions are described.",Python library - conformal prediction framework - MIT-license - libconform v0.1.0 - API,"Fassbender, J.",2019.0,arXiv,arXiv,,,arXiv,English,,
Inspec,An overview and comparison of free Python libraries for data mining and big data analysis,"The popularity of Python is growing, especially in the field of data science. Consequently, there is an increasing number of free libraries available for usage. The aim of this review paper is to describe and compare the characteristics of different data mining and big data analysis libraries in Python. There is currently no paper dealing with the subject and describing pros and cons of all these libraries. Here we consider more than 20 libraries and separate them into six groups: core libraries, data preparation, data visualization, machine learning, deep learning and big data. Beside functionalities of a certain library, important factors for comparison are the number of contributors developing and maintaining the library and the size of the community. Bigger communities mean larger chances for easily finding solution to a certain problem. We currently recommend: pandas for data preparation; Matplotlib, seaborn or Plotly for data visualization; scikit-learn for machine leraning; TensorFlow, Keras and PyTorch for deep learning; and Hadoop Streaming and PySpark for big data.",free Python libraries - data science - core libraries - data preparation - data visualization - big data analysis - data mining - machine learning - deep learning - pandas - Matplotlib - seaborn - Plotly - scikit-learn - TensorFlow - Keras - PyTorch - PySpark - Hadoop Streaming,"Stancin, I.(1); Jovic, A.(1)",2019.0,Conference,"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)",10.23919/MIPRO.2019.8757088,"(1) Dept. of Electron., Microelectron., Comput. & Intell. Syst., Univ. of Zagreb, Zagreb, Croatia",IEEE,English,,
Inspec,The Python user interface of the elsA CFD software: a coupling framework for external steering layers [arXiv],"The Python--elsA user interface of the elsA CFD (Computational Fluid Dynamics) software has been developed to allow users to specify simulations with confidence, through a global context of description objects grouped inside scripts. The software main features are generated documentation, context checking and completion, and helpful error management. Further developments have used this foundation as a coupling framework, allowing (thanks to the descriptive approach) the coupling of external algorithms with the CFD solver in a rather simple and abstract way, leading to more success in complex simulations. Along with the description of the technical part of the interface, we try to gather the salient points pertaining to the psychological viewpoint of user experience (UX).",elsA CFD software - external steering layers - Python--elsA user interface - computational fluid dynamics - description objects - context checking - error management - CFD solver - complex simulations - psychological viewpoint - user experience - UX,"Marc, L.(1)",2016.0,arXiv,arXiv,,"(1) ONERA, Chatillon, France",arXiv,English,,
Inspec,Kernel methods library for pattern analysis and machine learning in python [arXiv],"Kernel methods have proven to be powerful techniques for pattern analysis and machine learning (ML) in a variety of domains. However, many of their original or advanced implementations remain in Matlab. With the incredible rise and adoption of Python in the ML and data science world, there is a clear need for a well-defined library that enables not only the use of popular kernels, but also allows easy definition of customized kernels to fine-tune them for diverse applications. The kernelmethods library fills that important void in the python ML ecosystem in a domain-agnostic fashion, allowing the sample data type to be anything from numerical, categorical, graphs or a combination of them. In addition, this library provides a number of well-defined classes to make various kernel-based operations efficient (for large scale datasets), modular (for ease of domain adaptation), and inter-operable (across different ecosystems). The library is available at https://github.com/raamana/kernelmethods.",kernel methods library - pattern analysis - machine learning - data type - kernel-based operations - Python ML ecosystem - Matlab,"Raamana, P.R.(1)",2020.0,arXiv,arXiv,,"(1) Baycrest Health Sci., Rotman Res. Inst., Toronto, ON, Canada",arXiv,English,,
Inspec,Parsl: Pervasive Parallel Programming in Python [arXiv],"High-level programming languages such as Python are increasingly used to provide intuitive interfaces to libraries written in lower-level languages and for assembling applications from various components. This migration towards orchestration rather than implementation, coupled with the growing need for parallel computing (e.g., due to big data and the end of Moore's law), necessitates rethinking how parallelism is expressed in programs. Here, we present Parsl, a parallel scripting library that augments Python with simple, scalable, and flexible constructs for encoding parallelism. These constructs allow Parsl to construct a dynamic dependency graph of components that it can then execute efficiently on one or many processors. Parsl is designed for scalability, with an extensible set of executors tailored to different use cases, such as low-latency, high-throughput, or extreme-scale execution. We show, via experiments on the Blue Waters supercomputer, that Parsl executors can allow Python scripts to execute components with as little as 5 ms of overhead, scale to more than 250 000 workers across more than 8000 nodes, and process upward of 1200 tasks per second. Other Parsl features simplify the construction and execution of composite programs by supporting elastic provisioning and scaling of infrastructure, fault-tolerant execution, and integrated wide-area data management. We show that these capabilities satisfy the needs of many-task, interactive, online, and machine learning applications in fields such as biology, cosmology, and materials science. [doi:10.1145/3307681.3325400].",composite programs - elastic provisioning - fault-tolerant execution - pervasive parallel programming - high-level programming languages - intuitive interfaces - lower-level languages - parallel computing - Moore's law - parallel scripting library - dynamic dependency graph - extreme-scale execution - Parsl executors - Python scripts - Parsl features - Blue Waters supercomputer - parallelism - Big Data,"Babuji, Y.; Woodard, A.; Zhuozhao Li; Katz, D.S.; Clifford, B.; Kumar, R.; Lacinski, L.; Chard, R.; Wozniak, J.M.; Foster, I.; Wilde, M.; Chard, K.",2019.0,arXiv,arXiv,,,arXiv,English,,
Inspec,srlearn: a python library for gradient-boosted statistical relational models [arXiv],"We present srlearn, a Python library for boosted statistical relational models. We adapt the scikit-learn interface to this setting and provide examples for how this can be used to express learning and inference problems.",learning problems - inference problems - gradient-boosted statistical relational models - Python library - srlearn - scikit-learn interface,"Hayes, A.L.",2019.0,arXiv,arXiv,,,arXiv,English,,
