DataBase,Title,Abstract,Keywords,Authors,Year,DocumentType,PublicationTitle,DOI,Link,Affiliations,Publisher,Language,ISSN,ISBN
IEEE,Evaluating COTS Components Using Gap Analysis,"In current COTS software components evaluation methods, the resulting scores only represent relative ranking of the alternatives and the differences in their value does not give any indication of their relative superiority. Based on gap analysis theory, a new evaluation approach is proposed in this paper. The functional and non-functional gap between COTS components and system requirements are identified through function point analysis and corresponding adjustment cost is measured by count of function points. Besides adjustment cost, purchase cost is also a part of the total cost for adopting a COTS product. The fitness of a COTS product to requirements is defined as the ratio of the functional size of target system to the total cost of COTS that is also measured in functional size.",CBSD;COTS evaluation and selection;gap analysis;function point,J. Sheng; B. Wang,2008,Conference,2008 The 9th International Conference for Young Computer Scientists,10.1109/ICYCS.2008.472,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4709152,"Sch. of Inf. Sci. & Eng., Central South Univ., Changsha; Sch. of Inf. Sci. & Eng., Central South Univ., Changsha",IEEE,English,,978-0-7695-3398-8
IEEE,The role of architecture in the development of software systems,"Systems increasingly rely on software as the main technology for implementing the desired behaviour. There is a clear trend of steadily growing sophistication in the behaviour of these systems. The availability of cheap and fast hardware suggests that successive generations of systems should exhibit greatly enhanced behaviour, but this increase in functionality is not observed to an extent that can be related to the progress made in hardware. To the contrary, systems grow in complexity very rapidly (as exemplified by their cost and the required sophistication of the development process), without providing much in terms of added functionality. This complexity, and resulting cost, limits the achievable level of sophistication in systems, unless techniques are found that allow the software complexity to be reduced very significantly. The imbalance between cost and functionality is discussed and arguments are presented suggesting it to be avoidable through a sound software architecture.",,M. Boasson,1996,Conference,Proceedings of 20th International Computer Software and Applications Conference: COMPSAC '96,10.1109/CMPSAC.1996.544589,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=544589,"Hollandse Signaalapparaten BV, Henglo, Netherlands",IEEE,English,0730-3157,0-8186-7579-9
IEEE,Software size measurement with use case point for employee application software at STT-PLN,"Employee Application (EA) is a system information for realizing the latest personal data and integrated, provide accurate employee information for planning, development, welfare and control of employees. EA in STT-PLN began to be published since 2013. The software size of the EA STT-PLN will be measured with use case point method. Measurement of the software size of EA STT-PLN will be measured with Use Case Point upon use case diagram for EA STT-PLN as shown in the project has small software size where score Use Case Point (UCP) = 70.34. UCP is another alternative implementation method which can be applied to measure application software size whenever needed to deal with time, money and people.",Use Case Point;Software Measurement;Software Metrics;Software Project,H. B. Agtriadi; N. Chandra; H. L. H. S. Warnars; F. L. Gaol,2017,Conference,2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom),10.1109/CYBERNETICSCOM.2017.8311701,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8311701,"Computer Science Department, BINUS Graduate Program - Doctor of Computer Science, Bina Nusantara University Jakarta, Indonesia 11480; Mobile Application & Technology Program, Computer Science Department, School of Computer Science Bina Nusantara University, Jakarta, Indonesia 11480; Computer Science Department, BINUS, Graduate Program - Doctor of Computer Science Bina Nusantara University Jakarta, Indonesia 11480; Computer Science Department, BINUS, Graduate Program - Doctor of Computer Science Bina Nusantara University Jakarta, Indonesia 11480",IEEE,English,,978-1-5386-0784-8
IEEE,An empirical study using task assignment patterns to improve the accuracy of software effort estimation,"In most software development organizations, there is seldom a one-to-one mapping between software developers and development tasks. It is frequently necessary to concurrently assign individuals to multiple tasks and to assign more than one individual to work cooperatively on a single task. A principal goal in making such assignments should be to minimize the effort required to complete each task. But what impact does the manner in which developers are assigned to tasks have on the effort requirements? This paper identifies four task assignment factors: team size, concurrency, intensity, and fragmentation. These four factors are shown to improve the predictive ability of the well-known intermediate COCOMO cost estimation model. A parsimonious effort estimation model is also derived that utilizes a subset of the task assignment factors and unadjusted function points. For the data examined, this parsimonious model is shown to have goodness of fit and quality of estimation superior to that of the COCOMO model, while utilizing fewer cost factors.",,R. K. Smith; J. E. Hale; A. S. Parrish,2001,Journal,IEEE Transactions on Software Engineering,10.1109/32.910861,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=910861,"Math., Comput. & Inf. Sci. Dept., Jacksonville State Univ., AL, USA; NA; NA",IEEE,English,1939-3520,
IEEE,Survival analysis for the duration of software projects,"In the area of software engineering various methods have been proposed in order to predict the cost of a software project in terms of the effort or of the productivity. An important feature which is closely related to the cost is the duration of a software project. In this paper we deal with the problem of studying and modeling the distribution of the time from specification until delivery of a software product. Specifically, we investigate the use of a statistical methodology known from biostatistics as survival analysis. The purpose of such an analysis is to describe the distribution of the duration and also to identify important factors that affect it. The great advantage of survival analysis is that we can utilize information not only from the completed projects in a dataset but also from ongoing projects. The general principles of the methodology are described with examples from applications to known data sets",,P. Sentas; L. Angelis,2005,Conference,11th IEEE International Software Metrics Symposium (METRICS'05),10.1109/METRICS.2005.45,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1509283,"Dept. of Informatics, Aristotle Univ. of Thesaloniki, Greece; Dept. of Informatics, Aristotle Univ. of Thesaloniki, Greece",IEEE,English,1530-1435,0-7695-2371-4
IEEE,A proposal for the improvement of project's cost predictability using EVM and historical data of cost,"This paper proposes an extension of the Earned Value Management - EVM technique through the integration of historical cost performance data of processes under statistical control as a means to improve the predictability of the cost of projects. The proposed technique was evaluated through a case-study in industry, which evaluated the implementation of the proposed technique in 22 software development projects Hypotheses tests with 95% significance level were performed, and the proposed technique was more accurate and more precise than the traditional technique for calculating the Cost Performance Index - CPI and Estimates at Completion - EAC.",Cost Performance Index — CPI;Software Metrics;Earned Value Management — EVM;High Maturity,A. Diniz de Souza,2013,Conference,2013 35th International Conference on Software Engineering (ICSE),10.1109/ICSE.2013.6606740,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6606740,"Universidade Federal do Rio de Janeiro - UFRJ / COPPE, Rio de Janeiro, Brasil",IEEE,English,1558-1225,978-1-4673-3076-3
IEEE,Are CMM Program Investments Beneficial? Analyzing Past Studies,"CMM experts strongly believe that investments in programs promoting an organization's CMM maturity yield substantial organizational and economic benefits. In particular, they argue that CMM programs that implement software process improvements can provide more benefits",CMM;software development performance metrics;error density;productivity;rework;cycle time;schedule fidelity;error detection effectiveness;return on investment;ROI,D. Galin; M. Avrahami,2006,Magazine,IEEE Software,10.1109/MS.2006.149,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4012629,Ruppin Academic Center; Lipman Electronic Engineering,IEEE,English,1937-4194,
IEEE,The Measurement of Software Size based on Generation Model using COSMIC FSM,"The software size measurement plays essential roles in developing a software project to estimate costs, efforts and other resources. It provides the necessary input to estimate the effort at the early stage of the software development process. Thus, COSMIC FSM (Common Software Measurement International Consortium Functional Size Measurement) is one of the well-known methods of FSM which is suitable to estimate the size of software project at the early stage of development process. The industries use not only the standardized methods but also the well-defined modeling notations to measure the functional size of software. Some research has focused on the specific design notations to facilitate the design of the system. Therefore, this paper proposes a new model which is named as a generation model that can be accepted from various types of modeling notations and then these types converted into common general model for calculating the functional size of COSMIC concept. The generation model can help many researchers and estimators to understand the concepts of complex diagram notations easily. Then, the mapping rules define between the COSMIC FSM and generation model to measure the size of software. Finally, the function size results of the system are calculated by using COSMIC method.",Meta model;UML sequence diagram;SysML sequence diagram;Petri net;COSMIC Functional Size Measurement (FSM),T. Zaw; S. Z. Hlaing; M. Myint Lwin; K. Ochimizu,2019,Conference,2019 23rd International Computer Science and Engineering Conference (ICSEC),10.1109/ICSEC47112.2019.8974688,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8974688,"University of Information Technology,Yangon,Myanmar; University of Information Technology,Yangon,Myanmar; University of Information Technology,Yangon,Myanmar; University of Information Technology,Yangon,Myanmar",IEEE,English,,978-1-7281-2544-2
IEEE,Function Point Analysis to knowledge representation of software size measurement,"In Function Point Analysis through the technique of case-based reasoning(CBR), use the expert system to measure the software size, is the new method of software measurement, the knowledge representation is the basis of this new method. In this paper, firstly, analyze the role of the function point analysis in the software measurement; then describe the knowledge representation method of Production Rules in detail; finally, propose the data model of the function point analysis for software size measurement, to analyze the Technical complexity factors and their weights of the model, then carry out knowledge representation on function point analysis. The results show that, the knowledge representation used in this paper, can simulate the human thinking process of problem solving, has features as Naturalness, modularity, efficiency, clarity, etc, on the application of Function Point Analysis to measure the size having good reference value.",,Y. Ren; T. Xing; Qiang Quan,2011,Conference,International Conference on Information Science and Technology,10.1109/ICIST.2011.5765224,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5765224,"College of Information Science and Technology, Bohai University, CO 121013 China; Key Laboratory of urban Operation and Management, Beijing Research Center of Urban Systems Engineering, CO 100089 China; Electronic & Information Engineering College, Liaoning Technology University, CO 121001 China",IEEE,English,2164-4357,978-1-4244-9442-2
IEEE,An approach to predict software maintenance cost based on ripple complexity,"Almost half of a software maintainer's time is spent trying to understand programs. This means that software maintenance cost prediction depends on software understandability. We have proposed ripple complexity as a means to predict program understandability. This paper describes an experiment to prove the usefulness of ripple complexity. The result of this experiment has shown that ripple complexity is more closely related to program understandability than lines of source code, cyclomatic complexity and function point analysis.<>",,T. Hirota; M. Tohki; C. M. Overstreet; M. Hashimoto; R. Cherinka,1994,Conference,Proceedings of 1st Asia-Pacific Software Engineering Conference,10.1109/APSEC.1994.465236,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=465236,"Kyushu Inst. of Technol., Iizuka, Japan; NA; NA; NA; NA",IEEE,English,,0-8186-6960-8
IEEE,A comparison of development effort estimation techniques for Web hypermedia applications,"Several studies have compared the prediction accuracy of different types of techniques with emphasis placed on linear and stepwise regressions, and case-based reasoning (CBR). We believe the use of only one type of CBR technique may bias the results, as there are others that can also be used for effort prediction. This paper has two objectives. The first is to compare the prediction accuracy of three CBR techniques to estimate the effort to develop Web hypermedia applications. The second objective is to compare the prediction accuracy of the best CBR technique, according to our findings, against three commonly used prediction models, namely multiple linear regression, stepwise regression and regression trees. One dataset was used in the estimation process and the results showed that different measures of prediction accuracy gave different results. MMRE and MdMRE showed better prediction accuracy for multiple regression models whereas box plots showed better accuracy for CBR.",,E. Mendes; I. Watson; C. Triggs; N. Mosley; S. Counsell,2002,Conference,Proceedings Eighth IEEE Symposium on Software Metrics,10.1109/METRIC.2002.1011332,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1011332,"Dept. of Comput. Sci., Auckland Univ., New Zealand; Dept. of Comput. Sci., Auckland Univ., New Zealand; NA; NA; NA",IEEE,English,1530-1435,0-7695-1339-5
IEEE,Towards Software Quality Economics for Defect-Detection Techniques,"There are various ways to evaluate defect-detection techniques. However, for a comprehensive evaluation the only possibility is to reduce all influencing factors to costs. There are already some models and metrics for the cost of quality that can be used in that context. The existing metrics for the effectiveness and efficiency of defect-detection techniques and experiences with them are combined with cost metrics to allow a more fine-grained estimation of costs and a comprehensive evaluation of defect-detection techniques. The current model is most suitable for directly comparing concrete applications of different techniques",,S. Wagner,2005,Conference,29th Annual IEEE/NASA Software Engineering Workshop,10.1109/SEW.2005.47,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1521215,"Institut fur Informatik Technische Universit at Munchen Boltzmannstr. Garching, Germany",IEEE,English,1550-6215,0-7695-2306-4
IEEE,Validation of software effort models,Several static models for software effort were examined on three data sets. Models applied to new data sets need to be evaluated relative to the quality of the data set and this can be benchmarked by fitting a least squares model to the data. This natural model can then be compared to the model that is being evaluated.,,L. F. Johnson; M. L. Smith; A. M. Stevens,1999,Conference,Engineering Solutions for the Next Millennium. 1999 IEEE Canadian Conference on Electrical and Computer Engineering (Cat. No.99TH8411),10.1109/CCECE.1999.807208,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=807208,"Inf. Metrics Inst., New Brunswick Univ., Fredericton, NB, Canada; NA; NA",IEEE,English,0840-7789,0-7803-5579-2
IEEE,Measuring the functionality of online stores,"This paper shows the need of a framework which can be used to measure the functionality delivered by electronic commerce (e-commerce) systems. Such a framework would be helpful in areas such as cost prediction, effort estimation, and so on. The paper goes on to propose such a framework, based on the established methods of function points and object points.",Software Metrication;e-Commerce;Function Points;Object Points;Software Quality Assurance,E. Cachia; M. Micallef,2005,Conference,29th Annual International Computer Software and Applications Conference (COMPSAC'05),10.1109/COMPSAC.2005.97,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1508087,"Dept. of Comput. Sci. & Artificial Intelligence, Univ. of Malta, Malta; Dept. of Comput. Sci. & Artificial Intelligence, Univ. of Malta, Malta",IEEE,English,0730-3157,0-7695-2413-3
IEEE,Estimating software project effort using analogies,"Accurate project effort prediction is an important goal for the software engineering community. To date most work has focused upon building algorithmic models of effort, for example COCOMO. These can be calibrated to local environments. We describe an alternative approach to estimation based upon the use of analogies. The underlying principle is to characterize projects in terms of features (for example, the number of interfaces, the development method or the size of the functional requirements document). Completed projects are stored and then the problem becomes one of finding the most similar projects to the one for which a prediction is required. Similarity is defined as Euclidean distance in n-dimensional space where n is the number of project features. Each dimension is standardized so all dimensions have equal weight. The known effort values of the nearest neighbors to the new project are then used as the basis for the prediction. The process is automated using a PC-based tool known as ANGEL. The method is validated on nine different industrial datasets (a total of 275 projects) and in all cases analogy outperforms algorithmic models based upon stepwise regression. From this work we argue that estimation by analogy is a viable technique that, at the very least, can be used by project managers to complement current estimation techniques.",,M. Shepperd; C. Schofield,1997,Journal,IEEE Transactions on Software Engineering,10.1109/32.637387,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=637387,"Dept. of Comput., Bournemouth Univ., Poole, UK; NA",IEEE,English,1939-3520,
IEEE,Value estimation for software product management,Value-based approach of software engineering proved to be one of the most important branches of software engineering because it elicits and reconciles stakeholder¿s value propositions with respect to the system into a mutually satisfactory set of objectives for the system. Thus most of software organizations in market-driven environment nowadays adopt value-based approach with the focus on maximizing the value gained from their products against consumed resources. This leads to a need for a value estimation methodology to incorporate all the software product value aspects altogether while measuring the product value. Most of the existing methodologies focus on measuring product financial value and neglect the nonfinancial value. Value point measurement will facilitate quantifying the total value obtained from the product and compare it against planned product budget at early phases of the product life cycle. Such comparison will be used as a sort of justification for product feasibility. This paper illustrates a new estimation methodology for the software product value called ¿Value Point¿. VP measures value gained from the software product through quantifying value obtained from each product requirement. The process for value point counting will be illustrated through a designed product management framework. A case study is performed to demonstrate the added value from the proposed methodology.,Value Point;Value-Based estimation;Product management;Release planning,S. I. Mohamed; A. M. Wahba,2008,Conference,2008 IEEE International Conference on Industrial Engineering and Engineering Management,10.1109/IEEM.2008.4738261,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4738261,"Department of computer and system Engineering, Ain Shams University, Cairo, Egypt; Department of computer and system Engineering, Ain Shams University, Cairo, Egypt",IEEE,English,2157-362X,978-1-4244-2629-4
IEEE,Measuring web service interfaces,"The following short paper describes a tool supported method for measuring web service interfaces. The goal is to assess the complexity and quality of these interfaces as well as to determine their size for estimating evolution and testing effort. Besides the metrics for quantity, quality and complexity, rules are defined for ensuring maintainability. In the end a tool - WSDAudit - is described which the author has developed for the static analysis of web service definitions. The WSDL schemas are automatically audited and measured for quality assurance and cost estimation. Work is underway to verify them against the BPEL procedures from which they are invoked.",web services;WSDL;metrics;rule checking;quality;complexity;sizing;static analysis;code inspection;interface rule checking,H. M. Sneed,2010,Conference,2010 12th IEEE International Symposium on Web Systems Evolution (WSE),10.1109/WSE.2010.5623580,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5623580,"ANECON GmbH, Vienna, Austria",IEEE,English,1550-4441,978-1-4244-8637-3
IEEE,Improving software size estimates by using probabilistic pairwise comparison matrices,"The pairwise comparison technique is a general purpose estimation approach for capturing expert judgment. This approach can be generalized to a probabilistic version using Monte Carlo methods to produce estimates of size distributions. The probabilistic pairwise comparison technique enables the estimator to systematically incorporate both estimation uncertainty as well as any uncertainty that arises from using multiple historical analogies as reference modules. In addition to describing the methodology, the results of the case study are also included. This paper is an extension of the work presented in [Lum, K et al., (2003)] and shows how the original software size estimates compared to the actual delivery size. It also describes the techniques used to modify the approach based on lessons learned. The results because they are based on only one case do not validate the effectiveness of the proposed approach but are suggestive that the technique can be effective and support the conclusion that further research is worth pursuing.",,J. Hihn; K. T. Lum,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357898,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357898,"Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA; Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,Software Project Estimation Using Improved Use Case Point,"Estimating metrics, such as effort, schedule and cost, needed for a software to be created and launched into market have significant economical effects. One of the most extensively utilized method for such estimation is a technique called Use Case Points. It is based on the use case modeling which is a popular and widely used technique for capturing and describing the functional requirements of a software system. In this paper multitude number of techniques have been proposed as the basis for improving estimation of the effort, schedule, and costs of software projects. These terms are conceptually similar but utilize different parameter values and metrics. Moreover, different versions of use case points have been proposed. This method suffers some limitations such as less accuracy, failure to consider software risks, failure to consider software quality aspects, failure to consider different levels of software security, and so on. The aim of this paper is to propose a new approach for cost estimation, based on use case points method, by considering all the existing risks related to software projects. The results indicate that the new estimation approach can produce relatively accurate estimates and also declare various aspects of project risks during project estimation. Our results also provide guidance for organizations that want to develop a software project.",Software Cost;Software Estimation;Software Risks;Use-case point,S. Bagheri; A. Shameli-Sendi,2018,Conference,"2018 IEEE 16th International Conference on Software Engineering Research, Management and Applications (SERA)",10.1109/SERA.2018.8477225,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8477225,"Faculty of Computer Science and Engineering, Shahid Beheshti University (SBU), Tehran, Iran; Faculty of Computer Science and Engineering, Shahid Beheshti University (SBU), Tehran, Iran",IEEE,English,,978-1-5386-5886-4
IEEE,esrcTool: A Tool to Estimate the Software Risk and Cost,"Function Point is a well known established method to estimate the size of software projects. There are several areas of the software engineering in which we can use the function point analysis (FPA) like project planning, project construction, software implementation etc. In this paper we have used the function point approach in order to develop the architecture of the esrcTool. This tool is used for two different purposes, firstly, to estimate the risk in the software and secondly to estimate the cost of the software. In the literature of software engineering there are so many models to estimate the risk in the software like Soft Risk Model, SRAM, SRAEM and so on. But in the esrcTool we have used SRAEM i.e. Software Risk Assessment and Estimation Model, because in this model FP is used as an input variable, and on the other hand side, in order to determine the cost of the software we have used the International Software Benchmarking Standards Group Release Report (ISBSG).",FPA;Software risk;Cost;SRAEM,M. Sadiq; A. Rahman; S. Ahmad; M. Asim; J. Ahmad,2010,Conference,2010 Second International Conference on Computer Research and Development,10.1109/ICCRD.2010.29,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5489451,"Fac. of Eng. & Technol., Jamia Millia Islamia A Central Univ., New Delhi, India; Dept. of Comput. Sci. & Eng., Al-Falah Sch. of Eng. & Technol., Faridabad, India; Fac. of Eng. & Technol., Jamia Millia Islamia A Central Univ., New Delhi, India; Dept. of Comput. Sci. & Eng., Al-Falah Sch. of Eng. & Technol., Faridabad, India; Fac. of Eng. & Technol., Jamia Millia Islamia A Central Univ., New Delhi, India",IEEE,English,,978-0-7695-4043-6
IEEE,Early Functional Size Estimation with IFPUG Unit Modified,"Nowadays functional size measurement is a strategic key to deal with the management of software systems development. The origin of this importance is the fact that functional size measurement is the main input variable in software effort estimation systems. Nevertheless, to obtain precise functional size measurements it is not only necessary to have a lot of information of the system to be developed, but also software project planning is one of the early stages in the project. To solve this difficulty, one of the main software management research technique is centered in the study of methods to obtain precise functional size measurements early in the development phase for early functional size estimation. The functional size unit selected to do the study has been IFPUG because is the most widely used method.",Software Management;Software Process;Software Measurement;Functional Size;IFPUG,J. J. Cuadrado-Gallego; P. Rodríguez-Soria; A. González; D. Castelo; S. Hakimuddin,2010,Conference,2010 IEEE/ACIS 9th International Conference on Computer and Information Science,10.1109/ICIS.2010.12,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5591011,"Comput. Sci. Dept., Univ. of Alcala, Alcala de Henares, Spain; Comput. Sci. Dept., Univ. of Alcala, Alcala de Henares, Spain; Comput. Sci. Dept., Univ. of Alcala, Alcala de Henares, Spain; Comput. Sci. Dept., Univ. of Alcala, Alcala de Henares, Spain; Dept. of Comput. Sci. & Eng., Manipal Inst. of Technol., Manipal, India",IEEE,English,,978-1-4244-8198-9
IEEE,Using Web objects for estimating software development effort for Web applications,"Web development projects are certainly different from traditional software development projects and hence require differently tailored measures for accurate effort estimation. We investigate the suitability of a newly proposed size measure for Web development projects: Web objects. Web objects have been specifically developed for sizing Web applications and used for estimating effort in a COCOMO Il-like estimation model called WEBMO. However, no empirical validation has yet been published. We apply and validate the proposed Web object approach in the context of a small Australian Web development company, for the first time. Besides Web objects, we apply traditional function points as an effort predictor for Web applications. Effort estimation models based on Web objects are compared with models based on traditional function points using ordinary least squares regression (OLS). Tested on data from twelve Web applications, the estimates derived from estimation models using Web objects significantly outperformed models using function points, with a mean magnitude of relative error of 0.24 versus 0.33, respectively. Based on the results, it seems that Web objects are more suitable for effort estimation purposes of Web applications than traditional function points.",,M. Ruhe; R. Jeffery; I. Wieczorek,2003,Conference,Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717),10.1109/METRIC.2003.1232453,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1232453,"Corp. Technol., Siemens AG, Germany; NA; NA",IEEE,English,1530-1435,0-7695-1987-3
IEEE,A comparative study on software reuse metrics and economic models from a traceability perspective,"A fundamental task when employing software reuse is evaluating its impacts by measuring the relation of reused and developed software, the cost for obtaining reuse and the cost avoided by reusing software during development and maintenance. Different reuse related metrics exist in the literature, varying from strictly code-based metrics, aiming to measure the amount of code reused in a product, to more elaborate cost-based metrics and models, aiming to measure the costs involved in reuse programs and to evaluate the impacts of reuse in software development. Although reuse is commonly claimed to benefit maintenance, the traceability problem is still neglected on the reuse metrics arena, despite its great impacts on software maintenance. Reuse metrics may be used as important support tools for dealing with the traceability between reused assets and their clients. The goal of this work is to evaluate the current state of the art on the reuse metrics area with special emphasis on code-based metrics, building on previous surveys with further analysis and considerations on the applicability of such metrics to reuse traceability.",,J. C. C. P. Mascena; E. S. de Almeida; S. R. de Lemos Meira,2005,Conference,"IRI -2005 IEEE International Conference on Information Reuse and Integration, Conf, 2005.",10.1109/IRI-05.2005.1506452,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1506452,"Recife Center for Adv. Studies & Syst., Fed. Univ. of Pernambuco, Brazil; Recife Center for Adv. Studies & Syst., Fed. Univ. of Pernambuco, Brazil; Recife Center for Adv. Studies & Syst., Fed. Univ. of Pernambuco, Brazil",IEEE,English,,0-7803-9093-8
IEEE,Value creation and capture: a model of the software development process,"Landmark Graphics supplies software and services to the upstream oil and gas industry. Our software portfolio, which ranges from exploration and drilling to data management and decision analysis, includes more than 60 products consisting of over 50 million lines of source code. For many years, Landmark has been collecting project metrics we wished to harvest to gain insight into key business questions in three areas: optimal release cycle duration (scope/time trade-off), optimal project staffing levels, effects of uncertainty. We set out to develop a relatively simple project dynamics model to use in conjunction with market sensitivity and economic analysis to help optimize profitability. Some of our ideas and results are similar to those of Preston Smith and Donald Reinertsen, who examined the impact of time-to-market sensitivity. However, our approach is a more detailed model tuned to software development issues.",,T. Little,2004,Magazine,IEEE Software,10.1109/MS.2004.1293072,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1293072,,IEEE,English,1937-4194,
IEEE,Developing a design complexity measure,"The cost to develop and maintain software is increasing at a rapid rate. The majority of the total cost to develop software is spent in the post-deployment-maintenance phase of the software life-cycle. In order to reduce life-cycle costs, more effort needs to be spent in earlier phases of the software life-cycle. One characteristic that merits investigation is the complexity of a software design. Project performance metrics (i.e. effort, schedule, defect density, etc.) are driven by software complexity, and affect project costs. The Software Design Complexity Measure examines an organization's historical project performance metrics along with the complexity of a project's software design to estimate future project performance metrics. These estimates indicate costs that the evaluated software design will incur in the future. Equipped with future cost estimates, a project manager will be able to make more informed decisions concerning the future of the project.",,K. Littlejohn; M. Olis; R. Lentz; M. Barnett,1996,Conference,15th DASC. AIAA/IEEE Digital Avionics Systems Conference,10.1109/DASC.1996.559130,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=559130,"Wright Res. & Dev. Center, Wright-Patterson AFB, OH, USA; NA; NA; NA",IEEE,English,,0-7803-3385-3
IEEE,FPA and Quality Metrics in Contracts,"Outsourcing software development projects continues to be a very difficult task for many organizations. They struggle with the questions they should ask in the 'Request for Proposal (RFP)' phase. These organizations wish to find the questions that enable them to compare the bidding suppliers in an objective, yet meaningful way and they wish to select the right supplier based on this comparison. In practice, the industry sees many RFP's that seem to comply to this goal, but when looked into a little detailed, it becomes obvious that in many cases the comparison is not objective and meaningful at all and even that in many cases the wrong supplier is selected, often resulting in failing projects. Repeatedly, suppliers argue with client organizations about the objective reasoning for missed offers and sometimes they even start legal actions.",Outsourcing;FPA;Contracting,H. v. Heeringen; H. Kuijpers; R. Scholten; F. S. Uiterkamp; D. Müller; J. Onvlee; H. Bernink; M. Pereboom,2014,Conference,2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement,10.1109/IWSM.Mensura.2014.40,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7000098,NA; NA; NA; NA; NA; NA; NA; NA,IEEE,English,,978-1-4799-4174-2
IEEE,Analyzing Data on Software Evolution Processes,"This paper describes a tool supported process for evaluating software evolution processes using data analytics. Software evolution is concerned with correcting, changing and enhancing existing software systems. The evolution process is driven by error reports and change requests. The ISO-12207 standard prescribes how the process should be conducted. The approach presented here goes beyond simply checking if the process under investigation conforms to the prevailing standard. It collects data on the numbers and types of evolution requests as well as data on the time and effort required to implement them to determine if the evolution process is improving or degrading. For this, the error reports, change requests and time sheets are scanned to load a process performance database. There a numerical analysis is performed to measure the error and change rates for assessing process quality. Performance and usability data are also included in the quality assessment. In addition, the expended effort is analyzed in relation to the impact domain of the corrections and changes to determine the productivity rate. The number of reported errors and submitted change requests is essential to estimating the costs of future releases.",Software Evolution;Process measurement;Process assessment;numeric data analysis;product quality and complexity;productivity measurement;evolution cost projection,H. M. Sneed; W. Prentner,2016,Conference,2016 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement (IWSM-MENSURA),10.1109/IWSM-Mensura.2016.013,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7809585,"ZT-Prentner-IT GmbH, Vienna, Austria; ZT-Prentner-IT GmbH, Vienna, Austria",IEEE,English,,978-1-5090-4147-3
IEEE,A reuse metrics and return on investment model,"It is argued that establishing a realistic return on investment on a reuse program is essential to inserting reuse into a corporate software development process, and that clearly stating the potential benefits of reuse in financial terms has proven to be a powerful motivator. A reuse metrics and return on investment (ROI) model that distinguish the savings and benefits from those already gained through accepted software engineering techniques are defined. Three reuse metrics are derived from readily available and observable software data elements. The metrics are used in the return on investment model to establish sound business justification for reuse.<>",,J. S. Poulin; J. M. Caruso,1993,Conference,[1993] Proceedings Advances in Software Reuse,10.1109/ASR.1993.291707,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=291707,NA; NA,IEEE,English,,0-8186-3130-9
IEEE,Determination of functional domains for use with functional size measurement-opportunities to classify software from a business perspective,"Functional size measurement (FSM) is the focus of ISO/IEC Project 14143. This project has five parts, ranging from the recently published Part 1 (""Concepts of FSM"") to Part 5 (""Determination of Functional Domains for Use with FSM""), which is in development as a Technical Report Type 2 (TR2). This paper outlines the basic principles of FSM and why the functional domain concept has been seen as important to the overall project success. It covers the rationale behind this sub-project, its relevance to the software engineering world and how the functional domain topic extends far beyond the realm of simple FSM. The paper profiles the state of the software industry today and how the classifications of software in modern literature are insufficient for the needs of FSM. The current state of this TR2-in-progress is also presented, together with the various opinions of the international community involved in its development.",,C. A. Dekkers,1999,Conference,Proceedings 4th IEEE International Software Engineering Standards Symposium and Forum (ISESS'99). 'Best Software Practices for the Internet Age',10.1109/SESS.1999.766598,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=766598,"Quality Plus Technol. Inc., Seminole, FL, USA",IEEE,English,1082-3670,0-7695-0068-4
IEEE,Reducing cost in regression testing of web service,"Regression testing and retesting of a modified Web Service can be very costly as it tends to generates large number of test cases. Regression testing cost can be reduced significantly by identifying and testing the modified portion of the Web Service only. This avoids the costly construction of new test cases and the unproductive rerunning of existing test cases when it can be guaranteed that the unmodified code of web service will produce the same results as it produced previously. In this paper, by designing Web service graph we propose an effective method of identifying the modified areas (in this paper area means code of web service to be tested) and use this information to reduce regression testing efforts. In this process, we define and use a set of metrics to categorize the testing of Web service. We demonstrate the applicability of the proposed approach using a case study that consisted of two steps. In the first step, we compared two versions of WSDL's to identify the inserted, modified and deleted areas of the Web services. Next, we use this information to generate the reduced test cases.",Regression testing;web service;XML Diff;WSDL,A. Chaturvedi,2012,Conference,2012 CSI Sixth International Conference on Software Engineering (CONSEG),10.1109/CONSEG.2012.6349498,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6349498,"Indian Institute of Information Technology, Design and Manufacturing Jabalpur",IEEE,English,,978-1-4673-2177-8
IEEE,A metrics-based software maintenance effort model,"We derive a model for estimating adaptive software maintenance effort in person hours, the adaptive maintenance effort model (AMEffMo). A number of metrics such as lines of code changed and number of operators changed were found to be strongly correlated to maintenance effort. The regression models performed well in predicting adaptive maintenance effort as well as provide useful information for managers and maintainers.",,J. H. Hayes; S. C. Patel; L. Zhao,2004,Conference,"Eighth European Conference on Software Maintenance and Reengineering, 2004. CSMR 2004. Proceedings.",10.1109/CSMR.2004.1281427,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1281427,"Dept. of Comput. Sci., Kentucky Univ., Lexington, KY, USA; NA; NA",IEEE,English,1534-5351,0-7695-2107-X
IEEE,Detecting Clones in Business Applications,"A business application automates a collection of business processes. A business process describes how a set of logically related tasks are executed, ordered and managed by following business rules to achieve business objectives. An online bookstore business application contains several tasks such as buying a book, ordering a book, and sending out promotions. Business analysts specify business tasks and software developers implement these tasks. Throughout the lifetime of a business application, business analysts may clone (e.g., copy and slightly modify) business processes to handle special circumstances or promotions. Identifying these clones and removing them helps improve the efficiency of an organization. However most clone detection techniques are source code based not business process based. In this paper, we propose an approach that makes use of traditional source code detection techniques to detect clones in business applications. The effectiveness of our approach is demonstrated through a case study on 10 large open source business applications in the Apache Open for Business Project.",Clone detections;Business proecesses;Business applications,J. Guo; Y. Zou,2008,Conference,2008 15th Working Conference on Reverse Engineering,10.1109/WCRE.2008.12,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4656398,"Sch. of Comput. Queen's, Univ. Kingston, Kingston, ON; Sch. of Comput. Queen's, Univ. Kingston, Kingston, ON",IEEE,English,2375-5369,978-0-7695-3429-9
IEEE,Using fuzzy theory for effort estimation of object-oriented software,"Estimating software effort and costs is a very important activity that includes very uncertain elements. The concepts of the fuzzy set theory has been successfully used for extending metrics such as FP and reducing human influence in the estimation process. However, when we consider object-oriented technologies, other models, such as the use case model, are used to represent the specification in the early stages of development. New metrics based on this model were proposed and the application of the fuzzy set theory in this context is also very important. This work introduces the metric FUSP (fuzzy use case size points) that allows gradual classifications in the estimation by using fuzzy numbers. Results of a study case show some advantages and limitations of the proposed metric.",,M. R. Braz; S. R. Vergilio,2004,Conference,16th IEEE International Conference on Tools with Artificial Intelligence,10.1109/ICTAI.2004.119,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1374187,"Comput. Sci. Dept., Fed. Univ. of Parana, Curitiba, Brazil; Comput. Sci. Dept., Fed. Univ. of Parana, Curitiba, Brazil",IEEE,English,1082-3409,0-7695-2236-X
IEEE,Analyzing the cost and benefit of pair programming,"We use a combination of metrics to understand, model, and evaluate the impact of pair programming on software development. Pair programming is a core technique in the hot process paradigm of extreme programming. At the expense of increased personnel cost, pair programming aims at increasing both the team productivity and the code quality as compared to conventional development. In order to evaluate pair programming, we use metrics from three different categories: process metrics such as the pair speed advantage of pair programming; product metrics such as the module breakdown structure of the software; and project context metrics such as the market pressure. The pair speed advantage is a metric tailored to pair programming and measures how much faster a pair of programmers completes programming tasks as compared to a single developer. We integrate the various metrics using an economic model for the business value of a development project. The model is based on the standard concept of net present value. If the market pressure is strong, the faster time to market of pair programming can balance the increased personnel cost. For a realistic sample project, we analyze the complex interplay between the various metrics integrated in our model. We study for which combinations of the market pressure and pair speed advantage the value of the pair programming project exceeds the value of the corresponding conventional project. When time to market is the decisive factor and programmer pairs are much faster than single developers, pair programming can increase the value of a project, but there also are realistic scenarios where the opposite is true. Such results clearly show that we must consider metrics from different categories in combination to assess the cost-benefit relation of pair programming.",,F. Padberg; M. M. Muller,2003,Conference,Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717),10.1109/METRIC.2003.1232465,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1232465,"Fak. fur Inf., Karlsruhe Univ., Germany; Fak. fur Inf., Karlsruhe Univ., Germany",IEEE,English,1530-1435,0-7695-1987-3
IEEE,SRS Based Estimation of Software Maintenance Effort,"Software maintenance effort estimation has always been a challenge for the software practitioners, as it consumes about half of the overall development costs. The effort required to develop or maintain software depend on the complexity of yet to be developed software. The proposed measure estimates the requirement-based complexity based on SRS document of yet to be developed software for systematic and early prediction of software maintenance effort using Software Requirements Specifications (SRS) document of the proposed software. The result obtained validates that, the proposed maintenance measure is a comprehensive one and compares well with various other prevalent measures proposed in the past. The computation of proposed maintenance effort estimation involves least overhead as compared to others.",requirement based complexity;requirement based maintenance complexity;requirement based maintenance effort estimation,A. Tripathi; B. Kumar; A. Sharma; D. S. Kushwaha,2012,Conference,2012 Third International Conference on Computer and Communication Technology,10.1109/ICCCT.2012.38,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6394686,NA; NA; NA; NA,IEEE,English,,978-1-4673-3149-4
IEEE,An assessment of halstead and COCOMO model for effort estimation,This paper portrays a utilization of Maurice Halstead's product hypothesis' effect on modern programming languages like Python. The Halstead Metric and the product apparatus created for registering them are examined. Investigation of the metric information demonstrates that the level of the exchanging dialect was not consistent crosswise over algorithms and that product blunder information was not a straight capacity of volume. We also benchmark Halstead Metric against COCOMO II with respect to the accuracy of effort estimation.,Halstead metric;COCOMO model;comparison;effort metric,C. Thirumalai; R. R. Shridharshan; L. R. Reynold,2017,Conference,2017 Innovations in Power and Advanced Computing Technologies (i-PACT),10.1109/IPACT.2017.8245069,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8245069,"School of Information Technology and Engineering, VIT University, Vellore, India; MS in Software Engineering, School of Information Technology and Engineering, VIT University, Vellore, India; MS in Software Engineering, School of Information Technology and Engineering, VIT University, Vellore, India",IEEE,English,,978-1-5090-5682-8
IEEE,Adapting the SIMAP productivity model to software maintenance,"Industrial production firms have over time developed tools and models to ensure that productivity is measured and understood. This article suggests the use of such a model, the SIMAP model, for software maintenance. This article also shows how data could be organized and categorized in order to fully benefit from the SIMAP productivity model.",,D. Dery; A. Abran,1995,Conference,Proceedings 1995 Canadian Conference on Electrical and Computer Engineering,10.1109/CCECE.1995.526607,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=526607,"Quebec Univ., Montreal, Que., Canada; Quebec Univ., Montreal, Que., Canada",IEEE,English,0840-7789,0-7803-2766-7
IEEE,Backfiring: converting lines of code to function points,"The availability of empirical data from projects that use both function-point and lines-of-code metrics has led to a useful technique called backfiring. Backfiring is the direct mathematical conversion of LOC data into equivalent function-point data. Because the backfiring equations are bidirectional, they also provide a powerful way of sizing, or predicting, source-code volume for any known programming language or combination of languages. The function-point metric, invented by A.J. Albrecht of IBM in the middle 1970s, is a synthetic metric derived by a weighted formula that includes five elements: inputs, outputs, logical files, inquiries, and interfaces. IBM put it into the public domain in 1979, and its use spread rapidly, particularly after the formation of the International Function Point Users Group (IFPUG) in the mid-1980s. By then, hundreds of software projects had been measured using both function points and lines of source code. Since an application's function-point total is independent of the source code, this dual analysis has led to several important discoveries.<>",,C. Jones,1995,Magazine,Computer,10.1109/2.471193,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=471193,"Software Productivity Res. Inc., Burlington, MA, USA",IEEE,English,1558-0814,
IEEE,Formalizing COSMIC-FFP using ROOM,"We propose a formalization of the COSMIC Full Function Point (COSMIC-FFP) measure for the Real-time Object Oriented Modeling (ROOM) language. COSMIC-FFP is a measure of the functional size of software. It has been proposed by the COSMIC group as an adaptation of the function point measure for real-time systems. The definition of COSMIC-FFP is general and can be applied to any specification language. The benefits of our formalization are twofold. First it eliminates measurement variance, because the COSMIC informal definition is subject to interpretation by COSMIC-FFP raters, which may lead to different counts for the same specification, depending on the interpretation made by each rater. Second it allows the automation of COSMIC-FFP measurement for ROOM specifications, which reduces measurement costs. Finally, the formal definition of COSMIC-FFP can provide a clear and unambiguous characterization of COSMIC-FFP concepts which is helpful for measuring COSMIC-FFP for other object-oriented notations like UML.",,H. Diab; M. Frappier; R. St. Denis,2001,Conference,Proceedings ACS/IEEE International Conference on Computer Systems and Applications,10.1109/AICCSA.2001.934002,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=934002,"Dept. de Math. et d'Inf., Sherbrooke Univ., Que., Canada; NA; NA",IEEE,English,,0-7695-1165-1
IEEE,Automated FPA (eFPA) in SAP Environment - Visions and Experiences of Automated Function Point Analysis,"Dynamic market conditions, changing technologies and continuous improvement require more IT financial transparency than ever. The market is characterized by large IT investments. Regarding the investments, managers require a clear understanding of the costs and require means to control them. The most effective metrics are those that are applicable during all stages of the development process. This paper describes an automated FPA solution called eFPA that is based on counting system components in a reusable way. The eFPA is based on a digital delivery of system objects from a repository. There is no specific knowledge of FPA necessary. eFPA provides the ability to calculate quickly and calculate variants to perform intermediate counts during the project.",function points;functional size measurement;SAP;automated counting,C. Kuijpers,2014,Conference,2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement,10.1109/IWSM.Mensura.2014.35,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7000079,"DutchSoft Technol., Netherlands",IEEE,English,,978-1-4799-4174-2
IEEE,Living with function points,"The number of people who develop software at AT&T Bell Laboratories has grown steadily since the 1960's. Major productivity improvements were made, but efforts to reliably measure them were unsuccessful. With more than half of its technical people working on software projects and one in every 12 employees in AT&T now involved in one way or another in the creation of software, a major effort to produce world-class software is underway. The key to this new program is a shift from counting lines of code to using function points to size software projects. Improved predictability, simplified designs, contained feature creep, and reduced redundancy are the direct results of deploying formal function point analysis (FPA). Estimates of the effort required to do a job are twice as accurate with FPA as with conventional methods. This presentation describes: the software initiative at AT&T, the history of usage of FPA in AT&T, source lines of code (SLOC) vs. function points and the best current practices, automation of the function point count and estimation process, changes in AT&T's metrics policy and experiences in measurements based on FPA. The bumpy road of software measurement, the problems in estimating software project size and effort, and some positive results of using a measurement program are also discussed.",,A. Lubashevsky,1996,Conference,Proceedings of NOMS '96 - IEEE Network Operations and Management Symposium,10.1109/NOMS.1996.539637,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=539637,"AT&T Bell Labs., Warren, NJ, USA",IEEE,English,,0-7803-2518-4
IEEE,Enhancing the Cocomo estimation models,"In software engineering, team task assignments appear to have a significant potential impact on a project's overall success. The authors propose task assignment effort adjustment factors that can help tune existing estimation models. They show significant improvements in the predictive abilities of both Cocomo I and II by enhancing them with these factors.",,J. Hale; A. Parrish; B. Dixon; R. K. Smith,2000,Magazine,IEEE Software,10.1109/52.895167,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=895167,"Dept. of Inf. Syst., Stat. & Manage. Sci., Alabama Univ., Tuscaloosa, AL, USA; NA; NA; NA",IEEE,English,1937-4194,
IEEE,A metrics-based decision support tool for software module interfacing technique selection to lower maintenance cost,"The Interfacing Techniques Comparison Graph visually compares applications in terms of attributes that relate to maintenance cost. Applications that have both lower coupling and lower complexity lie closer to the origin of the graph and exhibit lower maintenance cost than those that do not. The study supports the idea that compositional techniques are important for achieving these improved metrics. The graph can be used in three ways. First it serves as a decision support tool for managers to determine whether expected maintenance savings compensate for the additional training, effort and time needed to support compositional development. Second, it functions as a decision support tool for designers and coders as they determine, for each module interface, whether to use coupled techniques or composition. The graph can help identify those situations in which the long term cost gain justifies the extra time needed for compositional design. Third, it can serve as a maintenance cost estimation tool. The study found a close correlation between predicted and actual maintenance effort.",,W. R. Bitman,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809738,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809738,"Appl. Phys. Lab., Johns Hopkins Univ., Baltimore, MD, USA",IEEE,English,,0-7695-0403-5
IEEE,Early metrics for object oriented designs,"To produce high quality object-oriented systems, a strong emphasis on the development process is necessary. This implies two implicit and complementary goals. First, to ensure a full control over the whole process, enabling accurate cost and delay estimation, resource efficient management, and a better overall understanding. Second, to improve quality all along the system lifecycle at development and maintenance stage. On the client side, a steady control over the development process implies a better detection and elimination of faults, raising the viability and usability of the system. This paper introduces a realistic example of metrics integration in the development process of object-oriented software. By addressing early stages of the design (ie. class diagram), we can anticipate design-level errors or warnings thus enabling a reduction of immediate and further costs and problems. Metrics used are issued from state of the art object-oriented research, and integrated in the widespread unified process of software development.",,B. Baldassari; C. Robach; L. du Bousquet,2004,Conference,"First International Workshop onTestability Assessment, 2004. IWoTA 2004. Proceedings.",10.1109/IWOTA.2004.1428417,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1428417,"LCIS, INP Grenoble, Valence, France; LCIS, INP Grenoble, Valence, France; NA",IEEE,English,,0-7803-8851-8
IEEE,A comparison of approaches to reuse investment analysis,"Software reuse economics has been the subject of vigorous study over the past few years. Although significant progress has been made in the areas of reuse metrics and cost estimation, work to date in reuse investment analysis has not always reflected accepted mainstream financial analysis practices. This paper compares several approaches that have been described in the reuse literature, points out known problems and indicates remedies.",,J. Favaro,1996,Conference,Proceedings of Fourth IEEE International Conference on Software Reuse,10.1109/ICSR.1996.496121,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=496121,"Intecs Sistemi SpA, Pisa, Italy",IEEE,English,,0-8186-7301-X
IEEE,A cost effectiveness indicator for software development,"Product quality, development productivity, and staffing needs are main cost drivers in software development. The paper proposes a cost-effectiveness indicator that combines these drivers using an economic criterion.",,H. Erdogmus,2007,Conference,First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007),10.1109/ESEM.2007.47,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4343774,"NRC Institute for Information Technology, Canada",IEEE,English,1949-3789,978-0-7695-2886-1
IEEE,A Quasi-experiment for Effort and Defect Estimation Using Least Square Linear Regression and Function Points,"Software companies are currently investing large amounts of money in software process improvement initiatives in order to enhance their products' quality. These initiatives are based on software quality models, thus achieving products with guaranteed quality levels. In spite of the growing interest in the development of precise prediction models to estimate effort, cost, defects and other project's parameters, to develop a certain software product, a gap remains between the estimations generated and the corresponding data collected in the project's execution. This paper presents a quasi-experiment reporting the adoption of effort and defect estimation techniques in a large worldwide IT company. Our contributions are the lessons learned during (a) extraction and preparation of project historical data, (b) the use of estimation techniques on these data, and (c) the analysis of the results obtained. We believe such lessons can contribute to the improvement of the state-of-the-art in prediction models for software development.",metrics estimation;linear regression;human judgment approaches,N. N. T. Jr.; M. B. Ribeiro; D. D. Ruiz,2008,Conference,2008 32nd Annual IEEE Software Engineering Workshop,10.1109/SEW.2008.20,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5328367,"NA; Fac. of Inf., Pontifical Catholic Univ. of Rio Grande do Sul, Porto Alegre, Brazil; Fac. of Inf., Pontifical Catholic Univ. of Rio Grande do Sul, Porto Alegre, Brazil",IEEE,English,1550-6215,978-0-7695-3617-0
IEEE,CBSE: can we count the cost?,"Component-based software engineering (CBSE) offers a new approach to the development of large software-intensive systems. To fully exploit CBSE technology, organisations will need to consider how this technology is best transferred, institutionalised and evolved within the organisation. The author outlines five CBSE technology risk areas and discusses the manner in which metrics could be used to help control the risks and to count the cost of the transfer.",,A. Vickers,1997,Conference,Proceedings Fifth International Symposium on Assessment of Software Tools and Technologies,10.1109/AST.1997.599917,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=599917,"Dept. of Comput. Sci., York Univ., UK",IEEE,English,,0-8186-7940-9
IEEE,Assessing the maintainability benefits of design restructuring using dependency analysis,"Software developers and project managers often have to assess the quality of software design. A commonly adopted hypothesis is that a good design should cost less to maintain than a poor design. We propose a model for quantifying the quality of a design from a maintainability perspective. Based on this model, we propose a novel strategy for predicting the ""return on investment"" (ROI) for possible design restructurings using procedure level dependency analysis. We demonstrate this approach with two exploratory Java case studies. Our results show that common low level source code transformations change the system dependency structure in a beneficial way, allowing recovery of the initial refactoring investment over a number of maintenance activities.",,R. Leitch; E. Stroulia,2003,Conference,Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717),10.1109/METRIC.2003.1232477,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1232477,"MacDonald, Dettwiler & Associates Ltd., Richmond, BC, Canada; NA",IEEE,English,1530-1435,0-7695-1987-3
IEEE,Assessing Overhead Cost Associated with Encrypting Swap File,"Privacy and security of information are two important concerns for most computer users. Passwords, keys, and encrypted information can be found unencrypted in the swap file which is used by the operating systems to support the implementation of virtual memory. Therefore, encrypting the swap file is essential to provide more security of users' private and confidential information. However, encrypting the swap file comes with an extra overhead cost. In this paper, we measure the overhead cost associated with encrypting the swap file. To effectively measure this cost, we developed our own benchmarks that will enforce heavy swapping with disk write and read operations. We measured the overhead cost for Windows 7 operating system. In our measurements, we considered a number of popular encryption algorithms which include AES, Blowfish, Twofish, and GOST. Our experimental measurements show that Windows 7 incurs considerable overhead penalties when encrypting the swap file.",Swap file;Encryption;Operating system security;virtual memory,B. AlBelooshi; K. Salah; T. Marin; A. Bentiba,2012,Conference,"2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications",10.1109/TrustCom.2012.96,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6296101,"Dept. of Electr. & Comput. Eng., Khalifah Univ. of Sci., Technol. & Res., Sharjah, United Arab Emirates; Dept. of Electr. & Comput. Eng., Khalifah Univ. of Sci., Technol. & Res., Sharjah, United Arab Emirates; Dept. of Electr. & Comput. Eng., Khalifah Univ. of Sci., Technol. & Res., Sharjah, United Arab Emirates; Dept. of Electr. & Comput. Eng., Khalifah Univ. of Sci., Technol. & Res., Sharjah, United Arab Emirates",IEEE,English,2324-9013,978-1-4673-2172-3
IEEE,"Estimating the size, cost, and types of Technical Debt",This study summarizes results of a study of Technical Debt across 745 business applications comprising 365 million lines of code collected from 160 companies in 10 industry segments. These applications were submitted to a static analysis that evaluates quality within and across application layers that may be coded in different languages. The analysis consists of evaluating the application against a repository of over 1200 rules of good architectural and coding practice. A formula for estimating Technical Debt with adjustable parameters is presented. Results are presented for Technical Debt across the entire sample as well as for different programming languages and quality factors.,software metrics;software structural quality;technical debt;static analysis;benchmarking,B. Curtis; J. Sappidi; A. Szynkarski,2012,Conference,2012 Third International Workshop on Managing Technical Debt (MTD),10.1109/MTD.2012.6226000,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6226000,"CAST, Fort Worth, Texas, USA; CAST, New York, NY, USA; CAST, Paris, France",IEEE,English,,978-1-4673-1749-8
IEEE,Development and application of composite complexity models and a relative complexity metric in a software maintenance environment,"A great deal of effort is now being devoted to the study, analysis, prediction, and minimization of expected software maintenance cost, long before software is delivered to users or customers. It had been estimated that, on the average, the effort spent on software maintenance is as costly as the effort spent on all other software stages. Ways to alleviate software maintenance complexity and high costs should originate in software design. Two aspects of maintenance deserve attention: protocols for locating and rectifying defects and ensuring that no new defects are introduced in the development phase of the software process, and development of protocols for increasing the quality and reducing the costs associated with modification, enhancement, and upgrading of software. This article focuses on the second aspect and puts forward newly developed parsimonious models and a relative complexity metric for complexity measurement of software that were used to rank the modules in the system relative to each other. Significant success was achieved by use of the models and relative metric to identify maintenance-prone modules.",,J. S. Sherif; J. M. Hops,1996,Conference,Wescon/96,10.1109/WESCON.1996.554559,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=554559,"California State Univ., Fullerton, CA, USA; NA",IEEE,English,1095-791X,0-7803-3274-1
IEEE,Digging the Development Dust for Refactorings,"Software repositories are rich sources of information about the software development process. Mining the information stored in them has been shown to provide interesting insights into the history of the software development and evolution. Several different types of information have been extracted and analyzed from different points of view. However, these types of information have not been sufficiently cross-examined to understand how they might complement each other. In this paper, we present a systematic analysis of four aspects of the software repository of an open source project - source-code metrics, identifiers, return-on-investment estimates, and design differencing - to collect evidence about refactorings that may have happened during the project development. In the context of this case study, we comparatively examine how informative each piece of information is towards understanding the refactoring history of the project and how costly it is to obtain",,C. Schofield; B. Tansey; Zhenchang Xing; E. Stroulia,2006,Conference,14th IEEE International Conference on Program Comprehension (ICPC'06),10.1109/ICPC.2006.18,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1631102,"University of Alberta, Canada; Comput. Sci. Dept., Alberta Univ., Edmonton, Alta.; Comput. Sci. Dept., Alberta Univ., Edmonton, Alta.; Comput. Sci. Dept., Alberta Univ., Edmonton, Alta.",IEEE,English,1092-8138,0-7695-2601-2
IEEE,Activity based software costing,"The study of software economics is not yet mature. For many years, the lines of code (LOG) metrics has tended to conceal major software cost drivers such as the production of requirements, plans, specifications, manuals, and other paper documents. The advent of function point metrics in the late 1970s allowed us to explore the measurement of such noncoding activities, none of which could be properly explored or normalized using LOC metrics. Indeed, we now know that on some projects (such as large defense systems) the cost to produce paper documents is twice as much as the cost to produce the code itself. The ability to measure all activities associated with software production has led to the concept of activity-based studies of software cost. The paper discusses the approach.",,C. Jones,1996,Magazine,Computer,10.1109/2.494092,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=494092,"Software Productivity Res. Inc., Burlington, MA, USA",IEEE,English,1558-0814,
IEEE,Quantitative Modeling of Communication Cost for Global Service Delivery,"IT service providers are increasingly utilizing globally distributed resources to drive down costs, reduce risk through diversification and gain access to a larger talent pool. However, fostering effective collaboration among geographically distributed resources is a difficult challenge. In this paper, we present our initial attempt to quantify the increased overhead in leveraging distributed resources as one of the project costs. We associate this overhead cost measurement with metrics that measure communication quality, such as reduction in productivity and communication delay. These metrics can in turn be computed as functions of underlying project parameters. To achieve this goal, we first build a project communication model (PCM) to categorize different types of collaborative communication. We then represent communication efficiency and changes in resource availability in terms of information theoretic concepts such as reduced channel capacity, information encoding efficiency and channel availability. This analysis is used to help determine the cost associated with team formation and task distribution during the project planning phase.",globalization;communication cost;project management;team structure;communication channel,N. Zhou; Q. Ma; K. Ratakonda,2009,Conference,2009 IEEE International Conference on Services Computing,10.1109/SCC.2009.79,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5283925,"T.J. Watson Res. Center, IBM, Hawthorne, NY, USA; Res. Center, IBM China, Beijing, China; T.J. Watson Res. Center, IBM, Hawthorne, NY, USA",IEEE,English,,978-1-4244-5183-8
IEEE,Systematic Literature Review on Software Effort Estimation Using Machine Learning Approaches,"Accurate effort estimation is amongst the key activities in the software project development. It directly impacts the time and cost of the software projects. This paper presents a systematic literature review of software effort estimation techniques using machine learning. This review presents a discussion about the research trends in machine learning inspired software effort estimation. The results of the systematic review has concluded prominent trends of machine learning approaches, size metrics, benchmark datasets, validation methods etc. used for software effort estimation.",Systematic Literature Review;Effort estimation;Machine learning approaches,P. Sharma; J. Singh,2017,Conference,2017 International Conference on Next Generation Computing and Information Systems (ICNGCIS),10.1109/ICNGCIS.2017.33,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8520309,"Comput. Sci. & Eng., Chitkara Univ., Rajpura, India; Comput. Sci. & Eng., Chitkara Univ., Rajpura, India",IEEE,English,,978-1-5386-4205-4
IEEE,An investigation of code cycles and Poltergeist anti-pattern,"The aim of this paper is to propose a method for detecting the Poltergeist anti-pattern. Anti-patterns are poor designs that lower software quality, especially by increasing complexity and decreasing maintainability. As maintenance of software projects costs as much as their development, it is necessary to detect poorly designed code and refactor it.",anti-patterns;poltergeist;cycle detection,S. R. A. Al-Rubaye; Y. E. Selcuk,2017,Conference,2017 8th IEEE International Conference on Software Engineering and Service Science (ICSESS),10.1109/ICSESS.2017.8342882,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8342882,"Department of Computer Engineering, Yildiz Technical University, Davutpasa, 34220, Istanbul, Turkiye; Department of Computer Engineering, Yildiz Technical University, Davutpasa, 34220, Istanbul, Turkiye",IEEE,English,2327-0594,978-1-5386-0497-7
IEEE,Measuring software product quality: a survey of ISO/IEC 9126,"To address the issues of software product quality, the Joint Technical Committee 1 of the International Organization for Standardization and International Electrotechnical Commission published a set of software product quality standards known as ISO/IEC 9126. These standards specify software product quality's characteristics and subcharacteristics and their metrics. Based on a user survey, this study of the standard helps clarity quality attributes and provides guidance for the resulting standards.",ISO/IEC 9126;software quality model standards,Ho-Won Jung; Seung-Gweon Kim; Chang-Shin Chung,2004,Magazine,IEEE Software,10.1109/MS.2004.1331309,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1331309,"Dept. of Bus. Adm., Korea Univ., Seoul, South Korea; Dept. of Bus. Adm., Korea Univ., Seoul, South Korea; NA",IEEE,English,1937-4194,
IEEE,Reliability of COSMIC Functional Size Measurement Results: A Multiple Case Study on Industry Cases,"Accuracy of the functional size is critical in software project management, since functional size is the most prevalent input for effort and cost estimation models. Functional size measurement is performed based on standardized manuals; however, the accuracy of FSM results is still based on the knowledge and cautions of the measurers. In this study we performed a multiple case study to identify the reliability of COSMIC and to observe the frequently encountered errors during functional size measurement. Problems in the individual learning process and the clarity of the guidelines are distinguished as the two main causes that impact the accuracy of the measurement results.",Functional Size Measurement;COSMIC;Reliability,O. O. Top; O. Demirors; B. Ozkan,2009,Conference,2009 35th Euromicro Conference on Software Engineering and Advanced Applications,10.1109/SEAA.2009.17,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5349939,"Inf. Inst., Middle East Tech. Univ., Ankara, Turkey; Inf. Inst., Middle East Tech. Univ., Ankara, Turkey; Inf. Inst., Middle East Tech. Univ., Ankara, Turkey",IEEE,English,2376-9505,978-0-7695-3784-9
IEEE,An experimental comparison of software effort estimation methods of ORM based 4GL software applications,"Software effort estimation is important in planning and project budgeting for both developers and customers. Although there are many popular effort estimation techniques which have gone through significant developments in the past, software development methodologies and technologies are developing rapidly as a result of the need to improve the existing models. To this end, this paper compares and analyses three popular methods, namely COCOMO II, COSYSMO and Advanced COSTMO-4GL when used with ORM based fourth-generation-language software applications. COSYSMO is found to give better estimation than COSTMO-4GL for both pure 4GL and with ORM components included.",Software Effort Estimation;COCOMO II;COSYSMO;COSTMO-4GL;4GL;Object Relational Mapping,M. Tanrıverdi; Ö. Ö. Tanrıöver,2017,Conference,2017 International Conference on Computer Science and Engineering (UBMK),10.1109/UBMK.2017.8093382,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8093382,"Computer Engineering, Ankara University, Ankara, Turkey; Computer Engineering, Ankara University, Ankara, Turkey",IEEE,English,,978-1-5386-0930-9
IEEE,Early Web size measures and effort prediction for Web costimation,"Size measures for Web costimation proposed in the literature are invariably related to implemented Web applications. Even when targeted at measuring functionality based on function point analysis, researchers only considered the final Web application, rather than requirements documentation generated using any existing Web development methods. This makes their usefulness as early effort predictors questionable. In addition, it is believed that company-specific data provide a better basis for accurate estimates. Many software engineering researchers have compared the accuracy of company-specific data with multiorganisation databases. However the datasets employed were comprised of data from conventional applications. To date no similar comparison has been adopted for Web project datasets. It has two objectives: The first is to present a survey where early size measures for Web costimation were identified using data collected from 133 Web companies worldwide. All companies included in the survey used Web forms to give quotes on Web development projects, based on gathered size measures. The second is to compare the prediction accuracy of a Web company-specific data with data from a multiorganisation database. Both datasets were obtained via Web forms, used as part of a research project called Tukutuku. Our results show that best predictions were obtained for company-specific dataset, for the two estimation techniques employed.",,E. Mendes; N. Mosley; S. Counsell,2003,Conference,Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717),10.1109/METRIC.2003.1232452,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1232452,"Dept. of Comput. Sci., Auckland Univ., New Zealand; NA; NA",IEEE,English,1530-1435,0-7695-1987-3
IEEE,Return on investment of software quality predictions,"Software quality classification models can be used to target reliability enhancement efforts toward high risk modules. We summarize a generalized classification rule which we have proposed. Cost aspects of a software quality classification model are discussed. The contribution of this paper is a demonstration of how to assess the return on investment of model accuracy, in the context of a software quality classification model. An industrial case study of a very large telecommunications system illustrates the method. The dependent variable of the model was the probability that a module will have faults discovered by customers. The independent variables were software product and process metrics. The model is compared to random selection of modules for reliability enhancement. Calculation of return on investment can guide selection of the generalized classification rule's parameter so that the model is well-suited to the project.",,T. M. Khoshgoftaar; E. B. Allen; W. D. Jones; J. P. Hudepohl,1998,Conference,Proceedings. 1998 IEEE Workshop on Application-Specific Software Engineering and Technology. ASSET-98 (Cat. No.98EX183),10.1109/ASSET.1998.688249,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=688249,"Florida Atlantic Univ., Boca Raton, FL, USA; NA; NA; NA",IEEE,English,,0-8186-8582-4
IEEE,Estimation of software defects fix effort using neural networks,"Software defects fix effort is an important software development process metric that plays a critical role in software quality assurance. People usually like to apply parametric effort estimation techniques using historical lines of code and function points data to estimate effort of defects fixes. However, these techniques are neither efficient nor effective for a new different kind of project's fixing defects when code will be written within the context of a different project or organization. In this paper, we present a solution for estimating software defect fix effort using self-organizing neural networks.",,Hui Zeng; D. Rine,2004,Conference,"Proceedings of the 28th Annual International Computer Software and Applications Conference, 2004. COMPSAC 2004.",10.1109/CMPSAC.2004.1342658,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1342658,"Sch. of Inf. & Technol., George Mason Univ., Fairfax, VA, USA; NA",IEEE,English,0730-3157,0-7695-2209-2
IEEE,Analysis of effort estimation based on software project models,"This paper investigates the interrelationship among various measured characteristics of a software project, ranging from project model, size, and metrics used to govern the administration of the project. By analyzing various dimensions of project characteristics based on the underlying model, metrics and project technicality such as language and development paradigm, our findings reveal that certain metrics and models are not suitable for small project since they possess insufficient information to extract and analyze the inherent characteristics of the project. As such, project managers should pay attention to proper selection of project parameters that are conducive toward accurate estimations.",,P. Jodpimai; P. Sophatsathit; C. Lursinsap,2009,Conference,2009 9th International Symposium on Communications and Information Technology,10.1109/ISCIT.2009.5341149,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5341149,"Advanced Virtual and Intelligent Computing (AVIC) Center, Department of Mathematics, Faculty of Science, Chulalongkorn University, Bangkok, Thailand; Advanced Virtual and Intelligent Computing (AVIC) Center, Department of Mathematics, Faculty of Science, Chulalongkorn University, Bangkok, Thailand; Advanced Virtual and Intelligent Computing (AVIC) Center, Department of Mathematics, Faculty of Science, Chulalongkorn University, Bangkok, Thailand",IEEE,English,,978-1-4244-4521-9
IEEE,A Method for Measuring the Size of a Component-Based System Specification,"The system-level size measures are particularly important in software project management as tasks such as planning and estimating the cost and schedule of software development can be performed more effectively when a size estimate of the entire system is available. However, due to the black-box nature of components, traditional software measures are not adequate as system-level measures for component-based systems (CBS). Thus, if a system-level size is required, alternate measures should be used for sizing CBS. In this paper, we present a function point like approach, named component point to measure the system-level size of a CBS using the CBS specification written in UML. The component point approach integrates two software measures and extends an existing size measure from the more matured object-oriented paradigm to the related and relatively young CBS discipline. We also suggest a customized set of general system characteristics so as to make our measure more relevant to CBS.",Software Size Estimation;Software Effort Estimation;Software Measurement;Component Point;Component-Based Systems;Component-Based Software Development;Function Point extension,T. Wijayasiriwardhane; R. Lai,2008,Conference,2008 The Eighth International Conference on Quality Software,10.1109/QSIC.2008.17,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4601562,"Dept. of Comput. Sci. & Comput. Eng., La Trobe Univ., Melbourne, VIC; Dept. of Comput. Sci. & Comput. Eng., La Trobe Univ., Melbourne, VIC",IEEE,English,2332-662X,978-0-7695-3312-4
IEEE,Applicability of Neural Network Based Models for Software Effort Estimation,"Effort Estimation is a very challenging task in the software development life cycle. Inaccurate estimations may cause the client dissatisfaction and thereby, decrease the quality of the product. Considering the problem of software cost and effort prediction, it is conceivable to call attention to that the estimation procedure considers the qualities present in the data set, as well as the aspects of the environment in which the model is embedded. Existing literatures have the instances where machine learning techniques such as Linear Regression (LR), Support Vector Machine (SVM), K-Nearest Neighbor (KNN) have been used to estimate the effort required to develop any software. Yet it is quite uncertain for any particular model to perform well with all the data sets. Most of the research is based on the dataset of any single organization. Consequently, the results obtained through these models cannot be generalized. So, the main objectives of this research are: i) to use different data preparation techniques such as selection, cleaning, and transformation to improve the quality of data set given to the model ii) to use other machine learning models such as Multi-Layer Perceptron Neural Network (MLPNN), Probabilistic Neural Network (PNN), and Recurrent Neural Network (RNN) to increase the performance of software effort estimation process iii) to use different optimization techniques to tune the parameters of machine learning models iv) to use ensemble methods to improve the accuracy of software effort estimation process. In this study, first, we found out the most influential attributes in the Desharnais data set, then, MLPNN has been applied on reduced data set with to improve the accuracy of software effort estimation. Then, the performance of the MLPNN model is compared with LR, SVM and KNN models in the literature to find the best model fitting this dataset. Results obtained from the study demonstrate that some of the variables are more important in comparison to others for effort estimation. Also among the various models used in this study, the best-obtained R2 value is 79 % for the MLPNN model.",Machine Learning;Software Metrics;Predictive Model;Effort Estimation,S. Shukla; S. Kumar,2019,Conference,2019 IEEE World Congress on Services (SERVICES),10.1109/SERVICES.2019.00094,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8817057,Indian Institute of Technology Roorkee; Indian Institute of Technology Roorkee,IEEE,English,2642-939X,978-1-7281-3851-0
IEEE,The development of method of the enhancement of Technical Factor (TF) and Environmental Factor (EF) to the Use Case Point (UCP) to calculate the estimation of software's effort,"Use Case Point (UCP) is one of many approaches used for software project estimation. This approach is implemented by calculating effort estimation based on prediction a total number of workers and software development time. UCP was fist introduced by Karner on 1993. This approach is widely used. It was because some research on UCP showed that UCP approach is better than those approaches developed by experts. The calculation of effort estimation that was mentioned in the paper (Chetan Nagar, 2011), it has been proven that calculation estimation using UCP sometimes doesn't fit the real effort. This leads to the difference in cost calculation and a total number of workers on software development project. The difference in effort calculation is maybe caused by the lack of consideration factors that was calculated on UCP. Besides, in the case of software development project, there must be so many factors that must be taken into consideration in UCP calculation. Based on those backgrounds, this paper will explain the way to minimize the difference between actual effort and effort estimation by increasing Technical Complexity Factor (TCF) and Environmental Complexity Factor (ECF) in estimation using UCP. Those factors are added by considering two ways (1) adding drive cost factor in COCOMO II that is mapped to TFC and ECF (2) conducting qualitative research by deeply understanding a problem in developing software. The result of estimation deviation using old UCP approach is 6.19% on project 1 and 39.32% on project 2 while the result of estimation deviation using new UCP approach is 5.02% on project 1 and 7.94% on project 2. The results showed that the decrease of deviation is too large in project 1 (on a middle scale), besides on project with smaller scale, the decrease of deviation can be much larger. Because of that, TF and EF involvement are effective enough to be implemented on the calculation of project a small scale. Beside of that, it is proven that the new UCP is better to be implemented in software development project effort estimation.",Use Case Point (UCP);Effort Estimation;COCOMO;TCP (Technical Complexity Factors);ECF (Enviromental Complexity Factor),Sarwosri; M. J. Al Haiyan; M. Husein; A. Putra Ferza,2016,Conference,2016 International Conference on Information & Communication Technology and Systems (ICTS),10.1109/ICTS.2016.7910299,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7910299,"Informatics Department, Faculty of Information Technology, Institut Teknologi Sepuluh Nopember (ITS), St. Arief Rahman Hakim, Surabaya 60111 Indonesia; Informatics Department, Faculty of Information Technology, Institut Teknologi Sepuluh Nopember (ITS), St. Arief Rahman Hakim, Surabaya 60111 Indonesia; Informatics Department, Faculty of Information Technology, Institut Teknologi Sepuluh Nopember (ITS), St. Arief Rahman Hakim, Surabaya 60111 Indonesia; Informatics Department, Faculty of Information Technology, Institut Teknologi Sepuluh Nopember (ITS), St. Arief Rahman Hakim, Surabaya 60111 Indonesia",IEEE,English,2338-185X,978-1-5090-1381-4
IEEE,Constructing C++ software size estimation model from class diagram,"Software size is one of the most important internal attributes of software product. The information obtained from estimating software size will be useful for planning about effort, cost and activities schedule of later phases. This paper proposes an approach for constructing C++ software size estimation model using a statistical technique called Multiple linear regression analysis. The proposed model is constructed from structural complexity metrics that can be measured from class diagram. The paper also presents an automated tool for measuring these metrics, and in effect, estimating the C++ software size.",size estimation model;structural complexity metric;class diagram,M. Kiewkanya; S. Surak,2016,Conference,2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE),10.1109/JCSSE.2016.7748880,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7748880,"Department of Computer Science, Faculty of Science Chiang Mai University, Thailand; Department of Computer Science, Faculty of Science Chiang Mai University, Thailand",IEEE,English,,978-1-5090-2033-1
IEEE,A survey on software estimation in the Norwegian industry,"We provide an overview of the estimation methods that software companies apply to estimate their projects, why those methods are chosen, and how accurate they are. In order to improve estimation accuracy, such knowledge is essential. We conducted an in-depth survey, where information was collected through structured interviews with senior managers from 18 different companies and project managers of 52 different projects. We analyzed information about estimation approach, effort estimation accuracy and bias, schedule estimation accuracy and bias, delivered functionality and other estimation related information. Our results suggest, for example, that average effort overruns are 41%, that the estimation performance has not changed much the last 10-20 years, that expert estimation is the dominating estimation method, that estimation accuracy is not much impacted by use of formal estimation models, and that software managers tend to believe that the estimation accuracy of their company is better than it actually is.",,K. Moloekken-OEstvold; M. Joergensen; S. S. Tanilkan; H. Gallis; A. C. Lien; S. W. Hove,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357904,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357904,"Simula Res. Lab., Lysaker, Norway; Simula Res. Lab., Lysaker, Norway; NA; NA; NA; NA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,Reuse in Systems Engineering,"Reuse in systems engineering is a frequent but poorly understood phenomenon. Nevertheless, it has a significant impact on system development and on estimating the appropriate amount of systems engineering effort with models like the Constructive Systems Engineering Cost Model (COSYSMO). Practical experience showed that the initial version of COSYSMO, based on a “build from the scratch” philosophy, needed to be refined in order to incorporate reuse considerations that fit today's industry environment. The notion of reuse recognizes the effect of legacy system definition in engineering a system and introduces multiple reuse categories for classifying the four COSYSMO size drivers-requirements, interfaces, algorithms, and operational scenarios. It fundamentally modifies the driver counting rules and updates its definition of system size. It provides an enabling framework for estimating a system under incremental and spiral development. In this paper, we present: 1) the definition of the COSYSMO reuse extension and the approach employed to define this extension; 2) the updated COSYSMO size driver definitions to be consistent with the reuse model; 3) the method applied to defining the reuse weights used in the modified parametric relationship; 4) a practical implementation example that instantiates the reuse model by an industry organization and the empirical data that provided practical validation of the extended COSYSMO model; and 5) recommendations for organizational implementation and deployment of this extension.",Cost estimation;metrics;reuse;systems engineering,G. Wang; R. Valerdi; J. Fortune,2010,Journal,IEEE Systems Journal,10.1109/JSYST.2010.2051748,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5492294,"BAE Systems, Reston, VA, USA; Engineering Systems Division, Massachusetts Institute of Technology, Cambridge, MA, USA; Center for Systems and Software Engineering, University of Southern California, Los Angeles, CA, USA",IEEE,English,1937-9234,
IEEE,Design for testability in embedded software projects,"The purpose of this white paper is to focus on design techniques or methodologies that add testability features to embedded software which is an integral and important process for verification of any safety critical system. This paper presents testability in two forms: software testability i.e. testability at code level and design testability: i.e. testability at software requirements level. The two testability forms are further classified into subtypes explained in detail with examples which cite issues that are faced by engineers while performing verification. In this paper I have also come up with metrics which could become an important criterion in calculating the testability of a system considering the number of inputs that can be driven and the outputs that can be observed in the software during the verification process. Practical usage of these metrics may help designers understand how testable the system they have designed is, thus reducing verification effort and project cost. Good testability features, if not present in a system, may lead to increased cost and completion period of the project at a time when cost reduction and deadline chasing is the key to winning future projects. This paper endeavors to provide software developers guidance to incorporate important testability features into the software during the design and coding phase.",,G. Sahay,2011,Conference,2011 IEEE/AIAA 30th Digital Avionics Systems Conference,10.1109/DASC.2011.6096129,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6096129,"India Design Centre, Goodrich Aerospace, Bangalore, Karnataka, India",IEEE,English,2155-7209,978-1-61284-798-6
IEEE,Improving subjective estimates using paired comparisons,"Despite the existence of structured methods for software sizing and effort estimation, the so-called ""expert"" approach seems to be the prevalent way to produce estimates in the software industry. This article presents a method based on paired comparisons, which social science researchers use for measuring when there is no accepted measurement scale or when a measurement instrument does not exist. Although not new, the idea has received little attention in the literature.",,E. Miranda,2001,Magazine,IEEE Software,10.1109/52.903173,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=903173,,IEEE,English,1937-4194,
IEEE,Understanding and predicting the process of software maintenance releases,"One of the major concerns of any maintenance organization is to understand and estimate the cost of maintenance releases of software systems. Planning the next release so as to maximize the increase in functionality and the improvement in quality are vital to successful maintenance management. The objective of the paper is to present the results of a case study in which an incremental approach was used to better understand the effort distribution of releases and build a predictive effort model for software maintenance releases. The study was conducted in the Flight Dynamics Division (FDD) of NASA Goddard Space Flight Center (GSFC). The paper presents three main results: (1) a predictive effort model developed for the FDD's software maintenance release process, (2) measurement-based lessons learned about the maintenance process in the FDD, (3) a set of lessons learned about the establishment of a measurement-based software maintenance improvement program. In addition, this study provides insights and guidelines for obtaining similar results in other maintenance organizations.",,V. Basili; L. Briand; S. Condon; Yong-Mi Kim; W. L. Melo; J. D. Valen,1996,Conference,Proceedings of IEEE 18th International Conference on Software Engineering,10.1109/ICSE.1996.493441,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=493441,"Inst. for Adv. Comput. Studies, Maryland Univ., College Park, MD, USA; NA; NA; NA; NA; NA",IEEE,English,0270-5257,0-8186-7247-1
IEEE,Comparative review of functional complexity assessment methods for effort estimation,"Budgetary constraints are placing increasing pressure on project managers to effectively estimate development effort requirements at the earliest opportunity. With the rising impact of automation on commercial software development, the attention of researchers developing effort estimation models has recently been focused on functional representations of systems, in response to the assertion that development effort is a function of specification content. A number of such models exist; several, however, have received almost no research or industry attention. Project managers wishing to implement a functional assessment and estimation programme are therefore unlikely to be aware of the various methods or how they compare. This paper therefore provides this information, as well as forming a basis for the development and improvement of new methods.<>",,S. G. MacDonell,1994,Journal,Software Engineering Journal,10.1049/sej.1994.0014,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=295067,"Dept. of Inf. Sci., Otago Univ., Dunedin, New Zealand",IET,English,0268-6961,
IEEE,Investigation of logistic regression as a discriminant of software quality,"Investigates the possibility that logistic regression functions (LRFs), when used in combination with Boolean discriminant functions (BDFs), which we had previously developed, would improve the quality classification ability of BDFs when used alone; this was found to be the case. When the union of a BDF and LRF was used to classify quality, the predictive accuracy of quality and inspection cost was improved over that of using either function alone for the Space Shuttle. Also, the LRFs proved useful for ranking the quality of modules in a build. The significance of these results is that very high-quality classification accuracy (1.25% error) can be obtained while reducing the inspection cost incurred in achieving high quality. This is particularly important for safety-critical systems. Because the methods are general and not particular to the Shuttle, they could be applied to other domains. A key part of the LRF development was a method for identifying the critical value (i.e. threshold) that could discriminate between high and low quality, and at the same time constrain the cost of inspection to a reasonable value.",,N. F. Schneidewind,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915540,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915540,"Naval Postgraduate Sch., Monterey, CA, USA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,A metric method for object-oriented systems based on MarkII method,"MarkII method is a function point method. It is primarily based on Reporting Requirements, but the MarkII method exists measuring problems: less data and poor accuracy. After analyzing the MarkII method and semantics of the main components of UML model, a method which applies MarkII method to measure the scale of the object-oriented system is proposed by establishing correspondence relationship and mapping rules between them. To verify the feasibility of this method, we design and develop a measure tool. Experimental results show that the proposed method can effectively measure the scale of the object-oriented system, and achieve significantly improved accuracy and automation.",MarkII method;UML model;Measure rules;Mapping rules;Measure tool,J. Fubo; Z. Yi; L. Huijun; C. Lu; L. Jiawei,2014,Conference,2014 IEEE 7th Joint International Information Technology and Artificial Intelligence Conference,10.1109/ITAIC.2014.7065114,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7065114,"Key Laboratory of Software Theory and Technology, College of Computer Science, Chongqing University, Chongqing, China; Key Laboratory of Software Theory and Technology, College of Computer Science, Chongqing University, Chongqing, China; Key Laboratory of Software Theory and Technology, College of Computer Science, Chongqing University, Chongqing, China; Key Laboratory of Software Theory and Technology, College of Computer Science, Chongqing University, Chongqing, China; Key Laboratory of Software Theory and Technology, College of Computer Science, Chongqing University, Chongqing, China",IEEE,English,,978-1-4799-4419-4
IEEE,Software Fault Prediction Using Artificial Intelligence Techniques,"Detecting faults in the initial stage of the development process has become an important prospect for the codes cost estimation; so a fault predictor model is very much necessary in order to bring down the cost of development and maintenance. Due to these reasons, developing models for fault prediction has become a crucial part of research, and various techniques have been adapted in order to predict faults in a software. Few of them include Artificial Neural Network, Decision Tree, Genetic Algorithm, etc. Among these techniques, Neural Networks and Genetic Algorithms have become a growing concern over the years and are being applied in various fields such as optimization, prediction or classification. These techniques make use of various software metrics to assess the characteristic of any software system such as number of faults, maintenance of class, etc. Most commonly used are Chidamber and Kemerer (CK) metrics which are found to be efficient from many researches.",Artificial Neural Network;Back Propagation;Chi-damber and Kemerer suite of metrics;Genetic Algorithm,A. Haveri; Y. Suresh,2017,Conference,2017 2nd International Conference on Computational Systems and Information Technology for Sustainable Solution (CSITSS),10.1109/CSITSS.2017.8447615,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8447615,"Department of Computer Science and Engineering, BMS Institute of Technology & Management, Bengaluru, 560064, India; Dept. of Comput. Sci. & Eng., BMS Inst. of Technol. & Manage., Bangalore, India",IEEE,English,,978-1-5386-2044-1
IEEE,Lattice LSTM Model for Function Point Based Software Cost Measurement,"One of the core problems in the field of software engineering is to measure the software development cost, which helps to ensure the software quality and avoid the waste of investment. Traditionally, the software cost measurement is implemented by experts who are strictly trained, which is relatively expensive and inefficient. In this paper, a neural network based machine learning method is proposed to perform software cost measurement task, which decreases the time and manpower costs. The proposed method takes advantage of the long short term memory (LSTM) neural network and conditional random field to identify different types of function points in software requirements document, where the function points is the key to measure to software cost. To solve the incorrect word segmentation problem in open domain such as software development cost field, lattice LSTM model is constructed to utilize both Chinese characters and words information. Experiments show the proposed method significantly reduces the human labor and ensure the quality of software cost measurement.",software cost measurement;machine learning;lattice LSTM model1,M. Qin,2019,Conference,2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),10.1109/ITAIC.2019.8785888,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8785888,"Information and Communication Department, Electric Power Research Institute Co., Ltd, Beijing, China",IEEE,English,,978-1-5386-8178-7
IEEE,Software Effort Estimation Based on Use Cases,"Software effort and cost estimation is a very important activity that includes very uncertain elements. In the context of object oriented software, traditional methods and metrics were extended to help managers in this activity. The metric use case points (UCP) is an example of metric that can be used. UCP considers functional aspects of the use case (UC) model, widely used in most organizations in the early phases of the development. However, the metric UCP presents some limitations mainly related to the granularity of the UC. To overcome these limitations, this paper introduces two metrics, also based on UCs. The first one, named USP (use case size points), considers the internal structures of the UC and better captures its functionality. The second one, named FUSP (fuzzy use case size points), considers concepts of the fuzzy set theory to create gradual classifications that better deal with uncertainty. Results from an empirical evaluation show the applicability and some advantages of the proposed metrics",Software Size;Prediction;Use Case Points;Function Points;Fuzzy Theory,M. R. Braz; S. R. Vergilio,2006,Conference,30th Annual International Computer Software and Applications Conference (COMPSAC'06),10.1109/COMPSAC.2006.77,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4020081,"Federal University of Parana - UFPR, Brazil; Federal University of Parana - UFPR, Brazil",IEEE,English,0730-3157,0-7695-2655-1
IEEE,Estimated measurement quality software on structural model academic system with Function Point Analysis,"In the software development indispensable is the suitability and accuracy in determining the size or value of the software to fit the operation to be performed. A wide variety of calculation methods have been widely used to estimate the size of the software, one of which is by using Function Point Analysis (FPA). Volume calculation software based on a scale of complexity. Since the point of measurement is highly subjective, in order to maintain consistency and validity of the results, the method should be run by an experienced professional. This method is then applied by the authors to measure the complexity of academic information system STIKOM Dinamika Bangsa Jambi using structured modeling approach. Measurements were performed in this study consisted of depictions information system is built into the structure. Which is then analyzed by counting models Crude Function Points (CRP), the relative complexity of Adjustment Factor (RCAF), and then calculate the point function. From the results of calculations using the FPA to software quality measurement academic system STIKOM Dinamika Bangsa Jambi obtained value FP 166.32 is good. Function point value produced will be used by developers in determining the price and the cost of software systems to be built or developed.",Software Quality Measurement;Structural Model;Function Point Analysis;System,H. Rohayani; F. L. Gaol; B. Soewito; H. L. H. Spits Warnars,2017,Conference,2017 International Conference on Applied Computer and Communication Technologies (ComCom),10.1109/COMCOM.2017.8167085,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8167085,"Doctor of Computer Science Program, Bina Nusantara University, Jl. Kebon Jeruk No 27, Jakarta. Indonesia; Doctor of Computer Science, Bina Nusantara University, Jl. Kebon Jeruk No27, Jakarta. Indonesia; Binus Graduate Program, Bina Nusantara University, Jl. Kebon Jeruk No27, Jakarta. Indonesia; Doctor of Computer Science, Bina Nusantara University, Jl. Kebon Jeruk No27, Jakarta. Indonesia",IEEE,English,,978-1-5090-4048-3
IEEE,Applying function point to unified modeling language: conversion model and pilot study,"We consider convertibility of the elements of the unified modeling language into entities of the function point analysis, introduces a model for establishing the link, and presents a pilot study for comparing the function point counts provided by the model with those provided by a function point certified expert. In order to map the unified modeling language elements to function point analysis entities, the paper develops guidelines, rules, heuristics, and flexibility specifications, which also constitute the requirements of an analyzer and semiautomatic converter, implemented as a wizard inside IBM-Rational Rose. The paper presents and discusses the design, conduction and results of the pilot study.",,G. Cantone; D. Pace; G. Calavaro,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357912,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357912,"DISP, Rome Univ., Italy; DISP, Rome Univ., Italy; NA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,Comparing Software Cost Prediction Models by a Visualization Tool,"A crucial issue in the software cost estimation area that has attracted the interest of software project managers is the selection of the best prediction method for estimating the cost of a project. Most of the prediction techniques estimate the cost from historical data. The selection of the best model is based on accuracy measures that are functions of the predictive error, whereas the significance of the differences can be evaluated through statistical procedures. However, statistical tests cannot be applied easily by non-experts while there are difficulties in the interpretation of their results. The purpose of this paper is to introduce the utilization of a visualization tool, the regression error characteristic curves in order to compare different prediction models easily, by a simple inspection of a graph. Moreover, these curves are adjusted to accuracy measures appeared in software cost estimation literature and the experimentation is based on two well-known datasets.",,N. Mittas; L. Angelis,2008,Conference,2008 34th Euromicro Conference Software Engineering and Advanced Applications,10.1109/SEAA.2008.23,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4725751,"Dept. of Inf., Aristotle Univ. of Thessaloniki, Thessaloniki, Greece; Dept. of Inf., Aristotle Univ. of Thessaloniki, Thessaloniki, Greece",IEEE,English,2376-9505,978-0-7695-3276-9
IEEE,Software reuse metrics for object-oriented systems,"The importance of software measurement is increasing leading to development of new measurement techniques. Reusing existing software components is a key feature in increasing software productivity. It is one of the key elements in object-oriented programming, which reduces the cost and increases the quality of the software. An important feature of C++ called templates support generic programming, which allows the programmer to develop reusable software modules such as functions, classes, etc. The need for software reusability metrics is particularly acute for an organization in order to measure the degree of generic programming included in the form of templates in code. This research addresses this need and introduces a new set of metrics for object-oriented software. Two metrics are proposed for measuring amount of genericty included in the code and then analytically evaluated against Weyuker's set of nine axioms. This set of metrics is then applied to standard projects and accordingly ways in which project managers can use these metrics are suggested.",,K. K. Aggarwal; Y. Singh; A. Kaur; R. Malhotra,2005,Conference,"Third ACIS Int'l Conference on Software Engineering Research, Management and Applications (SERA'05)",10.1109/SERA.2005.60,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1563143,"Sch. of Inf. Technol., GGS Indraprastha Univ., Delhi, India; Sch. of Inf. Technol., GGS Indraprastha Univ., Delhi, India; Sch. of Inf. Technol., GGS Indraprastha Univ., Delhi, India; Sch. of Inf. Technol., GGS Indraprastha Univ., Delhi, India",IEEE,English,,0-7695-2297-1
IEEE,Influence of the Review of Executed Activities Utilizing Planning Poker,"Background -- The software effort estimation research area aims to improve the accuracy of this estimation in software projects and activities. Aims -- This study describes the development and usage of a web application to collect the generated data from the Planning Poker estimation process and the analysis of the collected data to investigate the impact of revising previous estimates when conducting similar new estimates in a Planning Poker context. Method -- Software activities were estimated by UTFPR students, using Planning Poker, with and without revising previous similar activities, storing data regarding the decision-making process. And the collected data was used to investigate the impact that revising similar executed activities have in the software effort estimates' accuracy. Obtained Results -- The UTFPR students were divided into 14 groups. Eight of them showed accuracy increase in more than half of their estimates. Three of them had almost the same accuracy in more than half of their estimates. And only three of them had accuracy decrease in more than half of their estimates. Conclusion -- Reviewing the similar executed software activities, when using Planning Poker, led to more accurate software estimates in most cases, and, because of that, can improve the software development process.",Software Metrics;Software Effort Prediction;Software Effort Estimate;Software Costs Prediction;Software Costs Estimate;Software Process Management,A. A. Tissot; M. C. Figueiredo Pereira Emer; L. C. Bastos,2015,Conference,2015 29th Brazilian Symposium on Software Engineering,10.1109/SBES.2015.26,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7328021,"Departamento de Informática (DAINF), Universidade Tecnológica Federal do Paraná (UTFPR), Curitiba, Brazil; Departamento de Informática (DAINF), Universidade Tecnológica Federal do Paraná (UTFPR), Curitiba, Brazil; Departamento de Informática (DAINF), Universidade Tecnológica Federal do Paraná (UTFPR), Curitiba, Brazil",IEEE,English,,978-1-4673-9272-3
IEEE,Adapting function point analysis to estimate data mart size,"To better control the time, cost and resources assigned to software projects, organizations need a proper estimate of their size even before the projects actually start. Accordingly, several approaches were proposed to estimate the size of a software project, as the well-known function point analysis (FPA), which is largely used in traditional software development projects. However, we observed in our company that it is not fit for data mart software measurement. Data mart (DM) systems have particularities in their development that are different from the traditional software systems (e.g. a DM uses other software systems as data sources and does not create new information). It is important, therefore, to have a measurement approach that considers those particularities while measuring the DM size. We present an adaptation of the FPA approach for DM size measurement and discuss results on 10 data marts project developed in the industry.",,A. T. Calazans; K. M. de Oliveira; R. R. Santos,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357914,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357914,"Caixa Economica Fed., Brazil; NA; NA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,Measurement of QuestDone mobile application using 7 steps use case points method,"The rise of mobile application is inevitable. Every year, the number of mobile application is increased. It is important for mobile application project owners to calculate the required resources before building a mobile application. In software metric, Use Case Points method is able to count software size of mobile application based on their functionality. This method utilizes use case diagram as their computation factors in the estimation process. Moreover, two other complexity factors are also considered in this method, which are: Technical Complexity Factor and Environment Factor. In this paper, we present software size calculation of QuestDone Mobile Application using 7 steps use case points method. QuestDone has been implemented, but we do not know its software size (i.e. how big the software, how much it cost, how many people is needed). As the result from use case points method, the Use Case Points value of QuestDone is 126.88 with Effort Estimation equal to 889 hours. The software size estimation process of QuestDone Mobile Application detailed in this paper can give an insight to project owners to count software size of other similar projects.",software size;software metrics;use case points;mobile application,R. Sutoyo; H. L. Hendric Spits Warnars; F. L. Gaol; E. Abdurachman; B. Soewito,2017,Conference,2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom),10.1109/CYBERNETICSCOM.2017.8311690,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8311690,"Computer Science Department, BINUS Graduate, Program - Doctor of Computer Science, Bina Nusantara University Jakarta, Indonesia 11480; Computer Science Department, BINUS Graduate, Program - Doctor of Computer Science, Bina Nusantara University Jakarta, Indonesia 11480; Computer Science Department, BINUS Graduate, Program - Doctor of Computer Science, Bina Nusantara University Jakarta, Indonesia 11480; Computer Science Department, BINUS Graduate, Program - Doctor of Computer Science, Bina Nusantara University Jakarta, Indonesia 11480; Computer Science Department, BINUS Graduate Program - Master of Computer Science Bina Nusantara University Jakarta, Indonesia 11480",IEEE,English,,978-1-5386-0784-8
IEEE,Applying metrics to rule-based systems,"Since the introduction of software measurement theory in the early seventies it has been accepted that in order to control software it must first be measured. Unambiguous and reproducible measurements are considered to be the most useful in controlling software productivity, costs and quality, and diverse sets of measurements are required to cover all aspects of software. This paper focuses on measures for rule-based language systems and also describes a process for developing measures for other non-standard 3GL development tools. This paper uses KEL as an example and the method allows the re-use of existing measures and indicates if and where new measures are required. As software engineering continues to generate more diverse methods of system development, it is important to continually update methods of measurement and control.<>",,P. Doyle; R. Verbruggen,1992,Conference,Proceedings Fourth International Conference on Software Engineering and Knowledge Engineering,10.1109/SEKE.1992.227938,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=227938,"Sch. of Comput. Applications, Dublin City Univ., Ireland; Sch. of Comput. Applications, Dublin City Univ., Ireland",IEEE,English,,0-8186-2830-8
IEEE,A study of productivity and efficiency for object-oriented methods and languages,"A study was commissioned by the Hughes Space and Communications Software Engineering Group to determine the effectiveness of the recent introduction of object-oriented languages, technologies and development methodologies. Of particular interest was any effect on development productivity. Fundamentally, productivity metrics are difficult to apply across non-homogeneous projects and development teams. Furthermore, owing to many uncontrolled variables, such as the lack of a solid control project and non-rigorously collected data, productivity measures alone are were sufficient to determine meaningful results as requested for the study. A new, robust means of comparing non-homogenous development efforts (that does not require a control project) called ""efficiency"" was introduced and was used to augment the comparative analysis of the projects and address possible concerns with the use of productivity metrics alone. Efficiency measures the actual effort compared to an estimate of that effort with respect to an independent and well-defined baseline - for purposes of the study, this was COCOMO II. Conclusive evidence was found to support the hypothesis that object-oriented languages coupled with object-oriented methods result in greater productivity and efficiency as compared to other efforts. Furthermore, it is concluded that efficiency metrics, along with the non-standard use of COCOMO II, are a meaningful, useful and practical approach to compare development efforts.",,D. Port; M. McArthur,1999,Conference,Proceedings Sixth Asia Pacific Software Engineering Conference (ASPEC'99) (Cat. No.PR00509),10.1109/APSEC.1999.809593,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809593,"Center for Software Eng., Univ. of Southern California, Los Angeles, CA, USA; NA",IEEE,English,,0-7695-0509-0
IEEE,Using a Line of Code Metric to Understand Software Rework,"A simple method measuring new effective lines of code showed that between 19 and 40 percent of code written on three projects wasn't in the final release. Generally, productivity is a function of input effort and output size. A strong understanding of software productivity, coupled with a good estimate of software size, is key to predicting project effort and, ultimately, producing reliable project duration estimates, schedules, and resource needs. Project managers and engineers often measure or predict the size of released software-the volume of software in the marketed product. However, the final release doesn't include reworked code-code that was changed or deleted during development.",lines of code;software productivity;software rework;software;software engineering,E. Morozoff,2010,Magazine,IEEE Software,10.1109/MS.2009.160,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5232799,"Medtronic, Inc. , Mounds View",IEEE,English,1937-4194,
IEEE,Information technology and software project management: Advanced undergraduate/graduate laboratory practicum,"A convergence of computer science (CS)/computer information systems (CIS) and management areas, in general, and, software development/software engineering and management, in particular, is quickly reshaping a profile of the software development industry. This motivated the Department of Computer Science and Information Systems at Bradley University (Peoria, IL) to propose, design, and develop innovative curriculum in CS-Management and CIS-Management areas. The developed state-of-the-art courseware in those areas is based on active utilization of software and CIS engineering concepts, methods, models, approaches, factors, and metrics in traditional (defined by Project Management Institute) project management processes and knowledge areas, particularly, 1) applications of software engineering methods and models to traditional five project management processes and nine knowledge areas; 2) utilization of software development life cycle stages in traditional project management life cycle; 3) applications of software/CIS specific estimation models and methodologies to traditional cost and time management; 4) utilization of specific software quality metrics and factors (ISO 9126) in traditional quality management; and 5) utilization of software-focused quality methodology (CMMI, DFSS) in software and CIS project management.",computer science;software project management;computer information systems;information technology project management;innovative curriculum,V. Uskov; K. Mittal,2012,Conference,2012 IEEE International Conference on Electro/Information Technology,10.1109/EIT.2012.6220773,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6220773,"Department of Computer Science and Information Systems, Bradley University; Department of Computer Science and Information Systems, Bradley University",IEEE,English,2154-0373,978-1-4673-0818-2
IEEE,Improvements to the Function Point Analysis Method: A Systematic Literature Review,"Function point analysis (FPA) is a standardized method to systematically measure the functional size of software. This method is proposed by an international organization and it is currently recommended by governments and organizations as a standard method to be adopted for this type of measurement. This paper presents a compilation of improvements, focused on increasing the accuracy of the FPA method, which have been proposed over the past 13 years. The methodology used was a systematic literature review (SLR), which was conducted with four research questions aligned with the objectives of this study. As a result of the SLR, of the 1600 results returned by the search engines, 454 primary studies were preselected according to the criteria established for the SLR. Among these studies, only 18 specifically referred to accuracy improvements for FPA, which was the goal of this study. The low number of studies that propose FPA improvements might demonstrate the maturity of the method in the current scenario of software metrics. Specifically in terms of found issues, it was found that the step for calculating the functional size exhibited the highest number of problems, indicating the need to revise FPA in order to encompass the possible improvements suggested by the researchers.",Accuracy improvement;function point analysis (FPA);systematic literature review (SLR);Accuracy improvement;function point analysis (FPA);systematic literature review (SLR),M. de Freitas Junior; M. Fantinato; V. Sun,2015,Journal,IEEE Transactions on Engineering Management,10.1109/TEM.2015.2453354,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7165621,"School of Sciences, Arts and Humanities, University of São Paulo, Sao Paulo, Brazil; School of Sciences, Arts and Humanities, University of São Paulo, Sao Paulo, Brazil; School of Sciences, Arts and Humanities, University of São Paulo, Sao Paulo, Brazil",IEEE,English,1558-0040,
IEEE,A Follow-Up Reflection on Software Process Improvement ROI,"Our discipline must shift toward value-based software engineering, because we're obliged to prove our contributions to the financial bottom line. In the May/June 2004 IEEE Software special issue on return on investment (ROI), the author presented measurement results for the ROI of software process improvement (SPI). This article made three main contributions. First, provided a detailed overview of publications containing real-life measurement results from practical applications of SPI, in which the author measured the ROI. My study included 20 cases, with an average ROI of 7 and a median of 6.6. This indicates that SPI's net profit seems to be approximately US$7 for every dollar invested. However, I found no published cases in which SPI investments resulted in a measurable loss; furthermore, the ROI bandwidth was large (between 1.5 and 19). This indicates that the actual ROI of an SPI investment seems hard to really guarantee up front. Second, I showed that benefits are just as easy to quantify as costs. Cost measurements are always based on an agreement about how to measure and quantify costs. Such an agreement can also serve as the basis for measuring benefits. My article contained data from two real-life projects that had made such cost and benefit measurements and calculated ROI. Finally, I concluded that expressing ""value"" is crucial. Software engineering and its improvement are often major investments for organizations. Investments must be profitable. Because different people in different roles share one generic term for value-money, I recommended expressing any software engineering effort and its benefits in financial terms.",software process improvement;return on investment;value-based software engineering;Six Sigma;management commitment;benefit measurement,R. van Solingen,2009,Magazine,IEEE Software,10.1109/MS.2009.120,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5222799,Delft University of Technology,IEEE,English,1937-4194,
IEEE,Software cost estimation models,"The importance of accurate cost estimates is discussed, and an overview of the existing methods for cost estimation is given. One class of models, namely, the parametric models, is then considered. The principles of parametric cost estimation models are examined, and an overview of such model is given. The existing models are compared, focusing mainly on the question of how accurate their estimates are. The advantages of the parametric models are described, and the state of the art is evaluated.<>",,F. J. Heemstra,1990,Conference,"Proceedings of the 5th Jerusalem Conference on Information Technology, 1990. 'Next Decade in Information Technology'",10.1109/JCIT.1990.128297,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=128297,"Dept. of Ind. Eng., Univ. of Technol., Eindhoven, Netherlands",IEEE,English,,0-8186-2078-1
IEEE,Project estimation using Screenflow Engineering,"Software project estimation is a topic that has been widely researched, yielding a multitude of different estimation models, tools and techniques aimed at increasing the accuracy of cost, effort and time estimates of proposed software projects. However, surveys in the United Kingdom, The Netherlands and New Zealand have identified a very low use of such models and tools, despite recognition of their importance. This paper introduces a method of software project estimation used in a New Zealand case. The method used is part of the Screenflow Engineering process. This is based on the premise that computer system applications should share a common pool of data, which is updated on-line and made available simultaneously to any user of any application.",,J. Paynter,1996,Conference,Proceedings 1996 International Conference Software Engineering: Education and Practice,10.1109/SEEP.1996.533994,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=533994,"Auckland Univ., New Zealand",IEEE,English,,0-8186-7379-6
IEEE,Software reliability analysis incorporating fault detection and debugging activities,"The software reliability measurement problem can be approached by obtaining the estimates of the residual number of faults in the software. Traditional black box based approaches to software reliability modeling assume that the debugging process is instantaneous and perfect. The estimates of the remaining number of faults, and hence reliability, are based on these oversimplified assumptions and they tend to be optimistic. We propose a framework relying on rate based simulation technique for incorporating explicit debugging activities along with the possibility of imperfect debugging into the black box software reliability models. We present various debugging policies and analyze the effect of these policies on the residual number of faults in the software. In addition, we propose a methodology to compute the reliability of the software, taking into account explicit debugging activities. An economic cost model to determine the optimal software release criteria in the presence of debugging activities is described. Finally, we present the high level architecture of a tool, called SRSIM, for the purpose of automating the simulation techniques presented.",,S. S. Gokhale; M. R. Lyu; K. S. Trivedi,1998,Conference,Proceedings Ninth International Symposium on Software Reliability Engineering (Cat. No.98TB100257),10.1109/ISSRE.1998.730883,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=730883,"Bourns Coll. of Eng., California Univ., Riverside, CA, USA; NA; NA",IEEE,English,1071-9458,0-8186-8991-9
IEEE,A model to evaluate the economic benefits of software components development,"ABB is a multi-national corporation that is developing a new generation of products based on the concept of Industrial/sup IT/. This concept provides a common integration platform for product interoperability. As Industrial/sup IT/ enabled products are developed across ABB, software reuse must be considered. Component based software development (CBSD) is an effective means to improve productivity and quality by developing reusable components. Measuring the economic benefits and performing sensitivity analyses of CBSD scenarios in the development of Industrial/sup IT/ products is important to improve efficiency. This paper presents a model that allows project leaders to evaluate a variety of software development scenarios. The model is based on a goal-question-metrics (GQM) approach and was developed at the ABB corporate research laboratories.",,A. Dagnino; H. Srikanth; M. Naedele; D. Brantly,2003,Conference,"SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483)",10.1109/ICSMC.2003.1244479,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1244479,"ABB-USETI, Raleigh, NC, USA; NA; NA; NA",IEEE,English,1062-922X,0-7803-7952-7
IEEE,Using grey relational analysis to predict software effort with small data sets,"The inherent uncertainty of the software development process presents particular challenges for software effort prediction. We need to systematically address missing data values, feature subset selection and the continuous evolution of predictions as the project unfolds, and all of this in the context of data-starvation and noisy data. However, in this paper, we particularly focus on feature subset selection and effort prediction at an early stage of a project. We propose a novel approach of using grey relational analysis (GRA) of grey system theory (GST), which is a recently developed system engineering theory based on the uncertainty of small samples. In this work we address some of the theoretical challenges in applying GRA to feature subset selection and effort prediction, and then evaluate our approach on five publicly available industrial data sets using stepwise regression as a benchmark. The results are very encouraging in the sense of being comparable or better than other machine learning techniques and thus indicate that the method has considerable potential",software project estimation;effort prediction;feature subset selection;empirical evaluation;Grey Relational Analysis;Grey System Theory,Qinbao Song; M. Shepperd; C. Mair,2005,Conference,11th IEEE International Software Metrics Symposium (METRICS'05),10.1109/METRICS.2005.51,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1509313,"Xi'an Jiaotong Univ., China; Xi'an Jiaotong Univ., China; Xi'an Jiaotong Univ., China",IEEE,English,1530-1435,0-7695-2371-4
IEEE,The impact of costs of misclassification on software quality modeling,"A software quality model can make timely predictions of the class of a module, such as not fault prone or fault prone. These enable one to improve software development processes by targeting reliability improvement techniques more effectively and efficiently. Published software quality classification models generally minimize the number of misclassifications. The contribution of the paper is empirical evidence, supported by theoretical considerations, that such models can significantly benefit from minimizing the expected cost of misclassifications, rather than just the number of misclassifications. This is necessary when misclassification costs for not fault prone modules are quite different from those of fault prone modules. We illustrate the principles with a case study using nonparametric discriminant analysis. The case study examined a large subsystem of the Joint Surveillance Target Attack Radar System, JS-TARS, which is an embedded, real time, military application. Measures of the process history of each module were independent variables. Models with equal costs of misclassification were unacceptable, due to high misclassification rates for fault prone modules, but cost weighted models had acceptable, balanced misclassification rates.",,T. M. Khoshgoftaar; E. B. Allen,1997,Conference,Proceedings Fourth International Software Metrics Symposium,10.1109/METRIC.1997.637165,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=637165,"Florida Atlantic Univ., Boca Raton, FL, USA; NA",IEEE,English,,0-8186-8093-8
IEEE,Factors systematically associated with errors in subjective estimates of software development effort: the stability of expert judgment,"Estimation of project development effort is most often performed by expert judgment rather than by using an empirically derived model (although such may be used by the expert to assist their decision). One question that can be asked about these estimates is how stable are they with respect to characteristics of the development process and product? This stability can be assessed in relation to the degree to which the project has advanced over time, the type of module for which the estimate is being made, and the characteristics of that module. In this paper we examine a set of expert-derived estimates for the effort required to develop a collection of modules from a large health-care system. Statistical tests are used to identify relationships between the type (screen or report) and characteristics of modules and the likelihood of the associated development effort being underestimated, approximately correct, or over-estimated. Distinct relationships are found that suggest that the estimation process being examined was not unbiased to such characteristics. This is a potentially useful finding in that it provides an opportunity for estimators to improve their prediction performance.",,A. R. Gray; S. G. MacDonell; M. J. Shepperd,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809743,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809743,"Dept. of Inf. Sci., Otago Univ., Dunedin, New Zealand; NA; NA",IEEE,English,,0-7695-0403-5
IEEE,Assessing the benefits of imputing ERP projects with missing data,"Incomplete, or missing data is likely to be encountered in empirical software engineering data sets. The authors evaluate some methods for handling missing data. The methods are presented and discussed in general and thereafter applied to effort estimation of ERP projects. We found that two sampling based methods, mean imputation (MI) and similar response pattern imputation (SRPI), waste less information than listwise deletion (LD). However, MI may introduce more bias than the SRPI method. Compared to sampling based methods, likelihood based imputation methods require too large data sets to be realistic to use in empirical software engineering. None of the sampling based methods, such as MI and SRPI, seem able to correct bias. So, though imputation is an attractive idea, the available methods still have severe limitations.",,I. Myrtveit; E. Stensrud; U. Olsson,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915517,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915517,NA; NA; NA,IEEE,English,1530-1435,0-7695-1043-4
IEEE,Effort estimation from change records of evolving software,Algorithmic cost estimation in the context of software evolution is being addressed as part of the FEAST/2 project with encouraging results from an industrial case study. The paper considers the approach and case study.,,J. F. Ramil; M. M. Lehman,2000,Conference,Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium,10.1145/337180.337633,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=870498,"Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK; NA",IEEE,English,0270-5257,1-58113-206-9
IEEE,Software metrics in student projects,"Software Engineering is an important part of modern Computer Engineering education. A comprehensive course in Software Engineering should include a topic on software metrics. Also, a number of courses practice handing team projects to students. In this paper a number of software metrics are applied to projects developed by students with the purpose of estimating overall team effort. In this way, conclusions are formed about usefulness of these metrics in the context of teaching software engineering.",,V. Ljubovic; N. Nosovic,2012,Conference,2012 20th Telecommunications Forum (TELFOR),10.1109/TELFOR.2012.6419495,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6419495,"Elektrotehnički fakultet Sarajevo, Zmaja od Bosne b.b.; Elektrotehnički fakultet Sarajevo, Zmaja od Bosne b.b.",IEEE,English,,978-1-4673-2984-2
IEEE,Cost implications of interrater agreement for software process assessments,"Much empirical research has been done on evaluating and modeling interrater agreement in software process assessments. Interrater agreement is the extent to which assessors agree in their ratings of software process capabilities when presented with the same evidence and performing their ratings independently. This line of research was based on the premise that lack of interrater agreement can lead to erroneous decisions from process assessment scores. However, thus far we do not know the impact of interrater agreement on the cost of assessments. We report on a study that evaluates the relationship between interrater agreement and the cost of the consolidation activity in assessments. The study was conducted in the context of two assessments using the emerging international standard ISO/IEC 15504. Our results indicate that for organizational processes, the relationship is strong and in the expected direction. For project level processes no relationship was found. These results indicate that for assessments that include organizational processes in their scope, ensuring high interrater agreement could lead to a reduction in their costs.",,K. El Emam; J. -. Simon; S. Rousseau; E. Jacquet,1998,Conference,Proceedings Fifth International Software Metrics Symposium. Metrics (Cat. No.98TB100262),10.1109/METRIC.1998.731225,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=731225,"Fraunhofer Inst. for Exp. Software Eng., Kaiserslautern, Germany; NA; NA; NA",IEEE,English,,0-8186-9201-4
IEEE,An experiment for evaluating the effectiveness of using a system dynamics simulation model in software project management education,"Due to increasing demand for software project managers in industry, efforts are needed to develop the management-related knowledge and skills of the current and future software workforce. In particular, university education needs to provide to their computer science students not only with technology-related skills but, in addition, a basic understanding of typical phenomena occurring in industrial (and academic) software projects. The paper presents a controlled experiment that evaluates the effectiveness of using a process simulation model for university education in software project management. The experiment uses a pre-test-post-test control group design with random assignment of computer science students. The treatment of the experimental group involves a system dynamics simulation model. The treatment of the control group involves a conventional predictive model for project planning, i.e. the well-known COCOMO model. In addition to the presentation of the results of the empirical study, the paper discusses limitations and threats to validity. Proposals for modifications of the experimental design and the treatments are made for future replications.",,D. Pfahl; N. Koval; G. Ruhe,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915519,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915519,"Fraunhofer IESE, Kaiserslautern, Germany; NA; NA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,Increasing the accuracy and reliability of analogy-based cost estimation with extensive project feature dimension weighting,"Accurate and reliable software cost estimation is a vital task in software project portfolio decisions like resource scheduling or bidding. A prominent and transparent method of supporting estimators is analogy-based cost estimation, which is based on finding similar projects in historical portfolio data. However, the various project feature dimensions used to determine project analogy represent project aspects differing widely in their relevance; they are known to have varying impact on the analogies - and in turn on the overall estimation accuracy and reliability - , which is not addressed by traditional approaches. This paper (a) proposes an improved analogy-based approach based on extensive dimension weighting, and (ii) empirically evaluates the accuracy and reliability improvements in the context of five real-world portfolio data sets. Main results are accuracy and reliability improvements for all analyzed portfolios and quality measures. Furthermore, the approach indicates a quality barrier for analogy-based estimation approaches using the same basic assumptions and quality measures.",,M. Auer; S. Biffl,2004,Conference,"Proceedings. 2004 International Symposium on Empirical Software Engineering, 2004. ISESE '04.",10.1109/ISESE.2004.1334902,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1334902,"Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Austria; Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Austria",IEEE,English,,0-7695-2165-7
IEEE,Definition of software metrics for software project development by using fuzzy sets and logic,"Software metrics measure certain properties of the software or its specifications. As quantitative measurements are required in all the sciences, there are ongoing efforts among computer science practitioners and academics to apply analogous approaches to software development process. The main aim is to provide objective, reproducible and quantitative measure that can have many useful applications in such important parts of software project management as the schedule and budget planning, cost estimation, quality assurance, software debugging, performance optimization and optimal staff task assignments as well as in the whole software development life cycle. There exist a number of techniques for modeling software metrics including FPA estimation (mean-based, median-based), LS regression, LMS regression, Neural Networks, and Fuzzy Logic. In this paper we are going to talk about singularities of applying Fuzzy Logic approach to the software metrics modeling.",software project management;fuzzy logic and sets;software metrics,S. Mirseidova; L. Atymtayeva,2012,Conference,"The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems",10.1109/SCIS-ISIS.2012.6505336,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6505336,"Kazakh-British Technical University, Tole bi st., 59, Almaty, Kazakhstan; Kazakh-British Technical University, Tole bi st., 59, Almaty, Kazakhstan",IEEE,English,,978-1-4673-2743-5
IEEE,Software Cost Estimation Framework for Service-Oriented Architecture Systems Using Divide-and-Conquer Approach,"Due to the complexity of Service-Oriented Architecture (SOA), cost and effort estimation for SOA-based software development is more difficult than that for traditional software development. Unfortunately, there is a lack of published work about cost and effort estimation for SOA-based software. Existing cost estimation approaches are inadequate to address the complex service-oriented systems. This paper proposes a novel framework based on Divide-and-Conquer (D&C) for cost estimation for building SOA-based software. By dealing with separately development parts, the D&C framework can help organizations simplify and regulate SOA implementation cost estimation. Furthermore, both cost estimation modeling and software sizing work can be satisfied respectively by switching the corresponding metrics within this framework. Given the requirement of developing these metrics, this framework also defines the future research in four different directions according to the separate cost estimation sub-problems.",service-oriented architecture (SOA);software cost estimation;divide-and-conquer (D&C);framework,Z. Li; J. Keung,2010,Conference,2010 Fifth IEEE International Symposium on Service Oriented System Engineering,10.1109/SOSE.2010.29,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5569930,"Sch. of Comput. Sci. & Eng., NICTA & UNSW, Sydney, NSW, Australia; Sch. of Comput. Sci. & Eng., NICTA & UNSW, Sydney, NSW, Australia",IEEE,English,,978-1-4244-7326-7
IEEE,Software size measurement of student information terminal with use case point,"Student Information Terminals (S-IT) is an independent academic service information system for students, where this service makes it easy for students to obtain academic information in real time with information such as the transcript of academic achievement, finance, course, attendance, exam, lecturer, card examinees and announcements academic, and has the function to print directly the data independently on S-IT devices. To find out how well the S-IT is in terms of software size, then needed a measurement. The measurements used in this paper using the Use Case Point (UCP) method as one of the approved software metrics which measure the functionality our software size. The results of the measurement of software size S-IT shown that the project has a small size, the software has a value of UCP = 96.767 estimate effort, has the development time 1,452 hours or equivalent 9 months 1 week and have development costs in Indonesian Rupiah is 263,175,000 IDR. The aims of measurement software size S-IT with the use case point is to help make decisions about the implementation of software development application project in terms of the estimated time, costs, and people.",use case point;software measurement;software metrics;student information terminal;information system academic,D. Kurniadi; Sasmoko; H. L. H. S. Warnars; F. L. Gaol,2017,Conference,2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom),10.1109/CYBERNETICSCOM.2017.8311703,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8311703,"Computer Science Department, BINUS Graduate Program - Doctor, of Computer Science, Bina Nusantara University Jakarta, Indonesia 11480; Primary Teacher Education, Department, Faculty of Humanities, Bina Nusantara University Jakarta, Indonesia 11480; Computer Science Department, BINUS Graduate, Program - Doctor of Computer Science, Bina Nusantara University, Jakarta, Indonesia 11480; Computer Science Department, BINUS Graduate, Program - Doctor of Computer Science, Bina Nusantara University, Jakarta, Indonesia 11480",IEEE,English,,978-1-5386-0784-8
IEEE,Empirical validation of relational database metrics for effort estimation,"Measurements of certain attributes during software development process are of core importance. Number of effort estimation metrics has been proposed for software projects, while ignoring relational database applications. In this paper we propose a set of metrics to measure the effort for small scale relational database applications. We present an effort estimation model using statistical techniques that can be used by software development organizations. Our model is flexible as it can measure effort with few database objects as well as with all database objects. We have compared estimated effort with actual effort and found very promising results.",,B. Jamil; J. Ferzund; A. Batool; S. Ghafoor,2010,Conference,INC2010: 6th International Conference on Networked Computing,,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5484854,"Department of Computer Science, University of Sargodha, Sargodha, Pakistan; Department of Computer Science, University of Sargodha, Sargodha, Pakistan; Department of Computer Science, University of Sargodha, Sargodha, Pakistan; Department of Computer Science, University of Sargodha, Sargodha, Pakistan",IEEE,English,,978-89-88678-20-6
IEEE,Measuring domain engineering effects on software change cost,Domain engineering (DE) is an increasingly popular process for efficiently producing software. DE uses detailed knowledge of a particular application domain to define rigorously a family of software products within that domain. We describe a methodology for precise quantitative measurement of DE impact on software change efforts. The methodology employs measures of small software changes to determine the effect of DE. We illustrate this approach in a detailed case study of DE in a telecommunications product. In the particular case the change effort was dramatically reduced. The methodology can precisely measure cost savings in change effort and is simple and inexpensive since it relies on information automatically collected by version control systems.,,H. Siy; A. Mockus,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809751,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809751,"Lucent Technol., Bell Labs., USA; NA",IEEE,English,,0-7695-0403-5
IEEE,"Business impact, benefit, and cost of applying GQM in industry: an in-depth, long-term investigation at Schlumberger RPS","Many success stories have been reported on specific effects of measurement, but little is known about the multiple interactions of measurement programmes with the business environment of a software organisation. This paper summarises industrial experiences with the Goal/Question/Metric (GQM) approach to software engineering measurement. They are based on long-term observation and additional detailed investigations at Schlumberger RPS. The paper reports the business impact of GQM in terms of identified benefit, cost models, and factors for successful application of GQM.",,A. Birk; R. van Solingen; J. Jarvinen,1998,Conference,Proceedings Fifth International Software Metrics Symposium. Metrics (Cat. No.98TB100262),10.1109/METRIC.1998.731231,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=731231,"Fraunhofer IESE, Kaiserslautern, Germany; NA; NA",IEEE,English,,0-8186-9201-4
IEEE,Effect of Variations in Measurement Process for Software Development Efforts,"Researchers have proposed that the reliability of software prediction models can be assessed by the following most widely used evaluation criterion, i.e., Difference Measure and Ratio Measure. Ratio measure is more suitable for the assessment of the accuracy in software cost estimation. Results in this research demonstrated that applying proposed method to the software effort estimation is by far the most feasible approach for addressing the problem of apprehension and ambiguity existing in software effort drivers. Small adjustments to the COCOMO cost drivers bring significant improvements to the quality criteria applied to the proposed approach.",Software Effort Estimation;COCOMO;Non Algorithmic Models;Genetic Algorithm;Evaluation Criterion,B. K. Singh; A. Punhani; G. P. Singh; A. K. Misra,2014,Conference,"2014 6th International Conference on Multimedia, Computer Graphics and Broadcasting",10.1109/MulGraB.2014.8,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7024246,"Deptt. of Comput. Sci. & Eng., RBS Coll., Agra, India; Deptt. of Comput. Sci. & Eng., RBS Coll., Agra, India; Deptt. of Comput. Sci. & Eng., Shivdan Singh Eng. Coll., Aligarh, India; Deptt. of Comput. Sci. & Eng., MNNIT Allahabad, Allahabad, India",IEEE,English,,978-1-4799-7764-2
IEEE,The Effect of Highlighting Error Categories in FSM Training on the Accuracy of Measurement,"As various software management activities including cost estimation and project control are conducted based on the software size measurement, achieving high accuracy in functional size measurement (FSM) is critical. Several studies examined the relation between FSM training and improvement in the accuracy of FSM. However, those studies propose comprehensive frameworks and approaches that require fundamental changes in the training content. In this study, we analyzed the effect of highlighting error categories during training by extracting the errors throughout four years. We showed that, highlighting the frequent error categories during the same training period without a fundamental change in the content would significantly decrease the error rate. The results of the research we conducted are promising about the improvement of measurement accuracy.",Highlighting Error Categories;Functional Size Measurement;Accuracy,A. M. Ertugrul; G. Yilmaz; M. Salmanoglu; O. Demirörs,2014,Conference,2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement,10.1109/IWSM.Mensura.2014.21,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7000094,NA; NA; NA; NA,IEEE,English,,978-1-4799-4174-2
IEEE,Algorithmic cost estimation for software evolution,"The study addresses the problem of cost estimation in the context of software evolution by building a set of quantitative models and assessing their predictive power. The models aim at capturing the relationship between effort, productivity and a suite of metrics of software evolution extracted from empirical data sets.",,J. F. Ramil,2000,Conference,Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium,10.1145/337180.337587,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=870473,"Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK",IEEE,English,0270-5257,1-58113-206-9
IEEE,Software productivity measurement using multiple size measures,"Productivity measures based on a simple ratio of product size to project effort assume that size can be determined as a single measure. If there are many possible size measures in a data set and no obvious model for aggregating the measures into a single measure, we propose using the expression AdjustedSize/Effort to measure productivity. AdjustedSize is defined as the most appropriate regression-based effort estimation model, where all the size measures selected for inclusion in the estimation model have a regression parameter significantly different from zero (p<0.05). This productivity measurement method ensures that each project has an expected productivity value of one. Values between zero and one indicate lower than expected productivity, values greater than one indicate higher than expected productivity. We discuss the assumptions underlying this productivity measurement method and present an example of its use for Web application projects. We also explain the relationship between effort prediction models and productivity models.",Index Terms- Software productivity measurement;software cost estimation.,B. Kitchenham; E. Mendes,2004,Journal,IEEE Transactions on Software Engineering,10.1109/TSE.2004.104,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1377195,"Nat. ICT Australia, Alexandria, NSW, Australia; NA",IEEE,English,1939-3520,
IEEE,Overcoming the challenges in cost estimation for distributed software projects,"We describe how we studied, in-situ, the operational processes of three large high process maturity distributed software development companies and discovered three common problems they faced with respect to early stage project cost estimation. We found that project managers faced significant challenges to accurately estimate project costs because the standard metrics-based estimation tools they used (a) did not effectively incorporate diverse distributed project configurations and characteristics, (b) required comprehensive data that was not fully available for all starting projects, and (c) required significant domain experience to derive accurate estimates. To address these challenges, we collaborated with practitioners at the three firms and developed a new learning-oriented and semi-automated early-stage cost estimation solution that was specifically designed for globally distributed software projects. The key idea of our solution was to augment the existing metrics-driven estimation methods with a case repository that stratified past incidents related to project effort estimation issues from the historical project databases at the firms into several generalizable categories. This repository allowed project managers to quickly and effectively “benchmark” their new projects to all past projects across the firms, and thereby learn from them. We deployed our solution at each of our three research sites for real-world field-testing over a period of six months. Project managers of 219 new large globally distributed projects used both our method to estimate the cost of their projects as well as the established metrics-based estimation approaches they were used to. Our approach achieved significantly reduced estimation errors (of up to 60%). This resulted in more than 20% net cost savings, on average, per project - a massive total cost savings across all projects at the three firms!",Globally distributed software development;software engineering economics;cost estimation;case-based reasoning;analogies;project management;learning,N. Ramasubbu; R. K. Balan,2012,Conference,2012 34th International Conference on Software Engineering (ICSE),10.1109/ICSE.2012.6227203,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6227203,"School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore",IEEE,English,1558-1225,978-1-4673-1067-3
IEEE,A Metric of Software Size as a Tool for IT Governance,"This paper proposes a new metric for software functional size, which is derived from Function Point Analysis (FPA), but overcomes some of its known deficiencies. The statistical results show that the new metric, Functional Elements (EF), and its sub metric, Functional Elements of Transaction (EFt), have higher correlation with the effort in software development than FPA in the context of the analyzed data. The paper illustrates the application of the new metric as a tool to improve IT governance specifically in assessment, monitoring, and giving directions to the software development area.",Function Points;IT governance;IT performance;Software engineering;Software metrics,M. V. B. D. Castro; C. A. M. Hernandes,2013,Conference,2013 27th Brazilian Symposium on Software Engineering,10.1109/SBES.2013.13,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6800186,"NA; Tribunal de Contas da Uniao (TCU), Brasilia, Brazil",IEEE,English,,978-0-7695-5165-4
IEEE,Evaluation and application of complexity-based criticality models,"Cost-effective software project management has the serious need to focus resources on those areas with highest criticality. Identifying such components in advance that need high development effort or that are likely to produce many failures during operation and assigning additional design or corrective effort is one approach for effective resource allocation. Complexity metrics are applied during the development of large telecommunication software in order to identify high risk components and to tailor reliability growth models. Five classification techniques (Pareto classification, classification trees, factor-based discriminant analysis, fuzzy classification, neural networks) are compared for identifying critical components. For testing and maintenance phases we combined this approach with tailored reliability growth models. Results from a current large-scale switching project are included to show practical benefits.",,C. Ebert,1996,Conference,Proceedings of the 3rd International Software Metrics Symposium,10.1109/METRIC.1996.492454,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=492454,"Switching Syst. Div., Alcatel, Stuttgart, Germany",IEEE,English,,0-8186-7365-6
IEEE,Are the principal components of software complexity data stable across software products?,"The current software market is not suitable for organizations that place competitive bids, set schedules, or control projects without regard to past performance. Software quality models based upon data collected from past projects can help engineers to estimate costs of future development efforts, and to control ongoing efforts. Application of principal components analysis can improve the stability and predictive quality of software quality models. However, models based upon principal components are only appropriate for application to products having similar principal components. We apply a statistical technique for quantifying the similarity of principal components. We find that distinct but similar products developed by the same organization can share similar principal components, and that distinct products developed by distinct organizations will likely have dissimilar principal components.<>",,T. M. Khoshgoftaar; D. L. Lanning,1994,Conference,Proceedings of 1994 IEEE 2nd International Software Metrics Symposium,10.1109/METRIC.1994.344227,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=344227,"Dept. of Comput. Sci. & Eng., Florida Atlantic Univ., Boca Raton, FL, USA; NA",IEEE,English,,0-8186-5865-7
IEEE,The application of case-based reasoning to early Web project cost estimation,"Literature shows that over the years numerous techniques for estimating development effort have been suggested, derived from late project measures. However, to the successful management of software projects, estimates are necessary throughout the whole development life cycle. The objective is twofold. First, we describe the application of case-based reasoning (CBR) for estimating Web hypermedia development effort using measures collected at different stages in the development cycle. Second, we compare the prediction accuracy of those measures, obtained using different CBR configurations. Contrary to the expected, late measures did not show statistically significant better predictions than early measures.",,E. Mendes; N. Mosley; S. Counsell,2002,Conference,Proceedings 26th Annual International Computer Software and Applications,10.1109/CMPSAC.2002.1045034,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1045034,"Dept. of Comput. Sci., Auckland Univ., New Zealand; Dept. of Comput. Sci., Auckland Univ., New Zealand; Dept. of Comput. Sci., Auckland Univ., New Zealand",IEEE,English,0730-3157,0-7695-1727-7
IEEE,How valuable is company-specific data compared to multi-company data for software cost estimation?,"This paper investigates the pertinent question whether multi-organizational data is valuable for software project cost estimation. Local, company-specific data is widely believed to provide a better basis for accurate estimates. On the other hand, multi-organizational databases provide an opportunity for fast data accumulation and shared. information benefits. Therefore, this paper trades off the potential advantages and drawbacks of using local data as compared to multi-organizational data. Motivated by the results from previous investigations, we further analyzed a large cost database from Finland that collects standard cost factors and includes information on six individual companies. Each of these companies provided data for more than ten projects. This information was used to compare the accuracy between company-specific (local) and company-external (global) cost models. They show that company-specific models seem not to yield better results than the company external models. Our results are based on applying two standard statistical estimation methods (OLS-regression, analysis of variance) and analogy-based estimation.",,I. Wieczorek; M. Ruhe,2002,Conference,Proceedings Eighth IEEE Symposium on Software Metrics,10.1109/METRIC.2002.1011342,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1011342,"Fraunhofer Inst. for Exp. Software Eng., Kaiserslautern, Germany; NA",IEEE,English,1530-1435,0-7695-1339-5
IEEE,Theoretical Maximum Prediction Accuracy for Analogy-Based Software Cost Estimation,"Software cost estimation is an important area of research in software engineering. Various cost estimation model evaluation criteria (such as MMRE, MdMRE etc.) have been developed for comparing prediction accuracy among cost estimation models. All of these metrics capture the residual difference between the predicted value and the actual value in the dataset, but ignore the importance of the dataset quality. What is more, they implicitly assume the prediction model to be able to predict with up to 100% accuracy at its maximum for a given dataset. Given that these prediction models only provide an estimate based on observed historical data, absolute accuracy cannot be possibly achieved. It is therefore important to realize the theoretical maximum prediction accuracy (TMPA) for the given model with a given dataset. In this paper, we first discuss the practical importance of this notion, and propose a novel method for the determination of TMPA in the application of analogy-based software cost estimation. Specifically, we determine the TMPA of analogy using a unique dynamic K-NN approach to simulate and optimize the prediction system. The results of an empirical experiment show that our method is practical and important for researchers seeking to develop improved prediction models, because it offers an alternative for practical comparison between different prediction models.",Software Cost Estimation;Software Metrics and Measurement;Software Cost Estimation;Analogy;K-NN;MMRE,J. W. Keung,2008,Conference,2008 15th Asia-Pacific Software Engineering Conference,10.1109/APSEC.2008.43,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4724583,"NICTA Ltd., Sydney, NSW, Australia",IEEE,English,1530-1362,978-0-7695-3446-6
IEEE,Metrics of software evolution as effort predictors - a case study,"Despite its importance, cost estimation in the context of continuing software evolution has been relatively unexplored. This paper addresses this omission by describing some models that predict effort as a function of a suite of metrics of software evolution. It presents a case study relating to the evolution of the kernel of a mainframe operating system. Six models based on eight different indicators of evolution activity are proposed, and their predictive power is examined and compared to that of two baseline models. Predictions with errors of the order of 20% of the actual values have been obtained from the models, when fitted to and tested against historical data over a segment of 10 years of the kernel's continuing evolution. The appropriateness of the proposed models as predictors appears to be restricted to homogeneous evolution segments, i.e. periods with relatively small variations in the level of effort applied. It was found that models based on coarse granularity measures, such as ""subsystem counts"", provided a mean magnitude of relative error which was similar to those based on finer alternatives, such as ""module counts"".",,Ramil; Lehman,2000,Conference,Proceedings 2000 International Conference on Software Maintenance,10.1109/ICSM.2000.883036,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=883036,"Dept. of Comput., Imperial Coll. of Sci., Technol. & Med., London, UK; NA",IEEE,English,1063-6773,0-7695-0753-0
IEEE,The effect of object-oriented frameworks on developer productivity,"Cost and time estimation are difficult problems in software development projects. Software metrics tackle this problem by assuming a statistical correlation between the size of a software project and the amount of effort typically required to realize it. To be useful in estimating cost, a size metric must take into account the inherent complexity of the system. Such metrics have been applied with varying degrees of success, but the nature of software development has been changing, and some of the assumptions behind the established cost-estimation techniques are slowly being invalidated. The System Meter (SM) is a new software sizing approach based on the notion of system description. System descriptions encompass all kinds of software artifacts, from requirement documents to final code. For each kind or level of artifacts, there is a corresponding flavor of SM. In our studies we used the first operational flavor, the SM at the preliminary analysis level, or Pre-SM. In contrast to the well-known Function Point (FP) metric, which is measurable after the more detailed but costly phase of domain analysis only, the SM explicitly takes OO concepts into account. It also distinguishes between components to be developed and those to be reused, thus reflecting the idea of incremental functionality. We present results of a field study of 36 projects developed using object technology. We measured both FP and the Pre-SM method in all 36 projects and compared their correlation to the development effort.",,S. Moser; O. Nierstrasz,1996,Magazine,Computer,10.1109/2.536783,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=536783,"Inst. fuer Inf., Berne Univ., Switzerland; Inst. fuer Inf., Berne Univ., Switzerland",IEEE,English,1558-0814,
IEEE,Making resource decisions for software projects,"Software metrics should support managerial decision making in software projects. We explain how traditional metrics approaches, such as regression-based models for cost estimation fall short of this goal. Instead, we describe a causal model (using a Bayesian network) which incorporates empirical data, but allows it to be interpreted and supplemented using expert judgement. We show how this causal model is used in a practical decision-support tool, allowing a project manager to trade-off the resources used against the outputs (delivered functionality, quality achieved) in a software project. The model and toolset have evolved in a number of collaborative projects and hence capture significant commercial input. Extensive validation trials are taking place among partners on the EC funded project MODIST (this includes Philips, Israel Aircraft Industries and QinetiQ) and the feedback so far has been very good. The estimates are sensible and the causal modelling approach enables decision-makers to reason in a way that is not possible with other project management and resource estimation tools. To ensure wide dissemination and validation a version of the toolset with the full underlying model is being made available for free to researchers.",,N. Fenton; W. Marsh; M. Neil; P. Cates; S. Forey; M. Tailor,2004,Conference,Proceedings. 26th International Conference on Software Engineering,10.1109/ICSE.2004.1317462,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1317462,"Dept. of Comput. Sci., Univ. of London, UK; Dept. of Comput. Sci., Univ. of London, UK; Dept. of Comput. Sci., Univ. of London, UK; Dept. of Comput. Sci., Univ. of London, UK; Dept. of Comput. Sci., Univ. of London, UK; Dept. of Comput. Sci., Univ. of London, UK",IEEE,English,0270-5257,0-7695-2163-0
IEEE,Determining the value of a corporate reuse program,"Reuse metrics must accurately reflect the amount of effort saved. One must have realistic measures to ensure the credibility of the value placed on reuse and to separate reuse benefits from those of other technologies also competing for limited investment dollars. The paper defines a reuse metric and return on investment (ROI) model at IBM that distinguishes reuse savings and benefits from those already gained through accepted software engineering techniques. Used in conjunction with a planned reuse program, the potential of reuse serves as a powerful motivator. They derive three reuse metrics from readily available software data elements and use these metrics in return on investment model that establishes a sound business justification for reuse.<>",,J. S. Poulin; J. M. Caruso,1993,Conference,[1993] Proceedings First International Software Metrics Symposium,10.1109/METRIC.1993.263804,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=263804,"IBM, London, UK; IBM, London, UK",IEEE,English,,0-8186-3740-4
IEEE,Quality prediction model of object-oriented software system using computational intelligence,"Effective prediction of the fault-proneness plays a very important role in the analysis of software quality and balance of software cost, and it also is an important problem of software engineering. Importance of software quality is increasing leading to development of new sophisticated techniques, which can be used in constructing models for predicting quality attributes. In this paper, we use fuzzy c-means clustering (FCM) and radial basis function neural network (RBFNN) to construct prediction model of the fault-proneness, RBFNN is used as a classificatory, and FCM is as a cluster. Object-oriented software metrics are as input variables of fault prediction model. Experiments results confirm that designed model is very effective for predicting a class's fault-proneness, it has a high accuracy, and its implementation requires neither extra cost nor expert's knowledge. It also is automated. Therefore, proposed model was very useful in predicting software quality and classing the fault-proneness.",FCM;fault-proneness;RBFNN;object-oriented;software metrics;software quality prediction,Cong Jin; Shu-Wei Jin; Jun-Min Ye; Qing-Guo Zhang,2009,Conference,2009 2nd International Conference on Power Electronics and Intelligent Transportation System (PEITS),10.1109/PEITS.2009.5406941,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5406941,"Department of Computer Science, Central China Normal University, Wuhan, China; The School of Physics & Technology, Wuhan University, China; Department of Computer Science, Central China Normal University, Wuhan, China; Department of Computer Science, Central China Normal University, Wuhan, China",IEEE,English,,978-1-4244-4544-8
IEEE,Better validation in a world-wide development environment,"Increasingly, software projects are handled in a global and distributed project setup. Global software development, however, also challenges traditional techniques of software engineering, such as peer reviews or teamwork. In particular, validation activities during development, such as inspections, need to be adjusted to achieve results which are both efficient and effective. Effective teamwork and the coaching of engineers contribute highly to successful projects. In this article, we evaluate experiences with validation activities in a global setting within Alcatel's switching and routing business. We investigate three hypotheses related, respectively, to the effects of collocated inspections, intensive coaching and feature-oriented development teams on globally distributed projects. As all these activities mean initial investment compared to a standard process with scattered activities, the major validation criterion for the three hypotheses is cost reduction due to earlier defect detection and less defects introduced. The data is taken from a sample of over 60 international projects of various sizes, from which we have collected all types of software product and process metrics in the past four years.",,C. Ebert; C. Hernandez Parro; R. Suttels; H. Kolarczyk,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915537,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915537,"Switching & Routing Div., Alcatel, Antwerp, Belgium; NA; NA; NA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,Software Project Cost Estimation Based on Groupware,"This paper combination of COCOMO2 cost structure model, Object Oriented Metric, groupware technology to research and achieve software project cost estimation based on groupware. Through the source codes calculation of inside groupware and function point assessment among groupware, we can improve range of error of the cost assessment and improve the accuracy of estimate.",Cost Estimation;Function Point Analysis;COCOMO2;Groupware,Y. Jin; J. Li; J. Lin; Q. Chen,2009,Conference,2009 WRI World Congress on Software Engineering,10.1109/WCSE.2009.268,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5319616,"Zhejiang Provincial Dept. of Finance, Inf. Centre, China; NA; Zhejiang Provincial Dept. of Finance, Inf. Centre, China; Coll. of Inf. Eng., Zhejiang Univ. of Technol., Hangzhou, China",IEEE,English,,978-0-7695-3570-8
IEEE,An empirical study of effort estimation during project execution,"Presents an empirical study of effort estimation in software engineering projects. In particular, this study is focused on improvements in effort estimations as more information becomes available. For example, after the requirements phase, the requirements specification is available, and the question is whether the knowledge regarding the number of requirements helps in improving the effort estimation of the project. The objective is twofold. First, it is important to find suitable measures that can be used in the re-planning of the projects. Second, the objective is to study how the effort estimations evolve as a software project is performed. The analysis is based on data from 26 projects. The analysis consists of two main steps: model building based on data from part of the projects, and evaluation of the models for the other projects. No single measure was found to be a particular good measure for an effort prediction model; instead, several measures from different phases were used. The prediction models were then evaluated, and it is concluded that it is difficult to improve effort estimations during project execution, at least if the initial estimate is fairly good. It is, however, believed that the prediction models are important for knowing that the initial estimate is of the right order, i.e. the estimates are needed to ensure that the initial estimate was fairly good. It is concluded that the re-estimation approach will help project managers to stay in control of their projects.",,M. C. Ohlsson; C. Wohlin,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809730,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809730,"Dept. of Commun. Syst., Lund Inst. of Technol., Sweden; NA",IEEE,English,,0-7695-0403-5
IEEE,Metrics for controlling effort during adaptive maintenance of object oriented systems,Object oriented modeling has been largely adopted in industry in the last few years. Several systems built 4 or 5 years ago may need an adaptive maintenance process in order to better satisfy market and customer needs. A model for effort estimation/prediction of the adaptive maintenance is presented. A selection of metrics for effort estimation has been applied to the general model for evaluating maintenance effort. The metrics presented have been validated against real data. The validation presented has shown that some metrics that can be profitably employed for effort estimation/prediction can be also used with success for the estimation/prediction of the maintenance effort. Moreover the results obtained give some guidelines for maintenance of control of relevant factors for adaptive maintenance.,,F. Fioravanti; P. Nesi; F. Stortoni,1999,Conference,Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM'99). 'Software Maintenance for Business Change' (Cat. No.99CB36360),10.1109/ICSM.1999.792646,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=792646,"Dept. of Syst. & Inf., Florence Univ., Italy; NA; NA",IEEE,English,1063-6773,0-7695-0016-1
IEEE,Metrics for agent-based software development,"In software engineering community an increasing effort has been put into design and development of multiagent systems (MAS). However, agent system development is currently dominated by informal guidelines, heuristics and inspirations rather than formal principles and well defined engineering techniques. In this paper we define a set of objective and subjective metrics to measure the complexity of MAS. The subjective metrics is a modified version of function point (FP) including the algorithmic complexity and knowledge complexity factor. The objective metrics is a measure for nearly-decomposability, measured by the communicative cohesion. Such metrics can be used to select the best architecture for the MAS. A methodology for agent-based software development based on such metrics is proposed.",,B. H. Far; T. Wanyama,2003,Conference,CCECE 2003 - Canadian Conference on Electrical and Computer Engineering. Toward a Caring and Humane Technology (Cat. No.03CH37436),10.1109/CCECE.2003.1226137,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1226137,"Dept. of Electr. & Comput. Eng., Calgary Univ., Alta., Canada; Dept. of Electr. & Comput. Eng., Calgary Univ., Alta., Canada",IEEE,English,0840-7789,0-7803-7781-8
IEEE,"Estimating effort by use case points: method, tool and case study","Use case point (UCP) method has been proposed to estimate software development effort in early phase of software project and used in a lot of software organizations. Intuitively, UCP is measured by counting the number of actors and transactions included in use case models. Several tools to support calculating UCP have been developed. However, they only extract actors and use cases and the complexity classification of them are conducted manually. We have been introducing UCP method to software projects in Hitachi Systems & Services, Ltd. To effective introduction of UCP method, we have developed an automatic use case measurement tool, called U-EST. This paper describes the idea to automatically classify the complexity of actors and use cases from use case model. We have also applied the U-EST to actual use case models and examined the difference between the value by the tool and one by the specialist. As the results, UCPs measured by the U-EST are similar to ones by the specialist.",,S. Kusumoto; F. Matukawa; K. Inoue; S. Hanabusa; Y. Maegawa,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357913,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357913,"Graduate Sch. of Inf. Sci. & Technol., Osaka Univ., Japan; Graduate Sch. of Inf. Sci. & Technol., Osaka Univ., Japan; Graduate Sch. of Inf. Sci. & Technol., Osaka Univ., Japan; NA; NA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,Simulation and comparison of Albrecht's function point and DeMarco's function bang metrics in a CASE environment,"Software size estimates provide a basis for software cost estimation during software development. Hence, it is important to measure the system size reliably as early as possible. Two of the best known specification level metrics, Albrecht's function points (A.J. Albrecht, 1979) and DeMarco's function bang metrics (T. DeMarco, 1982) are compared by a simulation study in which automatically generated randomized dataflow diagrams (DFDs) were used as a statistical sample to automatically count function points and function bang in a built CASE environment. These value counts were correlated statistically using correlation coefficients and regression analysis. The simulation study permits sufficient variation in the base material to cover most types of system specifications. Moreover, it allows sufficient sampling sizes to make statistical analysis of data. The obtained results show that in certain cases there is a relatively good statistical correlation between these metrics.<>",,R. Rask; P. Laamanen; K. Lyyttinen,1993,Journal,IEEE Transactions on Software Engineering,10.1109/32.238567,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=238567,"Dept. of Comput. Sci., Joensuu Univ., Finland; Dept. of Comput. Sci., Joensuu Univ., Finland; NA",IEEE,English,1939-3520,
IEEE,Factors that influence software project cost and schedule estimation,"Software Project Management is a core topic in software engineering courses because it teaches how software projects planned, implemented, controlled, monitored, and evaluated. The development of theories in software metrics and prediction models builds on the broader project management field but also attempt to overcome the difficulties inherent in measuring an intangible object like software. This paper is situated within research into the factors that influence cost and time estimation for software projects that continue to challenge software development organizations. The study described in this paper explored technical and non-technical factors seen by Sudanese software practitioners as critical in estimation, and if not managed, can result in cost and time overrun or in some cases lead to project failure. Using a mixed-method approach, the research project was first informed through a qualitative study that explored the kinds of problems that face the estimation process from the perspectives of different staff levels. This part of the study revealed a number of factors that can be broadly categorized as technical factors, e.g. the skills of those involved in the estimation process, and non-technical factors such as the high level of uncertainty in the local business environment. The second part of the study focused on one of the leading factors, software project staff training and experience, using the survey method to examine how well the software engineering curriculum is aligned with skills required in the software market, especially those related to estimation. The recommendations this study produced on reducing estimation errors, whether geared towards companies or academia, are preliminary and may only reflect the local setting. However, they also drew upon the vast literature on cost estimation techniques and case studies in similar and more advanced settings. The problem of software effort prediction and estimation models has been a thorny issue in the software engineering field since the concept of “software crisis” and the field itself, as a response to the crisis, emerged in the late 1960s. It still seems to some that “After forty years of currency the phrase `software engineering' still denotes no more than a vague and largely unfulfilled aspiration” [2]. This study develops our understanding of problems facing one of the young professions in the country, as well as contributes to the global body of research on developing techniques to manage the intricacy of software engineering compared to more established engineering disciplines.",Software Project Management;Software Effort Prediction;Software Project Failure;Software Project Cost Estimation techniques,S. M. A. Suliman; G. Kadoda,2017,Conference,2017 Sudan Conference on Computer Science and Information Technology (SCCSIT),10.1109/SCCSIT.2017.8293053,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8293053,"Faculty of Mathematical Sciences, University of Khartoum, Khartoum, Sudan; Independent Researcher, Khartoum, Sudan",IEEE,English,,978-1-5386-0667-4
IEEE,Re-planning for a successful project schedule,"Time-to-market or project duration has increasing significance for commercial software development. We report on a longitudinal study of a project at IBM Hursley Park. The focus of this study was schedule behaviour; however, we explored a range of related factors, including planned versus actual progress, resource allocation and functionality delivered. In the course of the 12-month study, evidence was collected from eight interviews, 49 project meetings, a number of project documents and a feedback workshop. The project leader considered the project to be a success, not only in terms of satisfying resource and schedule objectives, but also in the marketplace. Whilst many of the originally planned external commitments were met, it is clear that the project did not adhere to its original (detailed) plan and indeed there were no less than seven re-plans. These re-plans were mainly in response to mis-estimates in the original plan, rather than in response to the introduction of additional requirements (of which there were several) or problems with external dependencies. Furthermore, these re-plans suggest a distinction between the nature of the initial planning process and the nature of the re-planning process during the project. Attention is also directed at the implications these re-plans have for software metrics and cost estimation research.",,A. Rainer; M. Shepperd,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809728,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809728,"Empirical Software Eng. Res. Group, Bournemouth Univ., Poole, UK; NA",IEEE,English,,0-7695-0403-5
IEEE,Stepping towards dynamic measurement for object oriented software,"Software metrics are very helpful in measuring the different aspects of software like cohesion, coupling, polymorphism, inheritance etc. The objective of measuring software metrics are quality assurance, defect prediction, maintainability prediction, cost estimation, debugging, etc. Many authors proposed the use of static metrics for the software maintainability prediction (SMP) and were successful, but static metrics don't take into account the run-time behavior of software. Hence, to capture this dynamic behavior, dynamic metrics are necessary to be evaluated. This paper presents the empirical investigation of dynamic metrics for SMP and also compares them with static metrics. Six machine learning algorithms are used to build the prediction models for both the static and dynamic metrics. The performance of all models is compared using prevalent accuracy measures. Results show that dynamic metrics perform better than static metrics, and can be used as a sound alternative for SMP.",software metrics;software maintenance;software maintainability;machine learning algorithms;prediction,A. Jain; A. Chug,2016,Conference,2016 1st India International Conference on Information Processing (IICIP),10.1109/IICIP.2016.7975323,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7975323,"University School of Information and Communication Technology, Guru Gobind Singh Indraprastha University, Dwarka, New Delhi, India; University School of Information and Communication Technology, Guru Gobind Singh Indraprastha University, Dwarka, New Delhi, India",IEEE,English,,978-1-4673-6984-8
IEEE,Measuring functionality and productivity in Web-based applications: a case study,"We explore the variation of the cost of writing code when object oriented framework based development of Web applications is encountered for the first time. Managers need such information to justify their investments in innovative development strategies. Size measurements are essential in this task and a number of metrics, namely: lines of code, classical function points, and object oriented function points, are employed. It is argued that lines of code and object oriented function points are more suitable in this case. Data analysis reveals that learning influences mainly the cost of writing new code, consisting of continuous calls to components provided by the framework. We also explore the applicability of an already proposed effort prediction model that is based on different reuse types. A cost estimation model is the by-product of this study, providing a helpful tool for managing the first projects in which the framework is employed.",,M. Morisio; I. Stamelos; V. Spahos; D. Romano,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809732,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809732,"Maryland Univ., College Park, MD, USA; NA; NA; NA",IEEE,English,,0-7695-0403-5
IEEE,Estimating the implementation time for discrete-event simulation model building,"There are several techniques for estimating cost and time for software development. These are known in software engineering as “software metrics.” LOC (lines of code), COCOMO (COnstructive COst Model), and FPA (Function Point Analysis) are examples of such techniques. Although Discrete Event Simulation Modeling (DESM) has some differences from classical software development, it is possible to draw a parallel between these techniques and DESM. This article reviews some of the metrics from software engineering, and, based on those, proposes a metric for estimating time for the implementation of a simulation model using one specific simulation software. The results obtained for 22 real simulation projects showed that the proposed technique can estimate the time for software development with acceptable accuracy (average error of 6% and maximum absolute error of 38%) for models that have less that 200 simulation objects.",,L. Chwif; J. Banks; M. R. P. Barretto,2010,Conference,Proceedings of the 2010 Winter Simulation Conference,10.1109/WSC.2010.5678891,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5678891,"Escola de Engenharia Mauá, Praça Mauá 1, São Caetano do Sul, 09580-900, BRAZIL; Tecnológico de Monterrey, 64849, NL, MÉXICO; Universidade de São Paulo, Av. Prof. Mello Moraes 2231, 05508-900, BRAZIL",IEEE,English,1558-4305,978-1-4244-9865-9
IEEE,Cost Estimation Using Extended Use Case Point (e-UCP) Model,"Estimating the cost of development is one of the most crucial and daunting tasks for a software project manager. A lot of cost estimation models were reported in the literature but many of these models became obsolete because of the rapid changes in technology. Earlier cost estimation models used the size of the ultimate software product as the primary factor which, in many cases, was difficult to estimate. For example, COCOMO model used the number of Delivered Source Instructions (DSI) which is hard to estimate for products developed using modern programming languages. On the other hand, models such as Function Point (FP) metrics were designed to consider functional requirements instead of lines of code. These models were applicable only to procedural paradigm, and are not directly applicable to software products developed using the object-oriented methodology. It is this idea that gave birth to the creation of Use Case Point (UCP) metrics, originally developed by Gustav Karner[1993]. UCP uses use cases as the primary factor; use case model is the first model developed in an object-oriented design process using UML. In this paper, the authors extended the original UCP model with additional information obtained from use case narratives.",,K. Periyasamy; A. Ghode,2009,Conference,2009 International Conference on Computational Intelligence and Software Engineering,10.1109/CISE.2009.5364515,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5364515,"Dept. of Comput. Sci., Univ. of Wisconsin-La Crosse, La Crosse, WI, USA; Dept. of Comput. Sci., Univ. of Wisconsin-La Crosse, La Crosse, WI, USA",IEEE,English,,978-1-4244-4507-3
IEEE,Early phase software effort estimation model,"Software cost estimation is the measurement of the effort and resource required to develop a software system for a particular defined time period. From the last few years, many software cost estimation models have been proposed for the estimation of effort and development time. The cost of the software can be estimated easily in the mid of project development. But with further study, we found that the cost must be estimated before the start of the project, to satisfy customer as well as developer's needs. In earlier proposed cost estimation models, cost estimation is done with more than 20 parameters at the early conceptual phase and if input is not defined using logical approach, then the results of estimation are unpredictable. This paper presents simple approach for estimating software development effort with a minimum set of parameters yet sufficient, that can be easily identified at an early stage while considering all possible aspects. We also introduced a weight factor in the estimation of effort for improving the accuracy of the estimation and the proposed weight factor is calculated by expert learning system. Further, we developed a web based tool for the estimation of cost based on our proposed approach. Finally, we compare our result with previous works on early estimation and conclude with the points of accuracy that we observe while comparing the results with existing approaches.",Project Estimation;Effort Estimation;Cost Models;KSLOC;SDLC;Early Phase Cost Estimation,P. Agrawal; S. Kumar,2016,Conference,2016 Symposium on Colossal Data Analysis and Networking (CDAN),10.1109/CDAN.2016.7570914,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7570914,"CSE Department, Sushila Devi Bansal College of Technology, Indore(M.P.), India; CSE Department, Sushila Devi Bansal College of Technology, Indore(M.P.), India",IEEE,English,,978-1-5090-0669-4
IEEE,Human performance estimating with analogy and regression models: an empirical validation,"Most cost estimation models seem to be validated without testing human performance and using data sets from custom software projects where the software typically is sized in lines of code (SLOC) or function points. From a practitioner's point of view this research seems not to address some important aspects of IT projects that we observe: estimating in an industrial environment is performed by people, not models; COTS projects are increasing their market share replacing traditional custom software projects; and industrial projects use a large variety of metrics to size the project deliverables and estimate the costs. Estimation by analogy tools like ANGEL and multiple regression analysis provide the necessary flexibility in terms of choice of input parameters. We describe an experiment to evaluate human performance where the subjects were aided by analogy and regression tools respectively. 68 partners and managers in Andersen Consulting estimated 48 different COTS projects. The results in terms of MMRE indicate that users benefit from both tools, however more from regression models than from analogy models as ANGEL. Furthermore, the performance of the ANGEL tool itself is not superior to the performance of the regression model. This result is contradictory to previous studies that claim that ANGEL outperforms multiple regression.",,E. Stensrud; I. Myrtveit,1998,Conference,Proceedings Fifth International Software Metrics Symposium. Metrics (Cat. No.98TB100262),10.1109/METRIC.1998.731247,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=731247,"Andersen Consulting, Northbrook, IL, USA; NA",IEEE,English,,0-8186-9201-4
IEEE,Using public domain metrics to estimate software development effort,"The authors investigate the accuracy of cost estimates when applying most commonly used modeling techniques to a large-scale industrial data set which is professionally maintained by the International Software Standards Benchmarking Group (ISBSG). The modeling techniques applied are ordinary least squares regression (OLS), analogy based estimation, stepwise ANOVA, CART, and robust regression. The questions addresses in the study are related to important issues. The first is the appropriate selection of a technique in a given context. The second is the assessment of the feasibility of using multi-organizational data compared to the benefits from company-specific data collection. We compare company-specific models with models based on multi-company data. This is done by using the estimates derived for one company that contributed to the ISBSG data set and estimates from using carefully matched data from the rest of the ISBSG data. When using the ISBSG data set to derive estimates for the company, generally poor results were obtained. Robust regression and OLS performed most accurately. When using the company's own data as the basis for estimation, OLS, a CART-variant, and analogy performed best. In contrast to previous studies, the estimation accuracy when using the company's data is significantly higher than when using the rest of the ISBSG data set. Thus, from these results, the company that contributed to the ISBSG data set, would be better off when using its own data for cost estimation.",,R. Jeffery; M. Ruhe; I. Wieczorek,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915512,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915512,"Centre for Adv. Empirical Software Res., New South Wales Univ., Sydney, NSW, Australia; NA; NA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,Evaluating a functional size measurement method for Web applications: an empirical analysis,"This paper describes a laboratory experiment which evaluates OO-method function points for the Web. OOmFPWeb measures the functional size of Web applications using conceptual models that are developed with object-oriented Web solutions (OOWS), an automated software production method for Web applications. OOmFPWeb is evaluated on a range of performance-based and perception-based variables, including efficiency, reproducibility, perceived ease of use, perceived usefulness and intention to use. The results show that OOmFPWeb is efficient when compared to current industry practices. Furthermore, the method produces consistent functional size assessments and is perceived to be easy to use and useful by its users.",,S. Abrahao; G. Poels; O. Pastor,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357921,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357921,"Dept. of Inf. Syst. & Comput., Valencia Univ., Spain; NA; NA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,On the sensitivity of COCOMO II software cost estimation model,"Software cost estimation techniques predict the amount of effort required to develop a software system. Cost estimates are needed throughout the software lifecycle to determine feasibility of software projects and to provide for appropriate allocation or reallocation of available resources. To assess the effect of imprecise evaluations, a comprehensive sensitivity analysis was performed on a major cost estimation model, COCOMO II. Results of this analysis are described and explicated in this paper. To reduce risk of drawing biased conclusions, three different methods for sensitivity analysis were employed: the mathematical analysis of the estimating equation, Monte Carlo simulation, and error propagation. The results of the first two methods are very consistent and confirm expected highest sensitivity of the model to the imprecision of the size estimate. Error propagation allows determination of the combined impact of imprecision in multiple inputs and it is therefore most valuable from the practical point of view. The results obtained by this technique also indicate very strong sensitivity to the imprecision in size estimates. A possible way to cope with imprecise information in software cost estimation is also indicated.",,P. Musilek; W. Pedrycz; Nan Sun; G. Succi,2002,Conference,Proceedings Eighth IEEE Symposium on Software Metrics,10.1109/METRIC.2002.1011321,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1011321,"Dept. of Electr. & Comput. Eng., Alberta Univ., Edmonton, Alta., Canada; Dept. of Electr. & Comput. Eng., Alberta Univ., Edmonton, Alta., Canada; Dept. of Electr. & Comput. Eng., Alberta Univ., Edmonton, Alta., Canada; NA",IEEE,English,1530-1435,0-7695-1339-5
IEEE,A cost estimation model for OEM based military software support,"Military software supportability increasingly becomes a key factor of equipment system supportability, and the proportion of software support cost in the system is rising significantly. Based on the analysis of the processes of supportability design and implementation, the paper proposes several effective methods for estimating software costs in the different stages and aspects, and constructs a general-purpose cost estimation model for military software support. Case studies on real-world projects demonstrate the feasibility and rationality of the model.",military software supportability;cost estimation;software metrics,Yuling Zhu; Y. Zheng,2010,Conference,The 2nd International Conference on Information Science and Engineering,10.1109/ICISE.2010.5690862,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5690862,"Systems Engineering Institute of Engineer Equipments, General Department of Armaments, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China",IEEE,English,2160-1291,978-1-4244-7618-3
IEEE,Estimating Procedure for Function Point Analysis in Korea,This paper introduces the practical guidelines for function point analysis in the Republic of Korea. Function Point Analysis is adopted as a standard method for measuring the functional size of software by Korean government. It was proposed by an international organization. We will present the procedure of counting Function Point during the software implementation phase. The functional size and development cost of software can be estimated from the number of Function Point.,Software Size;Development Cost Estimation;Function Point Analysis;korean Guidelines for FP,B. Kang; J. Lee,2018,Conference,"2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",10.1109/SNPD.2018.8441088,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8441088,"Dept. of Computer & Information Engineering, Daegu University, Daegu city, Republic of Korea; Dept. of Computer Engineering, Woosuk University, Jincheon eup, Repubic of Korea",IEEE,English,,978-1-5386-5889-5
IEEE,Investigating metrics for a development effort prediction model of Web applications,"Although there are metrics proposed in the hypermedia literature to measure hypermedia processes and products, many lack the necessary theoretical and empirical validation. To address these issues, this paper presents the results of a quantitative case study which validated empirically a set of metrics proposed to measure the development effort involved in authoring World Wide Web applications. These metrics adhere to the representational theory of measurement. The results obtained for the case study have shown that three out of four of the proposed metrics presented statistically significant correlations with development effort, suggesting that they may be useful parameters for a prediction model that estimates the effort involved in developing Web applications.",,E. Mendes,2000,Conference,Proceedings 2000 Australian Software Engineering Conference,10.1109/ASWEC.2000.844556,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=844556,"Comput. Sci. Dept., Auckland Univ., New Zealand",IEEE,English,,0-7695-0631-3
IEEE,Ensemble imputation methods for missing software engineering data,"One primary concern of software engineering is prediction accuracy. We use datasets to build and validate prediction systems of software development effort, for example. However it is not uncommon for datasets to contain missing values. When using machine learning techniques to build such prediction systems, handling of incomplete data is an important issue for classifier learning since missing values in either training or test set or in both sets can affect prediction accuracy. Many works in machine learning and statistics have shown that combining (ensemble) individual classifiers is an effective technique for improving accuracy of classification. The ensemble strategy is investigated in the context of incomplete data and software prediction. An ensemble Bayesian multiple imputation and nearest neighbour single imputation method, BAMINNSI, is proposed that constructs ensembles based on two imputation methods. Strong results on two benchmark industrial datasets using decision trees support the method",Machine learning;decision trees;incomplete data;imputation;ensemble;software prediction,B. Twala; M. Cartwright,2005,Conference,11th IEEE International Software Metrics Symposium (METRICS'05),10.1109/METRICS.2005.21,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1509308,"Brunei Univ., Manchester, UK; Brunei Univ., Manchester, UK",IEEE,English,1530-1435,0-7695-2371-4
IEEE,PCA based cost estimation model for agile software development projects,"Agile software development has been attached much importance as a new software engineering methodology as it emphasizes on good communication between the developers, the rapid delivery of software, and change on demand. The metrics and methods from conventional lifecycle models cannot predict accurately for agile projects. We have proposed a new cost estimation model for agile software development projects. In this model we apply Principal Component Analysis to reduce the dimensions of the attributes required and identify the key attributes which have maximum correlation to the development cost; and then use constraint solving approach to satisfy the criteria imposed by agile manifesto. The proposed methodology is found to bet suitable for agile projects as it uses constraint programming to explicitly check for satisfaction of agile manifestos. On comparison with other approaches under research we find that our model provides a low MMRE value i.e.50.63. Our methodology can also be used in case of unavailability of historical data or expert opinion. Hence we can safely say that the proposed cost estimation approach increases the precision and accuracy of estimates; and hence is better suited for the Agile Software Development Projects.",agile development;software cost estimation;factor analysis principal components analysis,S. Garg; D. Gupta,2015,Conference,2015 International Conference on Industrial Engineering and Operations Management (IEOM),10.1109/IEOM.2015.7228109,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7228109,"Department of Computer Engineering, Delhi Technological University (DTU), India; Department of Computer Engineering, Delhi Technological University (DTU), India",IEEE,English,,978-1-4799-6065-1
IEEE,Influence of team size and defect detection technique on inspection effectiveness,"Inspection team size and the set of defect detection techniques used by the team are major characteristics of the inspection design, which influences inspection effectiveness, benefit and cost. The authors focus on the inspection performance of a nominal, that is non-communicating team, similar to the situation of an inspection team after independent individual preparation. We propose a statistical model based on empirical data to calculate the expected values for the inspection effectiveness and effort of synthetic nominal teams. Further, we introduce an economic model to compute the inspection benefits, net gain, and return on investment. With these models we determine (a) the best mix of reading techniques (RTs) to maximize the average inspection performance for a given team size, (b) the optimal team size and RT mix for a given inspection time budget, and (c) the benefit of an additional inspector for a given team size. Main results of the investigation with data from a controlled experiment are: (a) benefits of an additional inspector for a given RT diminished quickly with growing team size, thus, above a given team size a mix of different RTs is more effective and has a higher net gain than using only one RT; (b) the cost-benefit model limits team size, since the diminishing gain of an additional inspector at some point is more than offset by his additional cost.",,S. Biffl; W. Gutjahr,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915516,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915516,"Inst. for Software Technol., Vienna Univ. of Technol., Austria; NA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,Early Phase Cost Models for Agile Software Processes in the US DoD,"Background: Software effort estimates are necessary and critical at an early phase for decision makers to establish initial budgets, and in a government context to select the most competitive bidder for a contract. The challenge is that estimated software requirements is the only size information available at this stage, compounded with the newly increasing adoption of agile processes in the US DoD. Aims: The objectives are to improve cost estimation by investigating available sizing measures, and providing practical effort estimation models for agile software development projects during the contract bidding phase or earlier. Method: The analysis explores the effects of independent variables for product size, peak staff, and domain on effort. The empirical data for model calibration is from 20 industrial projects completed recently for the US DoD, among a larger dataset of recent projects using other lifecycle processes. Results: Statistical results showed that initial software requirements is a valid size metric for estimating agile software development effort. Prediction accuracy improves when peak staff and domain are added as inputs to the cost models. Conclusion: These models may be used for estimates of agile projects, and evaluating software development contract cost proposals with inputs available during the bidding phase or earlier.",agile software processes;software cost estimation;software effort;software size;software requirements;requirements volatility;peak staff;domain;productivity;interfaces,W. Rosa; R. Madachy; B. Clark; B. Boehm,2017,Conference,2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM),10.1109/ESEM.2017.10,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8170082,"IT Estimating Div., Naval Center for Cost Anal., Washington, DC, USA; Dept. of Syst. Eng., Naval Postgrad. Sch., Monterey, CA, USA; Software Metrics, Inc., Haymarket, VA, USA; USC Center for Syst. & Software Eng., Univ. of Southern California, Los Angeles, CA, USA",IEEE,English,,978-1-5090-4039-1
IEEE,Estimating the size of Web applications by using a simplified function point method,"Software size estimation is a key factor to determine the amount of time and effort needed to develop software systems, and the Web applications are no exception. In this paper a simplified way of the IFPUG (International Function Point Users Group) function points based on the simplification ideas suggested by NESMA (Netherlands Software Metrics Association) to estimate size of management information systems is presented. In an empirical study, twenty Web applications were analyzed. The estimates using the simplified method were close to the ones using the IFPUG detailed method. Based on the results, it was possible to establish a simplified method to estimate the size of Web applications according to the development characteristics of the studied company.",,E. J. D. Candido; R. Sanches,2004,Conference,"WebMedia and LA-Web, 2004. Proceedings",10.1109/WEBMED.2004.1348154,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1348154,"Inst. de Ciencias Matematica e de Computacao, Sao Paulo Univ., Brazil; Inst. de Ciencias Matematica e de Computacao, Sao Paulo Univ., Brazil",IEEE,English,,0-7695-2237-8
IEEE,Experimental Study of Quantitative Analysis of Maintenance Effort Using Program Slicing-Based Metrics,"During the software development lifecycle, studies have shown that over 75% of project costs originate from the maintenance phase. Analysis of the processes within the maintenance phase could prove beneficial since most maintenance activities revolve around source code. Accurate estimations of the maintenance effort spent on code changes would enable cost effective management of resources. In this research, we investigate a quantitative approach to express maintenance effort, for which a set of program-sliced metrics is proposed. Using the time to resolve an issue as a measure of maintenance effort, we evaluated our proposed metrics against the basic code-based metrics Lines of Code and McCabe's Cyclomatic Complexity. To eliminate outside factors, we performed an experimental case study on a set of pre-defined maintenance activities. Results suggest that program slicing metrics have the strongest correlation with maintenance effort, exhibiting a moderate degree of correlation with maintenance effort. In contrast, Lines of Code has a weak correlation with maintenance effort. This study contributes to our ongoing research into the analysis of maintenance processes.",Micro Process;Software Metrics;Program Slicing;Software Maintenance,R. G. Kula; K. Fushida; N. Yoshida; H. Iida,2012,Conference,2012 19th Asia-Pacific Software Engineering Conference,10.1109/APSEC.2012.105,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6462781,"NAIST, Ikoma, Japan; R&D Headquarters, NTT Data Corp., Tokyo, Japan; NAIST, Ikoma, Japan; NAIST, Ikoma, Japan",IEEE,English,1530-1362,978-1-4673-4930-7
IEEE,MONSET-a prototype software development estimating tool,"The development of large-scale computer software has traditionally been a difficult cost estimation problem. Software has been developed for more than thirty years and it is reasonable to expect that the experience gained in this time, would make software development effort predictions more reliable. One way by which an organisation can benefit from past projects is to measure, track and control each project and use the collected results to assist future project estimation. This paper describes a hybrid model for software effort prediction and its validation against available data on some large software projects. A prototype software development estimation system (MONSET-Monash Software Estimating Tool) based on the proposed model is described. The system aims to provide guidance for project managers during the software development process.<>",,B. Srinivasan; G. Martin,1994,Conference,Proceedings of 3rd Symposium on Assessments of Quality Software Development Tools,10.1109/AQSDT.1994.315761,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=315761,"Dept. of Comput. Technol., Monash Univ., Clayton, Vic., Australia; Dept. of Comput. Technol., Monash Univ., Clayton, Vic., Australia",IEEE,English,,0-8186-5660-3
IEEE,A fuzzy logic based set of measures for software project similarity: validation and possible improvements,"The software project similarity attribute has not yet been the subject of in-depth study, even though it is often used when estimating software development effort by analogy. Among the inadequacies identified (M. Shepperd et al., 1996; 1997) in most of the proposed measures for the similarity attribute, the most critical is that they are used only when the software projects are described by numerical variables (interval, ratio or absolute scale). However, in practice, many factors which describe software projects, such as the experience of programmers and the complexity of modules, are measured in terms of an ordinal (or nominal) scale composed of qualifications such as 'low' and 'high'. To overcome this limitation, we propose a set of new measures based on fuzzy logic for similarity when the software projects are described by categorical data. The proposed measures are validated by means of an axiomatic validation approach. We also present the results of an empirical validation of our similarity measures, based on the COCOMO'81 database.",,A. Idri; A. Abran,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915518,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915518,"Software Eng. Manage. Res. Lab., UQAM, Montreal, Que., Canada; NA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,Rough set-based data analysis in goal-oriented software measurement,"The analysis of software engineering data is often concerned with the treatment of incomplete knowledge, the management of inconsistent pieces of information and the manipulation of various data representation levels. Existing techniques of data analysis are mainly based on quite strong assumptions (some knowledge about dependencies, probability distributions, and a large number of experiments), are unable to derive conclusions from incomplete knowledge, or cannot manage inconsistent pieces of information. A rough set is a collection of objects which, in general, cannot be precisely characterized in terms of the values of the set of attributes, while a lower and an upper approximation of the collection can do so. Rough sets have been successfully applied for data analysis in different areas. In this paper, the approach is applied to the analysis of software engineering data resulting from goal-oriented measurement. Fundamental principles and concepts of rough sets are presented. They are illustrated by an example predicting the criticality of software modules based on metrics data from the early development phases. In a further application, analysis of COCOMO (COnstructive COst MOdel) cost drivers is studied.",,G. Ruhe,1996,Conference,Proceedings of the 3rd International Software Metrics Symposium,10.1109/METRIC.1996.492439,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=492439,"Inst. for Exp. Software Eng., Fraunhofer Gesellschaft, Kaiserslautern, Germany",IEEE,English,,0-8186-7365-6
IEEE,A vector-based approach to software size measurement and effort estimation,"Software size is a fundamental product measure that can be used for assessment, prediction and improvement purposes. However, existing software size measures, such as function points, do not address the underlying problem complexity of software systems adequately. This can result in disproportional measures of software size for different types of systems. We propose a vector size measure (VSM) that incorporates both functionality and problem complexity in a balanced and orthogonal manner. The VSM is used as the input to a vector prediction model (VPM) which can be used to estimate development effort early in the software life-cycle. We theoretically validate the approach against a formal framework. We also empirically validate the approach with a pilot study. The results indicate that the approach provides a mechanism to measure the size of software systems, classify software systems, and estimate development effort early in the software life-cycle to within /spl plusmn/20% across a range of application types.",,T. E. Hastings; A. S. M. Sajeev,2001,Journal,IEEE Transactions on Software Engineering,10.1109/32.917523,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=917523,"Sch. of Comput. Sci. & Software Eng., Monash Univ., Caulfield East, Vic., Australia; NA",IEEE,English,1939-3520,
IEEE,Understanding of estimation accuracy in software development projects,"Over the past decades large investments in software engineering research and development have been made by academia and the software industry. These efforts have produced considerably insight in the complex domain of software development, and have paid off in the shape of the improved tools, languages, methodologies and techniques. However, a recent review of estimation survey documents that less progress has been made in the area of estimation performance. This is a major concern for the software industry, as lack of estimation performance often causes budget overruns, delays, lost contracts or poor quality software. Because of these rather dramatic consequences, there is a high demand for more research on the topic of effort estimation in software development projects. That demand motivated this PhD. The thesis is written at the Estimation Group at Simula Research Laboratory in Oslo, Norway. The work is supervised by professor Magne Jorgensen, and is part of the SPIKE (Software Process Improvement based on Knowledge and Experience) project which is funded by the Norwegian Research Council",,S. Grimstad,2005,Conference,11th IEEE International Software Metrics Symposium (METRICS'05),10.1109/METRICS.2005.50,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1509320,"Simula Res. Lab., Lysaker, Norway",IEEE,English,1530-1435,0-7695-2371-4
IEEE,Estimating the size of changes for evolving object oriented systems: a case study,"Size related measures have traditionally been the basis for effort estimation models to predict costs of software activities along the entire software product life cycle. Object-Oriented (OO) systems are developed and evolve by adding/removing new classes and modifying existing entities. We propose an approach to predict the size of changes of evolving OO systems based on the analysis of the classes impacted by a change request. Our approach can be used both in iterative development processes or during software maintenance. A first empirical evaluation of the proposed approach has been obtained by applying our tools to the post-release evolution of OO software systems available on the net. The systems were analyzed, and models to predict added modified LOCs from added/modified classes were statistically validated. In the paper preliminary results of the above outlined evaluation is presented.",,G. Antoniol; G. Canfora; A. De Lucia,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809746,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809746,"Fac. of Eng., Sannio Univ., Benevento, Italy; NA; NA",IEEE,English,,0-7695-0403-5
IEEE,Early & Quick function point: sizing more with less,"The Early & Quick technique was originally proposed in 1997 for IFPUG Function Points, to size software in early stages of the development process, when functional requirements are still to be established in a detailed form and/or when a rapid measure is needed for existing software from a high-level viewpoint, within limited time. Typical lack of measurement details and requirements volatility in early project stages are overcome by the E&Q approach to provide a size estimate as a significant contribution to early project planning needs. Fundamental principles of the technique are classification by analogy, functionality structured aggregation, and multilevel approach, with statistical validation of numerical ranges. Recently, the technique has evolved, to fully comply with any functional size measurement method (ISO/IEC 14143:1998), so to cover new generation methods (e.g., COSMIC Full FP 2.2) and updated releases of existing methods (e.g., IFPUG FP 4.1 and 4.2). This paper describes the current technique release 2.0, application cases, validation results, supporting tools, and further improvement directions",,L. Santillo; M. Conte; R. Meli,2005,Conference,11th IEEE International Software Metrics Symposium (METRICS'05),10.1109/METRICS.2005.33,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1509284,"Data Process. Organ., Italy; Data Process. Organ., Italy; Data Process. Organ., Italy",IEEE,English,1530-1435,0-7695-2371-4
IEEE,A neuro-fuzzy tool for software estimation,"Accurate software estimation such as cost estimation, quality estimation and risk analysis is a major issue in software project management. We present a soft computing framework to tackle this challenging problem. We first use a preprocessing neuro-fuzzy inference system to handle the dependencies among contributing factors and decouple the effects of the contributing factors into individuals. Then we use a neuro-fuzzy bank to calibrate the parameters of contributing factors. In order to extend our framework into fields that lack of an appropriate algorithmic model of their own, we propose a default algorithmic model that can be replaced when a better model is available. Validation using industry project data shows that the framework produces good results when used to predict software cost.",,X. Huang; D. Ho; J. Ren; L. F. Capretz,2004,Conference,"20th IEEE International Conference on Software Maintenance, 2004. Proceedings.",10.1109/ICSM.2004.1357862,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357862,"Western Ontario Univ., Canada; NA; NA; NA",IEEE,English,1063-6773,0-7695-2213-0
IEEE,Why we should use function points [software metrics],"Function point analysis helps developers and users quantify the size and complexity of software application functions in a way that is useful to software users. Are function points a perfect metric? No. Are they a useful metric? In the author's experience, yes. Function points are technologically independent, consistent, repeatable, and help normalize data, enable comparisons, and set project scope and client expectations. The author addresses these issues from the perspective of a practitioner who uses the International Function Point Users Group's Counting Practices Manual, Release 4.0 rules for counting function points. Of course, other function point standards exist, including Mark II and Albrecht's original rules.",,S. Furey,1997,Magazine,IEEE Software,10.1109/52.582971,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=582971,"American Manage. Syst., USA",IEEE,English,1937-4194,
IEEE,Evaluating software reuse alternatives: a model and its application to an industrial case study,"We propose a model that enables software developers to systematically evaluate and compare all possible alternative reuse scenarios. The model supports the clear identification of the basic operations involved and associates a cost component with each basic operation in a focused and precise way. The model is a practical tool that assists developers to weigh and evaluate different reuse scenarios, based on accumulated organizational data, and then to decide which option to select in a given situation. The model is currently being used at six different companies for cost-benefit analysis of alternative reuse scenarios; we give a case study that illustrates how it has been used in practice.",Index Terms- Reuse models;cost estimation;maintenance management;software libraries;process metrics;process measurement;planning.,A. Tomer; L. Goldin; T. Kuflik; E. Kimchi; S. R. Schach,2004,Journal,IEEE Transactions on Software Engineering,10.1109/TSE.2004.50,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1324647,"RAFAEL Ltd., Haifa, Israel; NA; NA; NA; NA",IEEE,English,1939-3520,
IEEE,An empirical assessment of function point-like object-oriented metrics,"Since object-oriented programming became a popular development practice, researchers and practitioners have defined several techniques aimed at measuring object-oriented software. Among these, several function point-like approaches have been proposed. However, mapping the concepts at the basis of function point analysis onto object-oriented concepts is not straightforward; therefore, there is the need to test the validity of FP-based object-oriented metrics. This paper presents an analysis of a set of programs developed by masteral students of a software engineering course employing object-oriented techniques (UML and Java). Different kinds of FP-based object-oriented metrics were applied, and the results analysed. The work done addresses questions like the following: is there a correlation between object-oriented FPs and LOCs? How do object-oriented FPs compare with the function points defined by Albrecht? How do object-oriented FPs compare with non FP-like OO metrics? How do object-oriented FPs compare with each other?",Object-oriented systems;size measures;Function Point Analysis;empirical validation,V. Del Bianco; L. Lavazza,2005,Conference,11th IEEE International Software Metrics Symposium (METRICS'05),10.1109/METRICS.2005.9,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1509318,"CEFRIEL, Politecnico di Milano, Milan, Italy; CEFRIEL, Politecnico di Milano, Milan, Italy",IEEE,English,1530-1435,0-7695-2371-4
IEEE,Analyzing Effect of Ensemble Models on Multi-Layer Perceptron Network for Software Effort Estimation,"Effort Estimation is a very challenging task in the software development life cycle. Inaccurate estimations may cause client dissatisfaction and thereby, decrease the quality of the product. Considering the problem of software cost and effort estimation, it is conceivable to call attention to that the estimation procedure considers the qualities present in the data set, as well as the aspects of the environment in which the model is embedded. Existing literature have the instances where machine learning techniques have been used to estimate the effort required to develop any software. Yet it is quite uncertain for any particular model to perform well with all the data sets. In this paper, Multi-Layer Perceptron (MLPNN) and its ensembles are explored in order to improve the performance of software effort estimation process. Firstly, MLPNN, Ridge-MLPNN, Lasso-MLPNN, Bagging-MLPNN, and AdaBoost-MLPNN models are developed and, then, the performance of these models are compared on the basis of R2 score to find the best model fitting this dataset. Results obtained from the study demonstrate that the R2 score of AdaBoost-MLPNN is 82.213%, which is highest among all the models.",Machine Learning;Software Metrics;Predictive Model;Effort Estimation,S. Shukla; S. Kumar; P. R. Bal,2019,Conference,2019 IEEE World Congress on Services (SERVICES),10.1109/SERVICES.2019.00116,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8817267,Indian Institute of Technology Roorkee; Indian Institute of Technology Roorkee; Indian Institute of Technology Roorkee,IEEE,English,2642-939X,978-1-7281-3851-0
IEEE,Features-Level Software Effort Estimation Using Machine Learning Algorithms,"Software effort estimation is a paramount mission in the software development process, which covered by project managers and software engineers. In the early stages, software system features are the only available measures. Therefore, cost estimation is a mission that comes under the planning stage of software venture management. In this paper, various machine learning algorithms are used to build software effort estimation models from software features. Artificial Neural Network (ANN), Support Vector Machines (SVM), K-star, and Linear Regression machine learning algorithms are evaluated on a public dataset with actual software efforts. Results showed that machine learning approach can be dependable on predicting the future effort of a software system.",machine learning;software development;effort estimation;cost estimation,M. Hammad; A. Alqaddoumi,2018,Conference,"2018 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)",10.1109/3ICT.2018.8855752,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8855752,"Department of Computer Science, Mutah University, Al Karak, Jordan; Department of Computer Science, University of Bahrain, Sakheer, Bahrain",IEEE,English,,978-1-5386-9207-3
IEEE,Applications of measurement in product-focused process improvement: a comparative industrial case study,"In ESPRIT project PROFES, measurement according to the Goal/Question/Metric (GQM) approach is conducted in industrial software projects at Drager Medical Technology, Ericsson Finland, and Schlumberger Retail Petroleum Systems. A comparative case study investigates three different ways of applying GQM in product-focused process improvement: long-term GQM measurement programmes at the application sites to better understand and improve software products and processes; GQM-based construction and validation of product/process dependency models, which describe the process impact on software quality; and cost/benefit investigation of the PROFES improvement methodology using GQM for (meta-) analysis of improvement programmes. This paper outlines how GQM is applied for these three purposes.",,A. Birk; P. Derks; D. Hamann; J. Hirvensalo; M. Oivo; E. Rodenbach; R. van Solingen; J. Taramaa,1998,Conference,Proceedings Fifth International Software Metrics Symposium. Metrics (Cat. No.98TB100262),10.1109/METRIC.1998.731234,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=731234,"Fraunhofer IESE, Kaiserslautern, Germany; NA; NA; NA; NA; NA; NA; NA",IEEE,English,,0-8186-9201-4
IEEE,An Analysis of Cost-Overrun Projects Using Financial Data and Software Metrics,"To clarify the characteristics of cost-overrun software projects, this paper focuses on the cost to sales ratio of software development, computed from financial information of a midsize software company in the embedded systems domain, and analyzes the correlation with outsourcing ratio as well as code reuse ratio and relative effort ratio per development phase. As a result, we found that the lower cost to sales ratio projects had the higher relative effort ratio in external design phase, which indicates that spending less effort in external design can cause decrease of profit. We also found that high outsourcing ratio projects had higher cost to sales ratio, and that projects having moderate code reuse ratio had lower and disperse cost to sales ratio, which suggests troubles in code reuse can damage the profit of a project.",Cost overrun project;Cost to sales ratio;Development phase;Outsourcing;Reuse,H. Uwano; Y. Kamei; A. Monden; K. Matsumoto,2011,Conference,2011 Joint Conference of the 21st International Workshop on Software Measurement and the 6th International Conference on Software Process and Product Measurement,10.1109/IWSM-MENSURA.2011.9,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6113064,"Dept. of Inf. Eng., Nara Nat. Coll. of Technol., Nara, Japan; Fac. of Inf. Sci. & Electr. Eng., Kyushu Univ., Fukuoka, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan",IEEE,English,,978-1-4577-1930-1
IEEE,A simulation study of the model evaluation criterion MMRE,"The mean magnitude of relative error, MMRE, is probably the most widely used evaluation criterion for assessing the performance of competing software prediction models. One purpose of MMRE is to assist us to select the best model. In this paper, we have performed a simulation study demonstrating that MMRE does not always select the best model. Our findings cast some doubt on the conclusions of any study of competing software prediction models that use MMRE as a basis of model comparison. We therefore recommend not using MMRE to evaluate and compare prediction models. At present, we do not have any universal replacement for MMRE. Meanwhile, we therefore recommend using a combination of theoretical justification of the models that are proposed together with other metrics proposed in this paper.",,T. Foss; E. Stensrud; B. Kitchenham; I. Myrtveit,2003,Journal,IEEE Transactions on Software Engineering,10.1109/TSE.2003.1245300,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1245300,"Norwegian Sch. of Manage., Sandvika, Norway; NA; NA; NA",IEEE,English,1939-3520,
IEEE,Empirical studies of software cost estimation: training of effort estimation uncertainty assessment skills,"This research abstract describes my proposed doctorial work within the field of software project cost and effort estimation. My work focuses on assessment of uncertainty of software development cost or effort estimates. In particular, the work focuses on to which degree this assessment is a skill that can be improved with better training. Work completed includes one small scale experiment with student participants. A follow-up, larger, experiment with professional software developers is currently in progress. Studies targeted towards better understanding of the mental processes of development of work effort estimates and uncertainty assessments will be the next step. This work aims at the development of effective training processes of estimation and uncertainty assessment skills. Through the METRICS05 dissertation forum I hope to receive feedback on the viability and relevance of the proposed work within the software cost and effort estimation field",,T. Gruschke,2005,Conference,11th IEEE International Software Metrics Symposium (METRICS'05),10.1109/METRICS.2005.19,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1509326,"Oslo Univ., Norway",IEEE,English,1530-1435,0-7695-2371-4
IEEE,The impact of design properties on development cost in object-oriented systems,"In the context of software cost estimation, system size is widely taken as a main driver of system development effort, but other structural design properties, such as coupling, cohesion and complexity, have been suggested as additional cost factors. In this paper, using effort data from an object-oriented development project, we empirically investigate the relationship between class size and the development effort for a class, and what additional impact structural properties such as class coupling have on effort. We use Poisson regression and regression trees to build cost prediction models from size and design measures, and use these models to predict the system development effort. We also investigate a technique to combine regression trees with regression analysis, which aims at building more accurate models. The results indicate that fairly accurate predictions of class effort can be made based on simple measures of the class interface size alone; mean MREs (magnitudes of relative error) are below 30%. Effort predictions at the system level are even more accurate as, using bootstrapping, the estimated 95% confidence interval for MREs is 3%-23%, but more sophisticated coupling and cohesion measures do not help to improve these predictions to a degree that would be practically significant. However, the use of hybrid models, combining Poisson regression and CART (classification and regression trees) clearly improves the accuracy of the models as compared to using Poisson regression alone.",,L. C. Briand; J. Wust,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915534,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915534,"Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, Ont., Canada; NA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,Conceptual Association of Functional Size Measurement Methods,"Functional size determines how much functionality software provides by measuring the aggregate amount of its cohesive execution sequences. Alan Albrecht first introduced the concept in 1979. Since he originally described the function point analysis (FPA) method, researchers and practitioners have developed variations of functional size metrics and methods. The authors discuss the conceptual similarities and differences between functional size measurement methods and introduce a model for unification.",management;cost estimation;product metrics,O. Demirors; C. Gencel,2009,Magazine,IEEE Software,10.1109/MS.2009.60,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4814963,Middle East Technical University; Blekinge Institute of Technology,IEEE,English,1937-4194,
IEEE,US DoD Application Domain Empirical Software Cost Analysis,"General software cost parameters such as size, effort distribution, and productivity are necessarily imprecise due to variations by domain. To improve this situation, empirical software cost analysis using the primary US DoD cost database has been segmented by domain. This analysis supports a software cost estimation metrics manual for improvements in acquisition policies, procedures and tools. We have addressed the challenges of consistent data definitions and taxonomies across diverse stakeholder communities, data integrity, data formats, and others. We highlight example analysis results from an application domain demonstrating cost estimating relationships, benchmarks on reuse parameters and effort distributions for estimators to use.",software cost estimation;software metrics;software cost models;software productivity;Department of Defense,R. Madachy; B. Boehm; B. Clark; T. Tan; W. Rosa,2011,Conference,2011 International Symposium on Empirical Software Engineering and Measurement,10.1109/ESEM.2011.56,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6092596,"Dept. of Syst. Eng., Naval Postgrad. Sch., Monterey, CA, USA; USC Center for Syst. & Software Eng., Univ. of Southern California, Los Angeles, CA, USA; USC Center for Syst. & Software Eng., Univ. of Southern California, Los Angeles, CA, USA; USC Center for Syst. & Software Eng., Univ. of Southern California, Los Angeles, CA, USA; Inf. Technol. Div., Air Force Cost Anal. Agency, Arlington, VA, USA",IEEE,English,1949-3789,978-1-4577-2203-5
IEEE,A Structured Framework for Software Metrics Based on Three Primary Metrics,"This paper presents a structured unifying framework for software metrics (numerical software measurements), based on the three ""primary metrics"" of function points (FP), person-months (PM), and lines of code (LOC). The framework is based on a layered model, with the three primary metrics constituting the lowest layer. An important property of the primary metrics, referred to as the ""convertibility property"" is that a primary metric can easily be converted to another primary metric. Time is also included in this layer as a fundamental (not necessarily software) primary metric. The second layer consists of general-purpose metrics such as productivity measures, which are computed from the primary metrics, and the third layer consists of specialpurpose metrics such as reliability and quality measures. This third layer is inherently extensible. The framework readily lends itself for use in both instructional and practitioner environments.",software;metrics,K. Akingbehin,2010,Conference,2010 IEEE/ACIS 9th International Conference on Computer and Information Science,10.1109/ICIS.2010.158,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=5591049,"Dept. of Comput. & Inf. Sci., Univ. of Michigan-Dearborn, Dearborn, MI, USA",IEEE,English,,978-1-4244-8198-9
IEEE,Definition and experimental evaluation of function points for object-oriented systems,"We present a method for estimating the size, and consequently effort and duration, of object oriented software development projects. Different estimates may be made in different phases of the development process, according to the available information. We define an adaptation of traditional function points, called Object Oriented Function Points, to enable the measurement of object oriented analysis and design specifications. Tools have been constructed to automate the counting method. The novel aspect of our method is its flexibility. An organisation can experiment with different counting policies, to find the most accurate predictors of size, effort, etc. in its environment. The method and preliminary results of its application in an industrial environment are presented and discussed.",,G. Caldiera; G. Antoniol; R. Fiutem; C. Lokan,1998,Conference,Proceedings Fifth International Software Metrics Symposium. Metrics (Cat. No.98TB100262),10.1109/METRIC.1998.731242,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=731242,"Price Waterhouse Coopers, Fairfax, VA, USA; NA; NA; NA",IEEE,English,,0-8186-9201-4
IEEE,A Two-Step Model for Defect Density Estimation,"Identifying and locating defects in software projects is a difficult task. Further, estimating the density of defects is more difficult. Measuring software in a continuous and disciplined manner brings many advantages such as accurate estimation of project costs and schedules, and improving product and process qualities. Detailed analysis of software metric data gives significant clues about the locations and magnitude of possible defects in a program. The aim of this research is to establish an improved method for predicting software quality via identifying the defect density of fault prone modules using machine-learning techniques. We constructed a two-step model that predicts defect density by taking module metric data into consideration. Our proposed model utilizes classification and regression type learning methods consecutively. The results of the experiments on public data sets show that the two-step model enhances the overall performance measures as compared to applying only regression methods.",,O. Kutlubay; B. Turhan; A. B. Bener,2007,Conference,33rd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO 2007),10.1109/EUROMICRO.2007.13,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4301095,Bogazici University; Bogazici University; Bogazici University,IEEE,English,2376-9505,978-0-7695-2977-6
IEEE,Reliability and validity in comparative studies of software prediction models,"Empirical studies on software prediction models do not converge with respect to the question ""which prediction model is best?"" The reason for this lack of convergence is poorly understood. In this simulation study, we have examined a frequently used research procedure comprising three main ingredients: a single data sample, an accuracy indicator, and cross validation. Typically, these empirical studies compare a machine learning model with a regression model. In our study, we use simulation and compare a machine learning and a regression model. The results suggest that it is the research procedure itself that is unreliable. This lack of reliability may strongly contribute to the lack of convergence. Our findings thus cast some doubt on the conclusions of any study of competing software prediction models that used this research procedure as a basis of model comparison. Thus, we need to develop more reliable research procedures before we can have confidence in the conclusions of comparative studies of software prediction models.",Index Terms- Software metrics;cost estimation;cross-validation;empirical methods;arbitrary function approximators;machine learning;estimation by analogy;regression analysis;simulation;reliability;validity;accuracy indicators.,I. Myrtveit; E. Stensrud; M. Shepperd,2005,Journal,IEEE Transactions on Software Engineering,10.1109/TSE.2005.58,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1438374,"Norwegian Sch. of Manage. BI, Sandvika, Norway; NA; NA",IEEE,English,1939-3520,
IEEE,Software defect prediction using software metrics - A survey,"Traditionally software metrics have been used to define the complexity of the program, to estimate programming time. Extensive research has also been carried out to predict the number of defects in a module using software metrics. If the metric values are to be used in mathematical equations designed to represent a model of the software process, metrics associated with a ratio scale may be preferred, since ratio scale data allow most mathematical operations to meaningfully apply. Work on the mechanics of implementing metrics programs. The goal of this research is to help developers identify defects based on existing software metrics using data mining techniques and thereby improve software quality which ultimately leads to reducing the software development cost in the development and maintenance phase. This research focuses in identifying defective modules and hence the scope of software that needs to be examined for defects can be prioritized. This allows the developer to run test cases in the predicted modules using test cases. The proposed methodology helps in identifying modules that require immediate attention and hence the reliability of the software can be improved faster as higher priority defects can be handled first. Our goal in this research focuses to improve the classification accuracy of the Data mining algorithm. To initiate this process we initially propose to evaluate the existing classification algorithms and based on its weakness we propose a novel Neural network algorithm with a degree of fuzziness in the hidden layer to improve the classification accuracy.",Software defect prediction;software defectproneness prediction;machine learning;scheme evaluation,K. Punitha; S. Chitra,2013,Conference,2013 International Conference on Information Communication and Embedded Systems (ICICES),10.1109/ICICES.2013.6508369,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6508369,"Bhajarang Engineering College, Tiruvallur, Chennai, TamilNadu, India; Er. Perumal Manimekalai College of Engineering, Hosur, Krishnagiri, Tamil Nadu, India",IEEE,English,,978-1-4673-5788-3
IEEE,MMWA: a software sizing model for Web applications,"Estimating time and costs is a crucial factor in application development projects and low error margins are a priority. In line with the very fast evolution of Internet technologies, all applications are quickly becoming Web applications, which are growing without a consolidated project methodology. Thus there is a clear need for an estimation model for these applications' development projects. The aim of the present paper is to illustrate a new Web application cost estimation model that can form the starting point for any development project. The estimation model described in this paper is called MMWA (metrics model for Web applications). This is an ""early measures model"", since the measurements are effected at the start of the software life cycle, with a view to accurately estimate time and costs so that the right decisions can be taken concerning the development of the Web application in hand.",,L. Mangia; R. Paiano,2003,Conference,"Proceedings of the Fourth International Conference on Web Information Systems Engineering, 2003. WISE 2003.",10.1109/WISE.2003.1254469,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1254469,"Dipto. Ingegneria dell'Innovazione, Universita di Lecce, Italy; Dipto. Ingegneria dell'Innovazione, Universita di Lecce, Italy",IEEE,English,,0-7695-1999-7
IEEE,Function point measurement tool for UML design specification,"Function point analysis (FPA) was originally proposed to help measure the size of a computerized business information system. It is now widely used in actual software development. However, it has been reported that, since function point counting involves judgment on the part of the counter, some differences would be caused between copies of the same product, even within the same organization. In this paper, we propose detailed FPA measurement rules for design specifications based on UML (Unified Modeling Language) and we develop a function point measurement tool, whose input products are design specifications on Rational Rose. We have also applied the tool in an actual design specification and have examined the difference between the values obtained using the tool and those given by an FPA specialist. The results show the applicability of our tool.",,T. Uemura; S. Kusumoto; K. Inoue,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809727,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809727,"Graduate Sch. of Eng. Sci., Osaka Univ., Japan; NA; NA",IEEE,English,,0-7695-0403-5
IEEE,Analyzing effects of cost estimation accuracy on quality and productivity,"This paper discusses the effects of estimation accuracy for software development cost on both the quality of the delivered code and the productivity of the development team. The estimation accuracy is measured by metric RE (relative error). The quality and productivity are measured by metrics FQ (field quality) and TP (team productivity). Using actual project data on thirty-one projects at a certain company, the following are verified by correlation analysis and testing of statistical hypotheses. There is a high correlation between the faithfulness of the development plan to standards and the value of RE (a coefficient of correlation between them is -0.60). Both FQ and TP are significantly different between projects with -10%<RE<+10% and projects with RE/spl ges/+10% (the level of significance is chosen as 0.05).",,O. Mizuno; T. Kikuno; K. Inagaki; Y. Takagi; K. Sakamoto,1998,Conference,Proceedings of the 20th International Conference on Software Engineering,10.1109/ICSE.1998.671596,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=671596,"Graduate Sch. of Eng. Sci., Osaka Univ., Japan; NA; NA; NA; NA",IEEE,English,0270-5257,0-8186-8368-6
IEEE,Measuring metadata-based aspect-oriented code in model-driven engineering,"Metrics measurement for cost estimation in model-driven engineering (MDE) is complex because of number of different artifacts that can potentially be generated. The complexity arises as auto-generated code, manually added code, and non-code artifacts must be sized separately for their contribution to overall effort. In this paper, we address measurement of a special kind of code artifacts called metadata-based aspect-oriented code. Our MDE toolset delivers large database-centric business-critical enterprise applications. We cater to special needs of enterprises by providing support for customization along three concerns, namely design strategies, architecture, and technology platforms (〈d, a, t〉) in customer-specific applications. Code that is generated for these customizations is conditional in nature, in the sense that model-to-text transformation takes place differently based on choices along these concerns. In our recent efforts to apply Constructive Cost Model (COCOMO) II to our MDE practices, we discovered that while the measurement of the rest of code and non-code artifacts can be easily automated, product-line-like nature of code generation for specifics of 〈d, a, t〉 requires special treatment. Our contribution is the use of feature models to capture variations in these dimensions and their mapping to code size estimates. Our initial implementation suggests that this approach scales well considering the size of our applications and takes a step forward in providing complete cost estimation for MDE applications using COCOMO II.",,S. Sunkle; V. Kulkarni; S. Roychoudhury,2012,Conference,2012 3rd International Workshop on Emerging Trends in Software Metrics (WETSoM),10.1109/WETSoM.2012.6226990,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6226990,"Tata Research Development and Design Center, Tata Consultancy Services, 54B, Industrial Estate, Hadapsar, Pune, 411013 India; Tata Research Development and Design Center, Tata Consultancy Services, 54B, Industrial Estate, Hadapsar, Pune, 411013 India; Tata Research Development and Design Center, Tata Consultancy Services, 54B, Industrial Estate, Hadapsar, Pune, 411013 India",IEEE,English,2327-0969,978-1-4673-1762-7
IEEE,The Internal Revenue Service function point analysis program: a brief,"The Internal Revenue Service (IRS) Information Systems has been using function point analysis since 1993 as the foundation of its software metrics program. Using function point analysis, the IRS has significantly improved the quality of its software project management as measured by the SEI Capability Maturity Model. The IRS can determine the size of its software about four times faster than industry averages can estimate software size and resource requirements for new development projects as soon as the central data model is known, and can accurately size small software work orders and estimate corresponding resources needed without examining the software or meeting with the project team. Each of these methodologies qualify at least at CMM Level 2.",,C. B. Tichenor,1997,Conference,Proceedings Twenty-First Annual International Computer Software and Applications Conference (COMPSAC'97),10.1109/CMPSAC.1997.625077,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=625077,,IEEE,English,0730-3157,0-8186-8105-5
IEEE,Test blueprint: an effective visual support for test coverage,"Test coverage is about assessing the relevance of unit tests against the tested application. It is widely acknowledged that a software with a ""good"" test coverage is more robust against unanticipated execution, thus lowering the maintenance cost. However, insuring a coverage of a good quality is challenging, especially since most of the available test coverage tools do not discriminate software components that require a ""strong"" coverage from the components that require less attention from the unit tests. HAPAO is an innovative test covepage tool, implemented in the Pharo Smalltalk programming language. It employs an effective and intuitive graphical representation to visually assess the quality of the coverage. A combination of appropriate metrics and relations visually shapes methods and classes, which indicates to the programmer whether more effort on testing is required. This paper presents the essence of HAPAO using a real world case study.",coverage;pharo;testing;visualization,V. P. Araya,2011,Conference,2011 33rd International Conference on Software Engineering (ICSE),10.1145/1985793.1986022,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=6032614,"University of Chile, Santiago, Chile",IEEE,English,1558-1225,978-1-4503-0445-0
IEEE,A change prediction model for embedded software applications,"A key aspect of effective software development is the ability to quantify and predict software product quality. Software quality is the degree to which software possesses desired attributes, including portability, reliability, testability and maintainability. Insofar as software with high change traffic affects its maintainability and reliability, a model which produces a change-traffic predictor metric may be useful. The information such a model would provide could be used to help estimate the development cost and effort. Resources could be better allocated to those areas where additional attention may be required. Software changes normally occur due to new requirements or errors in the software, and so a change-traffic metric is not necessarily a good proxy for errors. Users should define their thresholds and ranges of acceptability. This paper identifies metrics collected from embedded Ada software that had a correlation with the change traffic of that software. Using multiple linear regression analysis and sample data from up to 287 embedded Ada software modules, change prediction models yielded values for the average absolute difference between predicted and actual changes per module of less than 3, and an adjusted-R/sup 2/ value of 0.57 for the full sample.",,K. J. Cronin; D. G. Linton,1998,Conference,Proceedings IEEE Southeastcon '98 'Engineering for a New Era',10.1109/SECON.1998.673277,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=673277,"Lockheed Martin, Orlando, FL, USA; NA",IEEE,English,,0-7803-4391-3
IEEE,Building a software cost estimation model based on categorical data,"The paper explores the possibility of generating a multi-organisational software cost estimation model by analysing the software cost data collected by the International Software Benchmarking Standards Group. This database contains data about recently developed projects characterised mostly by attributes of categorical nature such as the project business area, organisation type, application domain and usage of certain tools or methods. The generation of the model is based on a statistical technique which has been proposed as alternative to the standard regression approach, namely the categorical regression or regression with optimal scaling. This technique starts with the quantification of the qualitative attributes (expressed either on nominal or ordinal scale), that appear frequently within such data, and proceeds by using the obtained scores as independent variables of a regression model. The generated model is validated by measuring certain indicators of accuracy.",,L. Angelis; I. Stamelos; M. Morisio,2001,Conference,Proceedings Seventh International Software Metrics Symposium,10.1109/METRIC.2001.915511,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=915511,"Dept. of Inf., Thessaloniki Univ., Greece; NA; NA",IEEE,English,1530-1435,0-7695-1043-4
IEEE,Impact of Budget and Schedule Pressure on Software Development Cycle Time and Effort,"As excessive budget and schedule compression becomes the norm in today's software industry, an understanding of its impact on software development performance is crucial for effective management strategies. Previous software engineering research has implied a nonlinear impact of schedule pressure on software development outcomes. Borrowing insights from organizational studies, we formalize the effects of budget and schedule pressure on software cycle time and effort as U-shaped functions. The research models were empirically tested with data from a 25 billion/year international technology firm, where estimation bias is consciously minimized and potential confounding variables are properly tracked. We found that controlling for software process, size, complexity, and conformance quality, budget pressure, a less researched construct, has significant U-shaped relationships with development cycle time and development effort. On the other hand, contrary to our prediction, schedule pressure did not display significant nonlinear impact on development outcomes. A further exploration of the sampled projects revealed that the involvement of clients in the software development might have ldquoerodedrdquo the potential benefits of schedule pressure. This study indicates the importance of budget pressure in software development. Meanwhile, it implies that achieving the potential positive effect of schedule pressure requires cooperation between clients and software development teams.",Cost estimation;time estimation;schedule and organizational issues;systems development.,N. Nan; D. E. Harter,2009,Journal,IEEE Transactions on Software Engineering,10.1109/TSE.2009.18,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4815275,"University of Oklahoma, Norman; Syracuse University, Syracuse",IEEE,English,1939-3520,
IEEE,Development of analogy-based estimation method for software development cost estimation in government agencies,"Cost estimation for software development in Government Agencies is still considered as a challenge. Owner Estimate Cost (OEC) should be estimated based on the specifications at the early stage of the procurement. There is no standard used by the government in formulating technical specifications. This affects the OEC value that tends to be highly subjective. Therefore, it is important to develop an estimation method that is able to represent software complexity at the early stage of procurement. The approach that can be considered in the early stages is the Use Case approach. UCP is a method to calculating effort algorithmically using use case complexity. However, UCP has a limitation, which only provides a level of fixed complexity and cannot handle uncertain conditions. In the other hand, Some previous research result shows that the analogy method has better performance than the algorithmic method. In this study, we developed the effort and cost estimation methods based on analogy by building a new dataset using the use case complexity parameters. Datasets are collected from 100 historical software projects data that have been built using the UCP method approach. Cost components for the project follow the current procurement regulations in Indonesia. Dataset evaluation for effort estimation using the proposed analogy method shows the best results of MMRE of 0.36 and PRED(0.25) of 0.57. MMRE shows the average difference of actual effort and estimated effort, whereas PRED (0.25) shows prediction level with error value smaller or equal to 25%. Furthermore, the estimated cost of the three software projects resulted in an average percentage deviation of 7.37%.",Analogy-Based Estimation;Use Case Points;Software Cost Estimation;Effort Estimation,I. Kurniawan; A. A. Arman; S. Mardiyanto,2017,Conference,2017 6th International Conference on Electrical Engineering and Informatics (ICEEI),10.1109/ICEEI.2017.8312460,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=8312460,"School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",IEEE,English,2155-6830,978-1-5386-0475-5
IEEE,Further comparison of cross-company and within-company effort estimation models for Web applications,"This paper extends a previous study, using data on 67 Web projects from the Tukutuku database, investigating to what extent a cross-company cost model can be successfully employed to estimate effort for projects that belong to a single company, where no projects from this company were used to build the cross-company model. Our within-company model employed data on 14 Web projects from a single Web company. Our results were similar to those from the previous study, showing that predictions based on the within-company model were significantly more accurate than those based on the cross-company model. We also found that predictions were very poor when the within-company cost model was used to estimate effort for 53 Web projects from different companies. We analysed the data using two techniques, forward stepwise regression and case-based reasoning. We found estimates produced using stepwise regression models were better for the within company model while case-based reasoning predictions were better for the cross-company model.",,E. Mendes; B. Kitchenham,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357920,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357920,"Dept. of Comput. Sci., Auckland Univ., New Zealand; NA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,Comparative Study on Applicability of WEBMO in Web Application Cost Estimation within Klang Valley in Malaysia,"Parametric Web application cost estimation is referred to the usage of mathematical model to derive the estimated effort and duration of Web application development. Typically, majority of Web application developers are applying expert judgment and estimation by analogy in Web application development. This paper is focusing on feasibility study of WEBMO (Web model), a parametric Web application cost estimation model, in Web application development within Klang Valley in Malaysia. WEBCOMO, a parametric Web application tool is developed based on WEBMOpsilas methodology to fulfill the objective of the study.",WEBMO;web application cost estimation;WEBCOMO;parametric software cost estimation;software cost estimation tool;software cost estimation;parametric cost estimation tool,T. C. Hooi; Y. Yusoff; Z. Hassan,2008,Conference,2008 IEEE 8th International Conference on Computer and Information Technology Workshops,10.1109/CIT.2008.Workshops.48,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4568489,NA; NA; NA,IEEE,English,,978-0-7695-3242-4
IEEE,An empirical validation of the relationship between the magnitude of relative error and project size,"Cost estimates are important deliverables of a software project. Consequently, a number of cost prediction models have been proposed and evaluated. The common evaluation criteria have been MMRE, MdMRE and PRED(k). MRE is the basic metric in these evaluation criteria. The implicit rationale of using a relative error measure like MRE, rather than an absolute one, is presumably to have a measure that is independent of project size. We investigate if this implicit claim holds true for several data sets: Albrecht, Kemerer, Finnish, DMR and Accenture-ERP. The results suggest that MRE is not independent of project size. Rather, MRE is larger for small projects than for large projects. A practical consequence is that a project manager predicting a small project may falsely believe in a too low MRE. Vice versa when predicting a large project. For researchers, it is important to know that MMRE is not an appropriate measure of the expected MRE of small and large projects. We recommend therefore that the data set be partitioned into two or more subsamples and that MMRE is reported per subsample. In the long term, we should consider using other evaluation criteria.",,E. Stensrud; T. Foss; B. Kitchenham; I. Myrtveit,2002,Conference,Proceedings Eighth IEEE Symposium on Software Metrics,10.1109/METRIC.2002.1011320,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1011320,"Norwegian Sch. of Manage., Norway; Norwegian Sch. of Manage., Norway; NA; NA",IEEE,English,1530-1435,0-7695-1339-5
IEEE,A Size Estimation Model for Board-Based Desktop Games,"Software size estimation plays a key role in the planning of projects at the time of project inception. This paper describes the derivation, validation, and usage of a parametric model meant for estimating the size of board-based desktop games. This model is derived using forward stepwise multiple linear regression on a data set comprising over 60 open source board-based games collected from multiple open source repositories. A variety of prediction accuracy metrics (e.g., MMRE, PRED(x), MdMRE, and so on) are used to assess this model and K-fold cross-validation is used to validate this model. Model assessment and validation exercises yield promising results. The utility of this model is demonstrated by presenting a worked-out game size estimation example followed by some size-related what-if analyses.",Linear regression;model fitting;model validation;open source software;software cost estimation;software games;software project management;software sizing,N. Sabahat; A. A. Malik; F. Azam,2017,Journal,IEEE Access,10.1109/ACCESS.2017.2678459,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7875479,"Department of Computer Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Lahore, Pakistan; Department of Computer Engineering, National University of Sciences and Technology, Islamabad, Pakistan",IEEE,English,2169-3536,
IEEE,Resource estimation for Web applications,"In the field of software engineering, several empirical methods have been developed to model software projects before they are undertaken to provide an estimate of required effort, development time and cost. In the case of Web applications, this process is complicated by their complexity, multitiered nature, extensive use of noncode artifacts such as multimedia and often short time-scales. In this paper we describe a simple, highly adaptable model using COSMIC full function points for application size measurement and design patterns as a measurement reference. Rather than a true derived model the aim is to provide a procedural framework for expert judgement which guides the practitioner through the estimation process, seeking to limit or mitigate variance in their judgement through algorithmic or statistical techniques. This hybrid has so far proven as accurate as expert judgement while remaining capable of application by a relatively inexperienced estimator.",,P. Umbers; G. Miles,2004,Conference,"10th International Symposium on Software Metrics, 2004. Proceedings.",10.1109/METRIC.2004.1357922,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1357922,"Internistic Ltd., Birmingham, UK; NA",IEEE,English,1530-1435,0-7695-2129-0
IEEE,Optimal project feature weights in analogy-based cost estimation: improvement and limitations,"Cost estimation is a vital task in most important software project decisions such as resource allocation and bidding. Analogy-based cost estimation is particularly transparent, as it relies on historical information from similar past projects, whereby similarities are determined by comparing the projects' key attributes and features. However, one crucial aspect of the analogy-based method is not yet fully accounted for: the different impact or weighting of a project's various features. Current approaches either try to find the dominant features or require experts to weight the features. Neither of these yields optimal estimation performance. Therefore, we propose to allocate separate weights to each project feature and to find the optimal weights by extensive search. We test this approach on several real-world data sets and measure the improvements with commonly used quality metrics. We find that this method 1) increases estimation accuracy and reliability, 2) reduces the model's volatility and, thus, is likely to increase its acceptance in practice, and 3) indicates upper limits for analogy-based estimation quality as measured by standard metrics.",Software cost estimation;analogy-based cost estimation;project clustering;project features.,M. Auer; A. Trendowicz; B. Graser; E. Haunschmid; S. Biffl,2006,Journal,IEEE Transactions on Software Engineering,10.1109/TSE.2006.1599418,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=1599418,"Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Austria; NA; NA; NA; NA",IEEE,English,1939-3520,
IEEE,An empirical study of the correlations between function point elements [software metrics],"Researchers and practitioners have noted correlations between the five types of elements in function point analysis. Practitioners exploit them; researchers have raised concerns about them. Two previous studies of the correlations between the elements have agreed in some findings, but differed on others. A large data set is analyzed here to gain further insight into the correlations. Two elements (inputs and logical files) are found to be correlated always, and one element (external files) is found to be generally uncorrelated with the others. Correlations are strongest in new development projects that use 4GLs. These results confirm some findings of previous researchers, and suggest explanations for differences between previous findings.",,C. J. Lokan,1999,Conference,Proceedings Sixth International Software Metrics Symposium (Cat. No.PR00403),10.1109/METRIC.1999.809741,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=809741,"Sch. of Comput. Sci., Australian Defence Force Acad., Canberra, ACT, Australia",IEEE,English,,0-7695-0403-5
IEEE,Software cost estimation using homeostasis mutation based differential evolution,"The main concern in the field of software development is estimation of the cost of software at its initial phase of development. The cost estimation usually depends upon the size of the project, which may use lines of code or function points as metrics. In COCOMO, for the accuracy of the cost estimation, cost factors need to be formulated in the individual development environment. In this paper, some new mutation strategies are proposed to improve the accuracy of cost estimation by modifying parameters of COCOMO using Homeostasis mutation based differential evolution(HMBDE). The proposed method adds one more vector named as Homeostasis mutation vector in the existing mutation vector to provide more bandwidth for selecting effective mutant solutions providing a wide search space for probable solution. The proposed approach provides more accurate solutions to guide the evolution. Performance of proposed algorithm is compared with software cost estimation models. The result verifies that our proposed HMBDE performs better than COCOMO based DE and PSO algorithm and other soft computing models.",Software Cost Estimation;Differential Evolution;Homeostasis;COCOMO Model,S. P. Singh; A. Kumar,2017,Conference,2017 11th International Conference on Intelligent Systems and Control (ISCO),10.1109/ISCO.2017.7855976,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=7855976,"Department Computer Science and Engineering, Motilal Nehru National Institute of Technology Allahabad, UP, India; Department Computer Science and Engineering, Motilal Nehru National Institute of Technology Allahabad, UP, India",IEEE,English,,978-1-5090-2717-0
IEEE,Optimal test distributions for software failure cost estimation,"We generalize the input domain based software reliability measures by E.C. Nelson (1973) and by S.N. Weiss and E.J. Weyuker (1988), introducing expected failure costs under the operational distribution as a measure for software unreliability. This approach incorporates in the reliability concept a distinction between different degrees of failure severity. It is shown how to estimate the proposed quantity by means of random testing, using the Importance Sampling technique from Rare Event Simulation. A test input distribution that yields an unbiased estimator with minimum variance is determined. The practical application of the presented method is outlined, and a detailed numerical example is given.<>",,W. J. Gutjahr,1995,Journal,IEEE Transactions on Software Engineering,10.1109/32.372149,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=372149,"Dept. of Stat., Oper. Res. & Comput. Sci., Wien Univ., Austria",IEEE,English,1939-3520,
IEEE,Enhanced software project management by application of metrics and cost estimation techniques,"This paper describes elements of an improvement project within a collaborative partnership between the University of Cambridge and GPT Ltd, the UK's largest supplier of telecommunications solutions. The project aims to identify, formulate and collect a series of key measures to aid project planning and control through the provision of valid quantitative project data, and to stimulate software process improvement. In the paper the approach to metrics implementation is discussed and recently developed cost estimation techniques are introduced.",,P. Fitzhenry; G. Gardiner,1995,Conference,IEE Colloquium on Project Management for Software Engineers,10.1049/ic:19951542,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=494938,"Manuf. Group, Cambridge Univ., UK; NA",IET,English,,
IEEE,Beyond Total Cost of Ownership: Applying Balanced Scorecards to Open-Source Software,"Potential users of Open Source Software (OSS) face the problem of evaluating OSS, in order to assess the convenience of adopting OSS instead of commercial software, or to choose among different OSS proposals. Different metrics were defined, addressing different OSS properties: the Total Cost of Ownership (TCO) addresses the cost of acquiring, adapting and operating OSS; the Total Account Ownership (TAO) represents the degree of freedom of the user with respect to the technology provider; indexes like the Open Business Quality Rating (Open BQR) assess the quality of the software with respect to the user's needs. However, none of the proposed methods and models addresses all the aspects of OSS in a balanced and complete way. For this purpose, the paper explores the possibility of adapting the Balanced Scorecard (BSC) technique to OSS. A preliminary definition of the BSC for OSS is given and discussed.",,L. Lavazza,2007,Conference,International Conference on Software Engineering Advances (ICSEA 2007),10.1109/ICSEA.2007.19,https://ieeexplore-ieee-org.recursos.biblioteca.upc.edu/stamp/stamp.jsp?arnumber=4299954,University of Insubria,IEEE,English,,0-7695-2937-2
